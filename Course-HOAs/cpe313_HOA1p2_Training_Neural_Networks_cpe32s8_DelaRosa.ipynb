{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jepowo/CPE_313/blob/main/cpe313_HOA1p2_Training_Neural_Networks_cpe32s8_DelaRosa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f299ae46-6ea3-411a-e003-de9fb81d368f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# filepath = \"pima-indians-diabetes.csv\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = '/content/drive/My Drive/dataset/pima-indians-diabetes.csv'\n",
        "\n",
        "\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "f196eeb5-5622-457c-8170-d741f94793ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "650               1                      91              54              25   \n",
              "408               8                     197              74               0   \n",
              "272               3                     122              78               0   \n",
              "147               2                     106              64              35   \n",
              "755               1                     128              88              39   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "650      100  25.2              0.234   23             0  \n",
              "408        0  25.9              1.191   39             1  \n",
              "272        0  23.0              0.254   40             0  \n",
              "147      119  30.5              1.400   34             0  \n",
              "755      110  36.5              1.057   37             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-651fdcbd-9b3b-42ba-8481-d20ef8bd627f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>54</td>\n",
              "      <td>25</td>\n",
              "      <td>100</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.234</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>8</td>\n",
              "      <td>197</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.9</td>\n",
              "      <td>1.191</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>3</td>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.254</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2</td>\n",
              "      <td>106</td>\n",
              "      <td>64</td>\n",
              "      <td>35</td>\n",
              "      <td>119</td>\n",
              "      <td>30.5</td>\n",
              "      <td>1.400</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>110</td>\n",
              "      <td>36.5</td>\n",
              "      <td>1.057</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-651fdcbd-9b3b-42ba-8481-d20ef8bd627f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-651fdcbd-9b3b-42ba-8481-d20ef8bd627f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-651fdcbd-9b3b-42ba-8481-d20ef8bd627f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0324a6f7-bcb8-4a3b-a2f8-a9c027eb0d55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0324a6f7-bcb8-4a3b-a2f8-a9c027eb0d55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0324a6f7-bcb8-4a3b-a2f8-a9c027eb0d55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0477e9a-7544-40e4-b29d-641ace25b461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "X"
      ],
      "metadata": {
        "id": "OSTDZVQW6Tf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b867021-2ef1-4986-83eb-be5e15ec0fd8"
      },
      "id": "OSTDZVQW6Tf_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)\n",
        "y"
      ],
      "metadata": {
        "id": "Y5D2s2lW6YgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68659bc4-c946-4adb-9235-b967f22432d4"
      },
      "id": "Y5D2s2lW6YgQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a661b4-5ba2-44de-cba0-7848cce879e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.layers)"
      ],
      "metadata": {
        "id": "OOXJVHRVIE8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31313416-5773-449c-8ed6-d5a950a5aae5"
      },
      "id": "OOXJVHRVIE8h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebb89ea-568c-45b7-89b6-5110c4749d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7823beda-49da-4f9f-a591-b057454d0c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 19ms/step - loss: 0.6846 - accuracy: 0.6111 - val_loss: 0.6275 - val_accuracy: 0.6302\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.6250 - val_loss: 0.6091 - val_accuracy: 0.6406\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6615 - val_loss: 0.5937 - val_accuracy: 0.6510\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.6667 - val_loss: 0.5807 - val_accuracy: 0.6771\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6753 - val_loss: 0.5697 - val_accuracy: 0.7031\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.6944 - val_loss: 0.5602 - val_accuracy: 0.7135\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.7031 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7170 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.7257 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7292 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7361 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7413 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7535 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7500 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7465 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7483 - val_loss: 0.5092 - val_accuracy: 0.7917\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7517 - val_loss: 0.5071 - val_accuracy: 0.7865\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7483 - val_loss: 0.5052 - val_accuracy: 0.7865\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7552 - val_loss: 0.5035 - val_accuracy: 0.7917\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7569 - val_loss: 0.5019 - val_accuracy: 0.7917\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7535 - val_loss: 0.5005 - val_accuracy: 0.7969\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7552 - val_loss: 0.4992 - val_accuracy: 0.7917\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7604 - val_loss: 0.4981 - val_accuracy: 0.7969\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7969\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7656 - val_loss: 0.4949 - val_accuracy: 0.7969\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7917\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.4932 - val_accuracy: 0.7917\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7969\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7969\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7865\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7865\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.4899 - val_accuracy: 0.7865\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4894 - val_accuracy: 0.7865\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7708 - val_loss: 0.4885 - val_accuracy: 0.7865\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4868 - val_accuracy: 0.7812\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7812\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7812\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.4845 - val_accuracy: 0.7760\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7760\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4842 - val_accuracy: 0.7760\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7760\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4840 - val_accuracy: 0.7760\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7760\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4839 - val_accuracy: 0.7812\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.4842 - val_accuracy: 0.7812\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7812\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7812\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7812\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7899 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7812\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7812\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7812\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4894 - val_accuracy: 0.7812\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7812\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.4896 - val_accuracy: 0.7812\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.4897 - val_accuracy: 0.7812\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7812\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7812\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7812\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.4905 - val_accuracy: 0.7812\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.4906 - val_accuracy: 0.7812\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4907 - val_accuracy: 0.7812\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.4909 - val_accuracy: 0.7812\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7899 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.4913 - val_accuracy: 0.7812\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7812\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7812\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7812\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7812\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7812\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7812\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7812\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7812\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7812\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7812\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7830 - val_loss: 0.4957 - val_accuracy: 0.7812\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.4958 - val_accuracy: 0.7812\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7812\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1cb554-0e34-4ef8-bd7d-273e47aa8498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "#\n",
        "# y_pred_class_nn_1 = model.predict_classes(X_test_norm)\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "# y_pred_class_nn_1 = np.argmax(model.predict(X_test_norm), axis=1)\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c8492b-d873-411d-a5d3-514bdbd3abd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044e2e3e-97e2-4f7e-ef10-0c0b431a5cd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57113004],\n",
              "       [0.565662  ],\n",
              "       [0.310637  ],\n",
              "       [0.18376544],\n",
              "       [0.17019185],\n",
              "       [0.4444157 ],\n",
              "       [0.024828  ],\n",
              "       [0.36225083],\n",
              "       [0.95339745],\n",
              "       [0.17365043]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "GFDsO0Gz-vAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f07f23-8cdd-48f8-fe16-a4b5db8844a7"
      },
      "id": "GFDsO0Gz-vAu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1"
      ],
      "metadata": {
        "id": "u_eECpLb-wg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49cdafa-6358-4c50-9a20-04040fb3bae5"
      },
      "id": "u_eECpLb-wg_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_1"
      ],
      "metadata": {
        "id": "YQCQLN5g-yjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292fb7aa-8e0c-447d-c0b8-281dee9a8b6f"
      },
      "id": "YQCQLN5g-yjf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.71130037e-01],\n",
              "       [5.65662026e-01],\n",
              "       [3.10636997e-01],\n",
              "       [1.83765441e-01],\n",
              "       [1.70191854e-01],\n",
              "       [4.44415689e-01],\n",
              "       [2.48279981e-02],\n",
              "       [3.62250835e-01],\n",
              "       [9.53397453e-01],\n",
              "       [1.73650429e-01],\n",
              "       [1.61885500e-01],\n",
              "       [7.13533387e-02],\n",
              "       [6.99699998e-01],\n",
              "       [4.37074490e-02],\n",
              "       [8.60502243e-01],\n",
              "       [6.69682682e-01],\n",
              "       [4.05974060e-01],\n",
              "       [2.32877091e-01],\n",
              "       [7.28196025e-01],\n",
              "       [1.44554049e-01],\n",
              "       [3.44109416e-01],\n",
              "       [1.40968626e-02],\n",
              "       [1.44714206e-01],\n",
              "       [7.62878239e-01],\n",
              "       [6.46985710e-01],\n",
              "       [7.30103850e-01],\n",
              "       [8.19693267e-01],\n",
              "       [8.34810913e-01],\n",
              "       [5.99085130e-02],\n",
              "       [8.86303246e-01],\n",
              "       [1.96762651e-01],\n",
              "       [4.51143056e-01],\n",
              "       [1.11813203e-01],\n",
              "       [3.44946891e-01],\n",
              "       [1.94703341e-01],\n",
              "       [6.92940235e-01],\n",
              "       [9.43637788e-01],\n",
              "       [3.97061586e-01],\n",
              "       [2.10833684e-01],\n",
              "       [5.47887981e-01],\n",
              "       [7.82161117e-01],\n",
              "       [2.89829791e-01],\n",
              "       [5.99531949e-01],\n",
              "       [7.45108664e-01],\n",
              "       [1.12761170e-01],\n",
              "       [1.22483626e-01],\n",
              "       [3.89119416e-01],\n",
              "       [1.31853923e-01],\n",
              "       [8.87373649e-03],\n",
              "       [5.24031520e-01],\n",
              "       [4.60932195e-01],\n",
              "       [4.42701638e-01],\n",
              "       [7.76272833e-01],\n",
              "       [2.21334457e-01],\n",
              "       [7.59756625e-01],\n",
              "       [1.25009209e-01],\n",
              "       [6.07459545e-02],\n",
              "       [1.29687324e-01],\n",
              "       [4.27557290e-01],\n",
              "       [3.86486761e-02],\n",
              "       [5.80156259e-02],\n",
              "       [2.52983004e-01],\n",
              "       [9.18312222e-02],\n",
              "       [1.39825670e-02],\n",
              "       [2.13971213e-02],\n",
              "       [5.40436625e-01],\n",
              "       [1.01265926e-02],\n",
              "       [5.37838880e-03],\n",
              "       [2.53004860e-02],\n",
              "       [3.97870451e-01],\n",
              "       [9.07898068e-01],\n",
              "       [2.26977617e-02],\n",
              "       [2.63323896e-02],\n",
              "       [1.37322485e-01],\n",
              "       [4.56928074e-01],\n",
              "       [5.19157827e-01],\n",
              "       [3.66446614e-01],\n",
              "       [5.39615095e-01],\n",
              "       [3.06772888e-01],\n",
              "       [3.39589983e-01],\n",
              "       [7.38012671e-01],\n",
              "       [1.26228211e-02],\n",
              "       [9.45053936e-04],\n",
              "       [1.81179866e-01],\n",
              "       [7.12512016e-01],\n",
              "       [1.52432676e-02],\n",
              "       [2.47522786e-01],\n",
              "       [6.13587141e-01],\n",
              "       [6.17698848e-01],\n",
              "       [4.08478945e-01],\n",
              "       [2.32042205e-02],\n",
              "       [3.23135927e-02],\n",
              "       [7.92022526e-01],\n",
              "       [8.17949831e-01],\n",
              "       [6.69253647e-01],\n",
              "       [3.74573432e-02],\n",
              "       [4.52679187e-01],\n",
              "       [3.27994466e-01],\n",
              "       [8.78478512e-02],\n",
              "       [4.49025869e-01],\n",
              "       [3.88059646e-01],\n",
              "       [1.54111683e-02],\n",
              "       [3.32508087e-01],\n",
              "       [5.20653427e-01],\n",
              "       [2.52916306e-01],\n",
              "       [2.22133592e-01],\n",
              "       [6.54499158e-02],\n",
              "       [4.24153693e-02],\n",
              "       [2.47939035e-01],\n",
              "       [9.01549101e-01],\n",
              "       [3.35924745e-01],\n",
              "       [3.97592783e-01],\n",
              "       [3.96166146e-01],\n",
              "       [1.01507418e-01],\n",
              "       [6.87933862e-02],\n",
              "       [1.51342107e-02],\n",
              "       [6.08249567e-02],\n",
              "       [2.75988400e-01],\n",
              "       [1.23513028e-01],\n",
              "       [1.13640614e-02],\n",
              "       [4.27316725e-01],\n",
              "       [7.50692636e-02],\n",
              "       [7.21193075e-01],\n",
              "       [6.52345419e-02],\n",
              "       [6.68436229e-01],\n",
              "       [4.15175527e-01],\n",
              "       [2.82744199e-01],\n",
              "       [6.99794829e-01],\n",
              "       [3.56070191e-01],\n",
              "       [4.24389020e-02],\n",
              "       [8.73139858e-01],\n",
              "       [1.19846851e-01],\n",
              "       [4.36540812e-01],\n",
              "       [1.88279092e-01],\n",
              "       [1.63456082e-01],\n",
              "       [1.36851206e-01],\n",
              "       [2.27081969e-01],\n",
              "       [1.81733534e-01],\n",
              "       [5.57283079e-03],\n",
              "       [3.04794237e-02],\n",
              "       [2.33880743e-01],\n",
              "       [9.23252761e-01],\n",
              "       [6.76224113e-01],\n",
              "       [9.98644624e-03],\n",
              "       [2.29506269e-01],\n",
              "       [5.27623892e-02],\n",
              "       [1.78110942e-01],\n",
              "       [3.10772955e-02],\n",
              "       [9.04554367e-01],\n",
              "       [5.62026799e-01],\n",
              "       [1.43996477e-01],\n",
              "       [1.91887349e-01],\n",
              "       [1.90227717e-01],\n",
              "       [4.10755634e-01],\n",
              "       [6.04765452e-02],\n",
              "       [1.20163187e-01],\n",
              "       [4.13950801e-01],\n",
              "       [4.86521274e-01],\n",
              "       [4.42842603e-01],\n",
              "       [1.74759597e-01],\n",
              "       [4.13263053e-01],\n",
              "       [4.04534817e-01],\n",
              "       [7.21913278e-02],\n",
              "       [3.63978475e-01],\n",
              "       [2.02647895e-01],\n",
              "       [7.95844257e-01],\n",
              "       [7.51830488e-02],\n",
              "       [2.32981905e-01],\n",
              "       [8.43915418e-02],\n",
              "       [9.03357342e-02],\n",
              "       [6.99960887e-01],\n",
              "       [4.60389972e-01],\n",
              "       [4.04823869e-01],\n",
              "       [1.59203857e-02],\n",
              "       [7.61474967e-01],\n",
              "       [6.95841992e-03],\n",
              "       [1.42365396e-02],\n",
              "       [1.81584656e-01],\n",
              "       [4.47731346e-01],\n",
              "       [1.47094771e-01],\n",
              "       [5.61909318e-01],\n",
              "       [5.09093516e-02],\n",
              "       [3.55929881e-01],\n",
              "       [1.19842418e-01],\n",
              "       [4.14444745e-01],\n",
              "       [7.12037802e-01],\n",
              "       [1.33534586e-02],\n",
              "       [4.55058753e-01],\n",
              "       [7.96518564e-01],\n",
              "       [9.64849472e-01],\n",
              "       [8.83080602e-01],\n",
              "       [1.81978598e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "1f619ab0-cce1-40f1-e286-5089e6c55ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.781\n",
            "roc-auc is 0.824\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1.round())))\n",
        "# print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1.round())))\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b771f84-1abe-4094-a6e0-0ab49554e091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "a6fed3c6-646a-41a1-c7b3-d2a07a26bb09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c5a34334af0>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "It appears that the training loss and validation loss both decrease over time which means that the model is learning from the training data and is improving its performance. But the validation loss is higher than the training loss."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelA = Sequential([\n",
        "    Dense(6, activation='relu'),\n",
        "    Dense(6, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "7CORaUkN_T5o"
      },
      "id": "7CORaUkN_T5o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_A = modelA.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "id": "dQK3tDZ6Ehrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8dc3e3-f879-4466-8f72-2d139ece3dbb"
      },
      "id": "dQK3tDZ6Ehrt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6675 - accuracy: 0.6580 - val_loss: 0.6729 - val_accuracy: 0.6510\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6580 - val_loss: 0.6683 - val_accuracy: 0.6510\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6528 - val_loss: 0.6642 - val_accuracy: 0.6458\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6528 - val_loss: 0.6604 - val_accuracy: 0.6458\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6580 - val_loss: 0.6570 - val_accuracy: 0.6458\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6580 - val_loss: 0.6538 - val_accuracy: 0.6510\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6580 - val_loss: 0.6509 - val_accuracy: 0.6510\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6580 - val_loss: 0.6482 - val_accuracy: 0.6458\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6580 - val_loss: 0.6457 - val_accuracy: 0.6458\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6580 - val_loss: 0.6433 - val_accuracy: 0.6458\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6597 - val_loss: 0.6411 - val_accuracy: 0.6458\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6597 - val_loss: 0.6389 - val_accuracy: 0.6458\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6597 - val_loss: 0.6369 - val_accuracy: 0.6458\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6597 - val_loss: 0.6349 - val_accuracy: 0.6458\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6597 - val_loss: 0.6330 - val_accuracy: 0.6458\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6597 - val_loss: 0.6311 - val_accuracy: 0.6458\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6615 - val_loss: 0.6293 - val_accuracy: 0.6458\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.6632 - val_loss: 0.6275 - val_accuracy: 0.6458\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6632 - val_loss: 0.6256 - val_accuracy: 0.6458\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6649 - val_loss: 0.6238 - val_accuracy: 0.6458\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6649 - val_loss: 0.6219 - val_accuracy: 0.6562\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.6632 - val_loss: 0.6201 - val_accuracy: 0.6615\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.6649 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6684 - val_loss: 0.6164 - val_accuracy: 0.6667\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5810 - accuracy: 0.6684 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.6701 - val_loss: 0.6127 - val_accuracy: 0.6771\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.6736 - val_loss: 0.6108 - val_accuracy: 0.6823\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6771 - val_loss: 0.6089 - val_accuracy: 0.6875\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.6823 - val_loss: 0.6069 - val_accuracy: 0.6771\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.6875 - val_loss: 0.6049 - val_accuracy: 0.6875\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6875 - val_loss: 0.6029 - val_accuracy: 0.6927\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6927 - val_loss: 0.6008 - val_accuracy: 0.6979\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.6910 - val_loss: 0.5987 - val_accuracy: 0.6927\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.6997 - val_loss: 0.5966 - val_accuracy: 0.6979\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7049 - val_loss: 0.5945 - val_accuracy: 0.6927\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7135 - val_loss: 0.5923 - val_accuracy: 0.6927\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7170 - val_loss: 0.5901 - val_accuracy: 0.6927\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7205 - val_loss: 0.5880 - val_accuracy: 0.6979\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7344 - val_loss: 0.5858 - val_accuracy: 0.7031\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7326 - val_loss: 0.5837 - val_accuracy: 0.6979\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7378 - val_loss: 0.5815 - val_accuracy: 0.6979\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7361 - val_loss: 0.5793 - val_accuracy: 0.7083\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7361 - val_loss: 0.5773 - val_accuracy: 0.7083\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7361 - val_loss: 0.5753 - val_accuracy: 0.7188\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7413 - val_loss: 0.5734 - val_accuracy: 0.7135\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7396 - val_loss: 0.5715 - val_accuracy: 0.7083\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7413 - val_loss: 0.5696 - val_accuracy: 0.7083\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7448 - val_loss: 0.5676 - val_accuracy: 0.7031\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5657 - val_accuracy: 0.7135\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7135\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7517 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7552 - val_loss: 0.5584 - val_accuracy: 0.7083\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7552 - val_loss: 0.5567 - val_accuracy: 0.7135\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7517 - val_loss: 0.5550 - val_accuracy: 0.6979\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7465 - val_loss: 0.5535 - val_accuracy: 0.7031\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7448 - val_loss: 0.5520 - val_accuracy: 0.7031\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7413 - val_loss: 0.5507 - val_accuracy: 0.7083\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7413 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7431 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7431 - val_loss: 0.5470 - val_accuracy: 0.7083\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7465 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7448 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7448 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7448 - val_loss: 0.5425 - val_accuracy: 0.7135\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7448 - val_loss: 0.5416 - val_accuracy: 0.7135\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7483 - val_loss: 0.5406 - val_accuracy: 0.7083\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7517 - val_loss: 0.5397 - val_accuracy: 0.7031\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7517 - val_loss: 0.5388 - val_accuracy: 0.7083\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7500 - val_loss: 0.5380 - val_accuracy: 0.7135\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7483 - val_loss: 0.5372 - val_accuracy: 0.7135\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7483 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7483 - val_loss: 0.5356 - val_accuracy: 0.7188\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7465 - val_loss: 0.5349 - val_accuracy: 0.7188\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7465 - val_loss: 0.5341 - val_accuracy: 0.7292\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7448 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7448 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7483 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7483 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7500 - val_loss: 0.5311 - val_accuracy: 0.7292\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7483 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7517 - val_loss: 0.5300 - val_accuracy: 0.7292\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7552 - val_loss: 0.5295 - val_accuracy: 0.7292\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7535 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7569 - val_loss: 0.5286 - val_accuracy: 0.7344\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7622 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7569 - val_loss: 0.5278 - val_accuracy: 0.7344\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7604 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7639 - val_loss: 0.5270 - val_accuracy: 0.7344\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7656 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7743 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7743 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7448\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7778 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7778 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7778 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7778 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7778 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7778 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7778 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7760 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7760 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7778 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7778 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7778 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7778 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7795 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7795 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7795 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7778 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7795 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7795 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7778 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4245 - accuracy: 0.7795 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7778 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7778 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7812 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7812 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7812 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7778 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7778 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7795 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7795 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7778 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7795 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7795 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7795 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7778 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7778 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7760 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7795 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7778 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7778 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7795 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7778 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4216 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.7778 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4216 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7760\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7795 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7778 - val_loss: 0.5255 - val_accuracy: 0.7760\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7795 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7812 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7795 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7795 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7865 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7760\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5255 - val_accuracy: 0.7760\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7865 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7865 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7865 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7865 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7899 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7882 - val_loss: 0.5254 - val_accuracy: 0.7760\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7865 - val_loss: 0.5253 - val_accuracy: 0.7760\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.5252 - val_accuracy: 0.7760\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7865 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7865 - val_loss: 0.5251 - val_accuracy: 0.7760\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7882 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7899 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5246 - val_accuracy: 0.7760\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5246 - val_accuracy: 0.7760\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5246 - val_accuracy: 0.7760\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7899 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7917 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5244 - val_accuracy: 0.7760\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7917 - val_loss: 0.5244 - val_accuracy: 0.7760\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5244 - val_accuracy: 0.7760\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5244 - val_accuracy: 0.7760\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7917 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7760\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7760\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7760\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7899 - val_loss: 0.5242 - val_accuracy: 0.7760\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5242 - val_accuracy: 0.7760\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5240 - val_accuracy: 0.7760\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5240 - val_accuracy: 0.7760\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4181 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7760\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7760\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5239 - val_accuracy: 0.7760\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7760\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7934 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.7934 - val_loss: 0.5236 - val_accuracy: 0.7760\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7760\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7934 - val_loss: 0.5236 - val_accuracy: 0.7760\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4178 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7899 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7865 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.7917 - val_loss: 0.5227 - val_accuracy: 0.7708\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7899 - val_loss: 0.5223 - val_accuracy: 0.7708\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7917 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7917 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7899 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7917 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7899 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7917 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7917 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7917 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7917 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7899 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7899 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7847 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7917 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7865 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7882 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7917 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7882 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7882 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7899 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7899 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.7899 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.7865 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7865 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.7899 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7882 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7865 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.7899 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.7865 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.7865 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4130 - accuracy: 0.7865 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.7865 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7917 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7934 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7899 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7865 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.7969 - val_loss: 0.5227 - val_accuracy: 0.7760\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.7865 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.7865 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.7865 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7917 - val_loss: 0.5232 - val_accuracy: 0.7760\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.5231 - val_accuracy: 0.7760\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7882 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7882 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7882 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7917 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.7951 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7917 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7917 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7934 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7899 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7934 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7917 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7934 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7951 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7917 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7951 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7899 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7934 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.7934 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7934 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7934 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7934 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7934 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7951 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7934 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.7934 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7917 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7917 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7917 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7934 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7969 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7934 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7969 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7951 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7934 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7934 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7951 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7951 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7951 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.7951 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.7969 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.7951 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.7951 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7969 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7934 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7951 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7934 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.7969 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.7934 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7951 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7951 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7934 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7969 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.7986 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8003 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8021 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8003 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8021 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8021 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8073 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8073 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8056 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8056 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8056 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(modelA.layers)"
      ],
      "metadata": {
        "id": "QeqWv4brH4qQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c63e4c1-4f25-4289-f9e5-af14086532c0"
      },
      "id": "QeqWv4brH4qQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_A = (modelA.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_A = modelA.predict(X_test_norm)"
      ],
      "metadata": {
        "id": "T3VVPbYjEiBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32abc90a-140e-4c48-8b33-71150f96bb46"
      },
      "id": "T3VVPbYjEiBK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_A[:10]"
      ],
      "metadata": {
        "id": "BQyds1oyGMoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8f9c78-526a-4f18-d8a5-f436f802fbaf"
      },
      "id": "BQyds1oyGMoB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_A[:10]"
      ],
      "metadata": {
        "id": "GqWmWInmEiG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c3e308-e564-4397-8330-1ec158ca6790"
      },
      "id": "GqWmWInmEiG6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5846946 ],\n",
              "       [0.6460568 ],\n",
              "       [0.46035126],\n",
              "       [0.27379274],\n",
              "       [0.09558823],\n",
              "       [0.6729518 ],\n",
              "       [0.01586329],\n",
              "       [0.14297067],\n",
              "       [0.9500153 ],\n",
              "       [0.14618982]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "2gL69pUcEiKf"
      },
      "id": "2gL69pUcEiKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_A)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_A)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_A, 'NN')"
      ],
      "metadata": {
        "id": "RcLjw-KpEiNi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "09d21ea3-9e5d-4a69-9c7d-9eb9f7bb5ada"
      },
      "id": "RcLjw-KpEiNi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.812\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "yq3gPuKXG40x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "673661d9-dc90-436a-9d6d-3794b23be819"
      },
      "id": "yq3gPuKXG40x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c5a34239990>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "xWBZjm0FK2aG"
      },
      "id": "xWBZjm0FK2aG"
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "filepath_wine = '/content/drive/My Drive/dataset/WineQT.csv'"
      ],
      "metadata": {
        "id": "wjF-oSxI3g6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478b9caf-5139-43bb-f58f-3fdde0adda6c"
      },
      "id": "wjF-oSxI3g6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df = pd.read_csv(filepath_wine)"
      ],
      "metadata": {
        "id": "s8DVPBO6GndO"
      },
      "id": "s8DVPBO6GndO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.shape"
      ],
      "metadata": {
        "id": "x6wl9tWb6dYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3153196-76da-4974-e6b4-08562347ab10"
      },
      "id": "x6wl9tWb6dYL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1143, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vV0low7gEys4",
        "outputId": "62a6c0f8-09d0-43f0-a05c-cd5e7d2b690c"
      },
      "id": "vV0low7gEys4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "843            7.0             0.745         0.12             1.8      0.114   \n",
              "97             6.3             0.390         0.08             1.7      0.066   \n",
              "727           10.1             0.370         0.34             2.4      0.085   \n",
              "982            7.1             0.755         0.15             1.8      0.107   \n",
              "803           10.4             0.520         0.45             2.0      0.080   \n",
              "\n",
              "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "843                 15.0                  64.0  0.99588  3.22       0.59   \n",
              "97                   3.0                  20.0  0.99540  3.34       0.58   \n",
              "727                  5.0                  17.0  0.99683  3.17       0.65   \n",
              "982                 20.0                  84.0  0.99593  3.19       0.50   \n",
              "803                  6.0                  13.0  0.99774  3.22       0.76   \n",
              "\n",
              "     alcohol  quality    Id  \n",
              "843      9.5        6  1194  \n",
              "97       9.4        5   143  \n",
              "727     10.6        7  1035  \n",
              "982      9.5        5  1384  \n",
              "803     11.4        6  1136  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b49bf8c-42ff-422a-9a86-532626946d11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>843</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.114</td>\n",
              "      <td>15.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.99588</td>\n",
              "      <td>3.22</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "      <td>1194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.066</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>10.1</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.085</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.99683</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.65</td>\n",
              "      <td>10.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.107</td>\n",
              "      <td>20.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.99593</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>10.4</td>\n",
              "      <td>0.520</td>\n",
              "      <td>0.45</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.080</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.99774</td>\n",
              "      <td>3.22</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.4</td>\n",
              "      <td>6</td>\n",
              "      <td>1136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b49bf8c-42ff-422a-9a86-532626946d11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b49bf8c-42ff-422a-9a86-532626946d11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b49bf8c-42ff-422a-9a86-532626946d11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9ff143d-b425-4a01-9778-e5a69951ee57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ff143d-b425-4a01-9778-e5a69951ee57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9ff143d-b425-4a01-9778-e5a69951ee57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnqXoO41E0wx",
        "outputId": "1cd79286-c10f-4163-ecc6-cf683e7c9387"
      },
      "id": "EnqXoO41E0wx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fixed acidity           float64\n",
              "volatile acidity        float64\n",
              "citric acid             float64\n",
              "residual sugar          float64\n",
              "chlorides               float64\n",
              "free sulfur dioxide     float64\n",
              "total sulfur dioxide    float64\n",
              "density                 float64\n",
              "pH                      float64\n",
              "sulphates               float64\n",
              "alcohol                 float64\n",
              "quality                   int64\n",
              "Id                        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.drop(['Id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Z_MnGVX-GlDy"
      },
      "id": "Z_MnGVX-GlDy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_wine = wine_df.drop(columns=['quality']).values\n",
        "y_wine = (wine_df['quality'] > 5).astype(int).values"
      ],
      "metadata": {
        "id": "k_FW93ZD6fQo"
      },
      "id": "k_FW93ZD6fQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_wine.shape)\n",
        "print(y_wine.shape)"
      ],
      "metadata": {
        "id": "VHQSjwC16gz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd927dab-0043-4dec-9bc4-b41f834100aa"
      },
      "id": "VHQSjwC16gz9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1143, 11)\n",
            "(1143,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainB, X_testB, y_trainB, y_testB = train_test_split(X_wine, y_wine, test_size=0.25, random_state=11111)"
      ],
      "metadata": {
        "id": "DgEKrL7q6oLE"
      },
      "id": "DgEKrL7q6oLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer_wine = StandardScaler()\n",
        "X_train_normB = normalizer_wine.fit_transform(X_trainB)\n",
        "X_test_normB = normalizer_wine.transform(X_testB)"
      ],
      "metadata": {
        "id": "ygwXcWbJ6pY-"
      },
      "id": "ygwXcWbJ6pY-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB = Sequential([\n",
        "   Dense(8, input_shape=(11,), activation='relu'),\n",
        "   Dense(4, activation='relu'),\n",
        "   Dense(2, activation='relu'),\n",
        "   Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "gNBWT7AiHkHu"
      },
      "id": "gNBWT7AiHkHu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrB = 0.016\n",
        "epocB = 1200"
      ],
      "metadata": {
        "id": "wu8lGGJPSKBC"
      },
      "id": "wu8lGGJPSKBC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.compile(SGD(lr = lrB), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_B = modelB.fit(X_train_normB, y_trainB, validation_data=(X_test_normB, y_testB), epochs=epocB)"
      ],
      "metadata": {
        "id": "O3RvQt7aK8HP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4264ebd3-bdcf-426d-cc0a-43d3dc0c4266"
      },
      "id": "O3RvQt7aK8HP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "27/27 [==============================] - 1s 15ms/step - loss: 0.7332 - accuracy: 0.5531 - val_loss: 0.7444 - val_accuracy: 0.5105\n",
            "Epoch 2/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7166 - accuracy: 0.5578 - val_loss: 0.7273 - val_accuracy: 0.5105\n",
            "Epoch 3/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7063 - accuracy: 0.5636 - val_loss: 0.7160 - val_accuracy: 0.5035\n",
            "Epoch 4/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.5648 - val_loss: 0.7078 - val_accuracy: 0.5140\n",
            "Epoch 5/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5648 - val_loss: 0.7012 - val_accuracy: 0.5350\n",
            "Epoch 6/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5683 - val_loss: 0.6959 - val_accuracy: 0.5385\n",
            "Epoch 7/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5799 - val_loss: 0.6915 - val_accuracy: 0.5385\n",
            "Epoch 8/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5846 - val_loss: 0.6874 - val_accuracy: 0.5524\n",
            "Epoch 9/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5963 - val_loss: 0.6836 - val_accuracy: 0.5699\n",
            "Epoch 10/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6044 - val_loss: 0.6801 - val_accuracy: 0.5664\n",
            "Epoch 11/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.5986 - val_loss: 0.6766 - val_accuracy: 0.5734\n",
            "Epoch 12/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6149 - val_loss: 0.6732 - val_accuracy: 0.5769\n",
            "Epoch 13/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6161 - val_loss: 0.6699 - val_accuracy: 0.5874\n",
            "Epoch 14/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6266 - val_loss: 0.6663 - val_accuracy: 0.5909\n",
            "Epoch 15/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6254 - val_loss: 0.6629 - val_accuracy: 0.5909\n",
            "Epoch 16/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.6301 - val_loss: 0.6593 - val_accuracy: 0.5979\n",
            "Epoch 17/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6371 - val_loss: 0.6557 - val_accuracy: 0.6049\n",
            "Epoch 18/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6371 - val_loss: 0.6522 - val_accuracy: 0.6119\n",
            "Epoch 19/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6371 - val_loss: 0.6485 - val_accuracy: 0.6224\n",
            "Epoch 20/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6429 - val_loss: 0.6448 - val_accuracy: 0.6259\n",
            "Epoch 21/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6511 - val_loss: 0.6411 - val_accuracy: 0.6294\n",
            "Epoch 22/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6511 - val_loss: 0.6373 - val_accuracy: 0.6503\n",
            "Epoch 23/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6511 - val_loss: 0.6333 - val_accuracy: 0.6503\n",
            "Epoch 24/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6581 - val_loss: 0.6295 - val_accuracy: 0.6678\n",
            "Epoch 25/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6616 - val_loss: 0.6255 - val_accuracy: 0.6783\n",
            "Epoch 26/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6721 - val_loss: 0.6216 - val_accuracy: 0.6888\n",
            "Epoch 27/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6733 - val_loss: 0.6180 - val_accuracy: 0.6818\n",
            "Epoch 28/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.6756 - val_loss: 0.6145 - val_accuracy: 0.6783\n",
            "Epoch 29/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6838 - val_loss: 0.6110 - val_accuracy: 0.6783\n",
            "Epoch 30/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6873 - val_loss: 0.6075 - val_accuracy: 0.6853\n",
            "Epoch 31/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6896 - val_loss: 0.6042 - val_accuracy: 0.6888\n",
            "Epoch 32/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6908 - val_loss: 0.6010 - val_accuracy: 0.6818\n",
            "Epoch 33/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6943 - val_loss: 0.5978 - val_accuracy: 0.6958\n",
            "Epoch 34/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6931 - val_loss: 0.5949 - val_accuracy: 0.6993\n",
            "Epoch 35/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6908 - val_loss: 0.5919 - val_accuracy: 0.7028\n",
            "Epoch 36/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6896 - val_loss: 0.5891 - val_accuracy: 0.7028\n",
            "Epoch 37/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6931 - val_loss: 0.5864 - val_accuracy: 0.7028\n",
            "Epoch 38/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6908 - val_loss: 0.5839 - val_accuracy: 0.7098\n",
            "Epoch 39/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6908 - val_loss: 0.5814 - val_accuracy: 0.7098\n",
            "Epoch 40/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6861 - val_loss: 0.5791 - val_accuracy: 0.7133\n",
            "Epoch 41/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6896 - val_loss: 0.5768 - val_accuracy: 0.7238\n",
            "Epoch 42/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6896 - val_loss: 0.5747 - val_accuracy: 0.7238\n",
            "Epoch 43/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6908 - val_loss: 0.5726 - val_accuracy: 0.7168\n",
            "Epoch 44/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.6896 - val_loss: 0.5706 - val_accuracy: 0.7133\n",
            "Epoch 45/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6931 - val_loss: 0.5688 - val_accuracy: 0.7098\n",
            "Epoch 46/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6908 - val_loss: 0.5672 - val_accuracy: 0.7133\n",
            "Epoch 47/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6931 - val_loss: 0.5655 - val_accuracy: 0.7098\n",
            "Epoch 48/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6931 - val_loss: 0.5639 - val_accuracy: 0.7133\n",
            "Epoch 49/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.6908 - val_loss: 0.5624 - val_accuracy: 0.7133\n",
            "Epoch 50/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6954 - val_loss: 0.5610 - val_accuracy: 0.7168\n",
            "Epoch 51/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6908 - val_loss: 0.5596 - val_accuracy: 0.7063\n",
            "Epoch 52/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.6931 - val_loss: 0.5583 - val_accuracy: 0.7098\n",
            "Epoch 53/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.6943 - val_loss: 0.5571 - val_accuracy: 0.7098\n",
            "Epoch 54/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.6954 - val_loss: 0.5558 - val_accuracy: 0.7168\n",
            "Epoch 55/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.6978 - val_loss: 0.5547 - val_accuracy: 0.7168\n",
            "Epoch 56/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.6966 - val_loss: 0.5536 - val_accuracy: 0.7168\n",
            "Epoch 57/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.6966 - val_loss: 0.5525 - val_accuracy: 0.7168\n",
            "Epoch 58/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.6954 - val_loss: 0.5515 - val_accuracy: 0.7203\n",
            "Epoch 59/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6966 - val_loss: 0.5505 - val_accuracy: 0.7273\n",
            "Epoch 60/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.6954 - val_loss: 0.5495 - val_accuracy: 0.7273\n",
            "Epoch 61/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6966 - val_loss: 0.5485 - val_accuracy: 0.7203\n",
            "Epoch 62/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.6966 - val_loss: 0.5476 - val_accuracy: 0.7168\n",
            "Epoch 63/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.6978 - val_loss: 0.5467 - val_accuracy: 0.7168\n",
            "Epoch 64/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7001 - val_loss: 0.5459 - val_accuracy: 0.7168\n",
            "Epoch 65/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7001 - val_loss: 0.5450 - val_accuracy: 0.7203\n",
            "Epoch 66/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7001 - val_loss: 0.5442 - val_accuracy: 0.7238\n",
            "Epoch 67/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7013 - val_loss: 0.5434 - val_accuracy: 0.7238\n",
            "Epoch 68/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7013 - val_loss: 0.5426 - val_accuracy: 0.7203\n",
            "Epoch 69/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.6989 - val_loss: 0.5419 - val_accuracy: 0.7203\n",
            "Epoch 70/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7025 - val_loss: 0.5412 - val_accuracy: 0.7238\n",
            "Epoch 71/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7001 - val_loss: 0.5405 - val_accuracy: 0.7203\n",
            "Epoch 72/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7013 - val_loss: 0.5397 - val_accuracy: 0.7203\n",
            "Epoch 73/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7048 - val_loss: 0.5390 - val_accuracy: 0.7203\n",
            "Epoch 74/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7013 - val_loss: 0.5383 - val_accuracy: 0.7203\n",
            "Epoch 75/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7048 - val_loss: 0.5376 - val_accuracy: 0.7238\n",
            "Epoch 76/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7025 - val_loss: 0.5370 - val_accuracy: 0.7238\n",
            "Epoch 77/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7025 - val_loss: 0.5363 - val_accuracy: 0.7238\n",
            "Epoch 78/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7060 - val_loss: 0.5357 - val_accuracy: 0.7238\n",
            "Epoch 79/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7036 - val_loss: 0.5351 - val_accuracy: 0.7238\n",
            "Epoch 80/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7071 - val_loss: 0.5345 - val_accuracy: 0.7238\n",
            "Epoch 81/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7083 - val_loss: 0.5340 - val_accuracy: 0.7238\n",
            "Epoch 82/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7095 - val_loss: 0.5334 - val_accuracy: 0.7238\n",
            "Epoch 83/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7095 - val_loss: 0.5328 - val_accuracy: 0.7273\n",
            "Epoch 84/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7141 - val_loss: 0.5323 - val_accuracy: 0.7273\n",
            "Epoch 85/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7095 - val_loss: 0.5318 - val_accuracy: 0.7273\n",
            "Epoch 86/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7071 - val_loss: 0.5312 - val_accuracy: 0.7273\n",
            "Epoch 87/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7130 - val_loss: 0.5307 - val_accuracy: 0.7273\n",
            "Epoch 88/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7106 - val_loss: 0.5302 - val_accuracy: 0.7238\n",
            "Epoch 89/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7118 - val_loss: 0.5297 - val_accuracy: 0.7238\n",
            "Epoch 90/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7106 - val_loss: 0.5292 - val_accuracy: 0.7238\n",
            "Epoch 91/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7118 - val_loss: 0.5287 - val_accuracy: 0.7238\n",
            "Epoch 92/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7130 - val_loss: 0.5282 - val_accuracy: 0.7238\n",
            "Epoch 93/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7106 - val_loss: 0.5277 - val_accuracy: 0.7238\n",
            "Epoch 94/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7106 - val_loss: 0.5272 - val_accuracy: 0.7238\n",
            "Epoch 95/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7130 - val_loss: 0.5268 - val_accuracy: 0.7238\n",
            "Epoch 96/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7118 - val_loss: 0.5263 - val_accuracy: 0.7238\n",
            "Epoch 97/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7118 - val_loss: 0.5258 - val_accuracy: 0.7238\n",
            "Epoch 98/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7106 - val_loss: 0.5254 - val_accuracy: 0.7238\n",
            "Epoch 99/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7130 - val_loss: 0.5249 - val_accuracy: 0.7238\n",
            "Epoch 100/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7130 - val_loss: 0.5244 - val_accuracy: 0.7273\n",
            "Epoch 101/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7130 - val_loss: 0.5239 - val_accuracy: 0.7273\n",
            "Epoch 102/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7141 - val_loss: 0.5235 - val_accuracy: 0.7273\n",
            "Epoch 103/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7141 - val_loss: 0.5231 - val_accuracy: 0.7273\n",
            "Epoch 104/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7141 - val_loss: 0.5226 - val_accuracy: 0.7273\n",
            "Epoch 105/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7141 - val_loss: 0.5221 - val_accuracy: 0.7273\n",
            "Epoch 106/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.7141 - val_loss: 0.5217 - val_accuracy: 0.7273\n",
            "Epoch 107/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.7130 - val_loss: 0.5213 - val_accuracy: 0.7273\n",
            "Epoch 108/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7141 - val_loss: 0.5209 - val_accuracy: 0.7273\n",
            "Epoch 109/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7141 - val_loss: 0.5205 - val_accuracy: 0.7273\n",
            "Epoch 110/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7141 - val_loss: 0.5201 - val_accuracy: 0.7273\n",
            "Epoch 111/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5492 - accuracy: 0.7141 - val_loss: 0.5198 - val_accuracy: 0.7273\n",
            "Epoch 112/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7153 - val_loss: 0.5193 - val_accuracy: 0.7273\n",
            "Epoch 113/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7165 - val_loss: 0.5191 - val_accuracy: 0.7273\n",
            "Epoch 114/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.7165 - val_loss: 0.5187 - val_accuracy: 0.7273\n",
            "Epoch 115/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.7188 - val_loss: 0.5183 - val_accuracy: 0.7273\n",
            "Epoch 116/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.7165 - val_loss: 0.5179 - val_accuracy: 0.7273\n",
            "Epoch 117/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7176 - val_loss: 0.5176 - val_accuracy: 0.7273\n",
            "Epoch 118/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7188 - val_loss: 0.5171 - val_accuracy: 0.7273\n",
            "Epoch 119/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.7188 - val_loss: 0.5168 - val_accuracy: 0.7273\n",
            "Epoch 120/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5465 - accuracy: 0.7200 - val_loss: 0.5164 - val_accuracy: 0.7273\n",
            "Epoch 121/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.7223 - val_loss: 0.5160 - val_accuracy: 0.7273\n",
            "Epoch 122/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7211 - val_loss: 0.5156 - val_accuracy: 0.7273\n",
            "Epoch 123/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.7188 - val_loss: 0.5152 - val_accuracy: 0.7273\n",
            "Epoch 124/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7211 - val_loss: 0.5147 - val_accuracy: 0.7273\n",
            "Epoch 125/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5450 - accuracy: 0.7211 - val_loss: 0.5143 - val_accuracy: 0.7308\n",
            "Epoch 126/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.7211 - val_loss: 0.5141 - val_accuracy: 0.7308\n",
            "Epoch 127/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7235 - val_loss: 0.5138 - val_accuracy: 0.7308\n",
            "Epoch 128/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7235 - val_loss: 0.5135 - val_accuracy: 0.7308\n",
            "Epoch 129/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7211 - val_loss: 0.5131 - val_accuracy: 0.7308\n",
            "Epoch 130/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7223 - val_loss: 0.5128 - val_accuracy: 0.7308\n",
            "Epoch 131/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7258 - val_loss: 0.5125 - val_accuracy: 0.7308\n",
            "Epoch 132/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7258 - val_loss: 0.5121 - val_accuracy: 0.7343\n",
            "Epoch 133/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7270 - val_loss: 0.5118 - val_accuracy: 0.7343\n",
            "Epoch 134/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7246 - val_loss: 0.5116 - val_accuracy: 0.7343\n",
            "Epoch 135/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5423 - accuracy: 0.7235 - val_loss: 0.5112 - val_accuracy: 0.7413\n",
            "Epoch 136/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7235 - val_loss: 0.5110 - val_accuracy: 0.7378\n",
            "Epoch 137/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7258 - val_loss: 0.5106 - val_accuracy: 0.7308\n",
            "Epoch 138/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7223 - val_loss: 0.5103 - val_accuracy: 0.7378\n",
            "Epoch 139/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7246 - val_loss: 0.5100 - val_accuracy: 0.7378\n",
            "Epoch 140/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7246 - val_loss: 0.5097 - val_accuracy: 0.7378\n",
            "Epoch 141/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7246 - val_loss: 0.5094 - val_accuracy: 0.7378\n",
            "Epoch 142/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7293 - val_loss: 0.5092 - val_accuracy: 0.7378\n",
            "Epoch 143/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7246 - val_loss: 0.5089 - val_accuracy: 0.7378\n",
            "Epoch 144/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7270 - val_loss: 0.5085 - val_accuracy: 0.7378\n",
            "Epoch 145/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7258 - val_loss: 0.5082 - val_accuracy: 0.7378\n",
            "Epoch 146/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7246 - val_loss: 0.5080 - val_accuracy: 0.7413\n",
            "Epoch 147/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7258 - val_loss: 0.5078 - val_accuracy: 0.7413\n",
            "Epoch 148/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7281 - val_loss: 0.5075 - val_accuracy: 0.7413\n",
            "Epoch 149/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7270 - val_loss: 0.5074 - val_accuracy: 0.7413\n",
            "Epoch 150/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7305 - val_loss: 0.5071 - val_accuracy: 0.7413\n",
            "Epoch 151/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7305 - val_loss: 0.5069 - val_accuracy: 0.7378\n",
            "Epoch 152/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7223 - val_loss: 0.5065 - val_accuracy: 0.7413\n",
            "Epoch 153/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7293 - val_loss: 0.5063 - val_accuracy: 0.7483\n",
            "Epoch 154/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7305 - val_loss: 0.5059 - val_accuracy: 0.7413\n",
            "Epoch 155/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7281 - val_loss: 0.5059 - val_accuracy: 0.7378\n",
            "Epoch 156/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7281 - val_loss: 0.5055 - val_accuracy: 0.7413\n",
            "Epoch 157/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7293 - val_loss: 0.5051 - val_accuracy: 0.7413\n",
            "Epoch 158/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7305 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 159/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7293 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 160/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7305 - val_loss: 0.5040 - val_accuracy: 0.7413\n",
            "Epoch 161/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7328 - val_loss: 0.5037 - val_accuracy: 0.7413\n",
            "Epoch 162/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7316 - val_loss: 0.5034 - val_accuracy: 0.7413\n",
            "Epoch 163/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7340 - val_loss: 0.5030 - val_accuracy: 0.7483\n",
            "Epoch 164/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7293 - val_loss: 0.5029 - val_accuracy: 0.7483\n",
            "Epoch 165/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7305 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 166/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7316 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 167/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7340 - val_loss: 0.5019 - val_accuracy: 0.7483\n",
            "Epoch 168/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7316 - val_loss: 0.5015 - val_accuracy: 0.7483\n",
            "Epoch 169/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7328 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 170/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7316 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 171/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7351 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
            "Epoch 172/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7375 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
            "Epoch 173/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7363 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
            "Epoch 174/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7351 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
            "Epoch 175/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7363 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 176/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7398 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 177/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7363 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 178/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7375 - val_loss: 0.4992 - val_accuracy: 0.7483\n",
            "Epoch 179/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7375 - val_loss: 0.4988 - val_accuracy: 0.7483\n",
            "Epoch 180/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7363 - val_loss: 0.4984 - val_accuracy: 0.7483\n",
            "Epoch 181/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7363 - val_loss: 0.4983 - val_accuracy: 0.7483\n",
            "Epoch 182/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7363 - val_loss: 0.4981 - val_accuracy: 0.7483\n",
            "Epoch 183/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7375 - val_loss: 0.4979 - val_accuracy: 0.7483\n",
            "Epoch 184/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7375 - val_loss: 0.4976 - val_accuracy: 0.7483\n",
            "Epoch 185/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7398 - val_loss: 0.4975 - val_accuracy: 0.7483\n",
            "Epoch 186/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7398 - val_loss: 0.4971 - val_accuracy: 0.7483\n",
            "Epoch 187/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7386 - val_loss: 0.4968 - val_accuracy: 0.7483\n",
            "Epoch 188/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7398 - val_loss: 0.4967 - val_accuracy: 0.7483\n",
            "Epoch 189/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7386 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
            "Epoch 190/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7386 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
            "Epoch 191/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7398 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
            "Epoch 192/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7398 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
            "Epoch 193/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7398 - val_loss: 0.4956 - val_accuracy: 0.7483\n",
            "Epoch 194/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7421 - val_loss: 0.4953 - val_accuracy: 0.7483\n",
            "Epoch 195/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7421 - val_loss: 0.4950 - val_accuracy: 0.7483\n",
            "Epoch 196/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7398 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 197/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7398 - val_loss: 0.4947 - val_accuracy: 0.7483\n",
            "Epoch 198/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7410 - val_loss: 0.4943 - val_accuracy: 0.7483\n",
            "Epoch 199/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7421 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
            "Epoch 200/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7410 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
            "Epoch 201/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7386 - val_loss: 0.4940 - val_accuracy: 0.7483\n",
            "Epoch 202/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7410 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
            "Epoch 203/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7433 - val_loss: 0.4939 - val_accuracy: 0.7517\n",
            "Epoch 204/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7433 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
            "Epoch 205/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7433 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
            "Epoch 206/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7398 - val_loss: 0.4931 - val_accuracy: 0.7517\n",
            "Epoch 207/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7421 - val_loss: 0.4930 - val_accuracy: 0.7587\n",
            "Epoch 208/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7445 - val_loss: 0.4926 - val_accuracy: 0.7622\n",
            "Epoch 209/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7421 - val_loss: 0.4925 - val_accuracy: 0.7587\n",
            "Epoch 210/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7421 - val_loss: 0.4923 - val_accuracy: 0.7622\n",
            "Epoch 211/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7410 - val_loss: 0.4920 - val_accuracy: 0.7622\n",
            "Epoch 212/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7445 - val_loss: 0.4919 - val_accuracy: 0.7622\n",
            "Epoch 213/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7421 - val_loss: 0.4916 - val_accuracy: 0.7622\n",
            "Epoch 214/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7410 - val_loss: 0.4916 - val_accuracy: 0.7622\n",
            "Epoch 215/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7445 - val_loss: 0.4914 - val_accuracy: 0.7622\n",
            "Epoch 216/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7433 - val_loss: 0.4911 - val_accuracy: 0.7622\n",
            "Epoch 217/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7445 - val_loss: 0.4909 - val_accuracy: 0.7622\n",
            "Epoch 218/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7445 - val_loss: 0.4909 - val_accuracy: 0.7622\n",
            "Epoch 219/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7480 - val_loss: 0.4907 - val_accuracy: 0.7622\n",
            "Epoch 220/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7456 - val_loss: 0.4905 - val_accuracy: 0.7622\n",
            "Epoch 221/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7491 - val_loss: 0.4905 - val_accuracy: 0.7622\n",
            "Epoch 222/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7480 - val_loss: 0.4905 - val_accuracy: 0.7622\n",
            "Epoch 223/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7468 - val_loss: 0.4903 - val_accuracy: 0.7587\n",
            "Epoch 224/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7503 - val_loss: 0.4901 - val_accuracy: 0.7622\n",
            "Epoch 225/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7480 - val_loss: 0.4900 - val_accuracy: 0.7622\n",
            "Epoch 226/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7503 - val_loss: 0.4897 - val_accuracy: 0.7587\n",
            "Epoch 227/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7491 - val_loss: 0.4895 - val_accuracy: 0.7587\n",
            "Epoch 228/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7445 - val_loss: 0.4891 - val_accuracy: 0.7622\n",
            "Epoch 229/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7480 - val_loss: 0.4888 - val_accuracy: 0.7622\n",
            "Epoch 230/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7480 - val_loss: 0.4885 - val_accuracy: 0.7622\n",
            "Epoch 231/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7503 - val_loss: 0.4885 - val_accuracy: 0.7622\n",
            "Epoch 232/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7503 - val_loss: 0.4883 - val_accuracy: 0.7622\n",
            "Epoch 233/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7515 - val_loss: 0.4882 - val_accuracy: 0.7622\n",
            "Epoch 234/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7503 - val_loss: 0.4881 - val_accuracy: 0.7622\n",
            "Epoch 235/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7503 - val_loss: 0.4879 - val_accuracy: 0.7622\n",
            "Epoch 236/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5224 - accuracy: 0.7503 - val_loss: 0.4878 - val_accuracy: 0.7622\n",
            "Epoch 237/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7515 - val_loss: 0.4879 - val_accuracy: 0.7622\n",
            "Epoch 238/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7480 - val_loss: 0.4875 - val_accuracy: 0.7622\n",
            "Epoch 239/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7515 - val_loss: 0.4876 - val_accuracy: 0.7622\n",
            "Epoch 240/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7515 - val_loss: 0.4874 - val_accuracy: 0.7657\n",
            "Epoch 241/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7526 - val_loss: 0.4873 - val_accuracy: 0.7657\n",
            "Epoch 242/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7515 - val_loss: 0.4870 - val_accuracy: 0.7657\n",
            "Epoch 243/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7491 - val_loss: 0.4867 - val_accuracy: 0.7657\n",
            "Epoch 244/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7515 - val_loss: 0.4867 - val_accuracy: 0.7657\n",
            "Epoch 245/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7515 - val_loss: 0.4865 - val_accuracy: 0.7657\n",
            "Epoch 246/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7526 - val_loss: 0.4864 - val_accuracy: 0.7657\n",
            "Epoch 247/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.7526 - val_loss: 0.4862 - val_accuracy: 0.7692\n",
            "Epoch 248/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.7526 - val_loss: 0.4859 - val_accuracy: 0.7727\n",
            "Epoch 249/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.7515 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 250/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7526 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 251/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7550 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 252/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7550 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 253/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7538 - val_loss: 0.4855 - val_accuracy: 0.7692\n",
            "Epoch 254/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7515 - val_loss: 0.4853 - val_accuracy: 0.7692\n",
            "Epoch 255/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7550 - val_loss: 0.4851 - val_accuracy: 0.7692\n",
            "Epoch 256/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7561 - val_loss: 0.4850 - val_accuracy: 0.7692\n",
            "Epoch 257/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7526 - val_loss: 0.4848 - val_accuracy: 0.7692\n",
            "Epoch 258/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7526 - val_loss: 0.4847 - val_accuracy: 0.7692\n",
            "Epoch 259/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7538 - val_loss: 0.4845 - val_accuracy: 0.7692\n",
            "Epoch 260/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7550 - val_loss: 0.4845 - val_accuracy: 0.7692\n",
            "Epoch 261/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7550 - val_loss: 0.4841 - val_accuracy: 0.7692\n",
            "Epoch 262/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7538 - val_loss: 0.4840 - val_accuracy: 0.7657\n",
            "Epoch 263/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7538 - val_loss: 0.4836 - val_accuracy: 0.7657\n",
            "Epoch 264/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7550 - val_loss: 0.4835 - val_accuracy: 0.7657\n",
            "Epoch 265/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7561 - val_loss: 0.4832 - val_accuracy: 0.7657\n",
            "Epoch 266/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7561 - val_loss: 0.4831 - val_accuracy: 0.7657\n",
            "Epoch 267/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7550 - val_loss: 0.4829 - val_accuracy: 0.7657\n",
            "Epoch 268/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7561 - val_loss: 0.4827 - val_accuracy: 0.7657\n",
            "Epoch 269/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7561 - val_loss: 0.4827 - val_accuracy: 0.7657\n",
            "Epoch 270/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7550 - val_loss: 0.4824 - val_accuracy: 0.7657\n",
            "Epoch 271/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7573 - val_loss: 0.4823 - val_accuracy: 0.7657\n",
            "Epoch 272/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7550 - val_loss: 0.4819 - val_accuracy: 0.7657\n",
            "Epoch 273/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7585 - val_loss: 0.4820 - val_accuracy: 0.7657\n",
            "Epoch 274/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7573 - val_loss: 0.4819 - val_accuracy: 0.7657\n",
            "Epoch 275/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7573 - val_loss: 0.4817 - val_accuracy: 0.7657\n",
            "Epoch 276/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7596 - val_loss: 0.4819 - val_accuracy: 0.7657\n",
            "Epoch 277/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7550 - val_loss: 0.4816 - val_accuracy: 0.7622\n",
            "Epoch 278/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7550 - val_loss: 0.4817 - val_accuracy: 0.7622\n",
            "Epoch 279/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7550 - val_loss: 0.4815 - val_accuracy: 0.7622\n",
            "Epoch 280/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7550 - val_loss: 0.4814 - val_accuracy: 0.7587\n",
            "Epoch 281/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7538 - val_loss: 0.4812 - val_accuracy: 0.7587\n",
            "Epoch 282/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7538 - val_loss: 0.4810 - val_accuracy: 0.7622\n",
            "Epoch 283/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7526 - val_loss: 0.4807 - val_accuracy: 0.7622\n",
            "Epoch 284/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7526 - val_loss: 0.4803 - val_accuracy: 0.7622\n",
            "Epoch 285/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7526 - val_loss: 0.4803 - val_accuracy: 0.7622\n",
            "Epoch 286/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7526 - val_loss: 0.4804 - val_accuracy: 0.7622\n",
            "Epoch 287/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7526 - val_loss: 0.4803 - val_accuracy: 0.7622\n",
            "Epoch 288/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7526 - val_loss: 0.4797 - val_accuracy: 0.7622\n",
            "Epoch 289/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7526 - val_loss: 0.4796 - val_accuracy: 0.7622\n",
            "Epoch 290/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7550 - val_loss: 0.4793 - val_accuracy: 0.7622\n",
            "Epoch 291/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7550 - val_loss: 0.4793 - val_accuracy: 0.7622\n",
            "Epoch 292/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7515 - val_loss: 0.4790 - val_accuracy: 0.7622\n",
            "Epoch 293/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7538 - val_loss: 0.4792 - val_accuracy: 0.7622\n",
            "Epoch 294/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7526 - val_loss: 0.4790 - val_accuracy: 0.7622\n",
            "Epoch 295/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7538 - val_loss: 0.4786 - val_accuracy: 0.7622\n",
            "Epoch 296/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.7585 - val_loss: 0.4786 - val_accuracy: 0.7622\n",
            "Epoch 297/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7538 - val_loss: 0.4785 - val_accuracy: 0.7622\n",
            "Epoch 298/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7585 - val_loss: 0.4786 - val_accuracy: 0.7622\n",
            "Epoch 299/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7573 - val_loss: 0.4783 - val_accuracy: 0.7622\n",
            "Epoch 300/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7538 - val_loss: 0.4780 - val_accuracy: 0.7622\n",
            "Epoch 301/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7550 - val_loss: 0.4779 - val_accuracy: 0.7622\n",
            "Epoch 302/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7550 - val_loss: 0.4777 - val_accuracy: 0.7692\n",
            "Epoch 303/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7573 - val_loss: 0.4777 - val_accuracy: 0.7622\n",
            "Epoch 304/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7526 - val_loss: 0.4775 - val_accuracy: 0.7692\n",
            "Epoch 305/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7550 - val_loss: 0.4774 - val_accuracy: 0.7692\n",
            "Epoch 306/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7526 - val_loss: 0.4774 - val_accuracy: 0.7692\n",
            "Epoch 307/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7526 - val_loss: 0.4773 - val_accuracy: 0.7692\n",
            "Epoch 308/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7561 - val_loss: 0.4773 - val_accuracy: 0.7692\n",
            "Epoch 309/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7573 - val_loss: 0.4770 - val_accuracy: 0.7692\n",
            "Epoch 310/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7561 - val_loss: 0.4772 - val_accuracy: 0.7692\n",
            "Epoch 311/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7561 - val_loss: 0.4771 - val_accuracy: 0.7657\n",
            "Epoch 312/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7550 - val_loss: 0.4771 - val_accuracy: 0.7657\n",
            "Epoch 313/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7585 - val_loss: 0.4769 - val_accuracy: 0.7657\n",
            "Epoch 314/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7550 - val_loss: 0.4764 - val_accuracy: 0.7657\n",
            "Epoch 315/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7573 - val_loss: 0.4761 - val_accuracy: 0.7657\n",
            "Epoch 316/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7573 - val_loss: 0.4761 - val_accuracy: 0.7692\n",
            "Epoch 317/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7596 - val_loss: 0.4760 - val_accuracy: 0.7657\n",
            "Epoch 318/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7561 - val_loss: 0.4761 - val_accuracy: 0.7692\n",
            "Epoch 319/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7585 - val_loss: 0.4757 - val_accuracy: 0.7692\n",
            "Epoch 320/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7596 - val_loss: 0.4755 - val_accuracy: 0.7692\n",
            "Epoch 321/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7585 - val_loss: 0.4752 - val_accuracy: 0.7692\n",
            "Epoch 322/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7596 - val_loss: 0.4752 - val_accuracy: 0.7692\n",
            "Epoch 323/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7573 - val_loss: 0.4751 - val_accuracy: 0.7692\n",
            "Epoch 324/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7631 - val_loss: 0.4747 - val_accuracy: 0.7657\n",
            "Epoch 325/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7561 - val_loss: 0.4747 - val_accuracy: 0.7692\n",
            "Epoch 326/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7620 - val_loss: 0.4750 - val_accuracy: 0.7692\n",
            "Epoch 327/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7596 - val_loss: 0.4748 - val_accuracy: 0.7692\n",
            "Epoch 328/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7585 - val_loss: 0.4748 - val_accuracy: 0.7692\n",
            "Epoch 329/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7620 - val_loss: 0.4746 - val_accuracy: 0.7657\n",
            "Epoch 330/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7585 - val_loss: 0.4745 - val_accuracy: 0.7657\n",
            "Epoch 331/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7608 - val_loss: 0.4741 - val_accuracy: 0.7657\n",
            "Epoch 332/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7573 - val_loss: 0.4742 - val_accuracy: 0.7622\n",
            "Epoch 333/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7573 - val_loss: 0.4743 - val_accuracy: 0.7657\n",
            "Epoch 334/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7620 - val_loss: 0.4738 - val_accuracy: 0.7622\n",
            "Epoch 335/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7596 - val_loss: 0.4739 - val_accuracy: 0.7657\n",
            "Epoch 336/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7631 - val_loss: 0.4738 - val_accuracy: 0.7657\n",
            "Epoch 337/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7608 - val_loss: 0.4730 - val_accuracy: 0.7692\n",
            "Epoch 338/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7573 - val_loss: 0.4734 - val_accuracy: 0.7692\n",
            "Epoch 339/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7585 - val_loss: 0.4735 - val_accuracy: 0.7657\n",
            "Epoch 340/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7585 - val_loss: 0.4737 - val_accuracy: 0.7692\n",
            "Epoch 341/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7631 - val_loss: 0.4732 - val_accuracy: 0.7692\n",
            "Epoch 342/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7608 - val_loss: 0.4727 - val_accuracy: 0.7727\n",
            "Epoch 343/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.7573 - val_loss: 0.4727 - val_accuracy: 0.7727\n",
            "Epoch 344/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7620 - val_loss: 0.4729 - val_accuracy: 0.7727\n",
            "Epoch 345/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7631 - val_loss: 0.4730 - val_accuracy: 0.7727\n",
            "Epoch 346/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7596 - val_loss: 0.4728 - val_accuracy: 0.7727\n",
            "Epoch 347/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7631 - val_loss: 0.4726 - val_accuracy: 0.7727\n",
            "Epoch 348/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7620 - val_loss: 0.4722 - val_accuracy: 0.7727\n",
            "Epoch 349/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7631 - val_loss: 0.4727 - val_accuracy: 0.7727\n",
            "Epoch 350/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7608 - val_loss: 0.4727 - val_accuracy: 0.7762\n",
            "Epoch 351/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7608 - val_loss: 0.4723 - val_accuracy: 0.7762\n",
            "Epoch 352/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.7608 - val_loss: 0.4720 - val_accuracy: 0.7727\n",
            "Epoch 353/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5039 - accuracy: 0.7608 - val_loss: 0.4716 - val_accuracy: 0.7762\n",
            "Epoch 354/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7550 - val_loss: 0.4719 - val_accuracy: 0.7762\n",
            "Epoch 355/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7608 - val_loss: 0.4715 - val_accuracy: 0.7797\n",
            "Epoch 356/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7631 - val_loss: 0.4711 - val_accuracy: 0.7762\n",
            "Epoch 357/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7620 - val_loss: 0.4714 - val_accuracy: 0.7797\n",
            "Epoch 358/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7596 - val_loss: 0.4720 - val_accuracy: 0.7762\n",
            "Epoch 359/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7596 - val_loss: 0.4720 - val_accuracy: 0.7692\n",
            "Epoch 360/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7631 - val_loss: 0.4719 - val_accuracy: 0.7727\n",
            "Epoch 361/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7585 - val_loss: 0.4715 - val_accuracy: 0.7762\n",
            "Epoch 362/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7585 - val_loss: 0.4712 - val_accuracy: 0.7762\n",
            "Epoch 363/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7573 - val_loss: 0.4705 - val_accuracy: 0.7832\n",
            "Epoch 364/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.7596 - val_loss: 0.4708 - val_accuracy: 0.7797\n",
            "Epoch 365/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7585 - val_loss: 0.4709 - val_accuracy: 0.7762\n",
            "Epoch 366/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7550 - val_loss: 0.4703 - val_accuracy: 0.7797\n",
            "Epoch 367/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7550 - val_loss: 0.4702 - val_accuracy: 0.7832\n",
            "Epoch 368/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7573 - val_loss: 0.4703 - val_accuracy: 0.7832\n",
            "Epoch 369/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7561 - val_loss: 0.4706 - val_accuracy: 0.7762\n",
            "Epoch 370/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7550 - val_loss: 0.4706 - val_accuracy: 0.7762\n",
            "Epoch 371/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7596 - val_loss: 0.4711 - val_accuracy: 0.7762\n",
            "Epoch 372/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7596 - val_loss: 0.4709 - val_accuracy: 0.7762\n",
            "Epoch 373/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7538 - val_loss: 0.4701 - val_accuracy: 0.7797\n",
            "Epoch 374/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7550 - val_loss: 0.4708 - val_accuracy: 0.7762\n",
            "Epoch 375/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7573 - val_loss: 0.4706 - val_accuracy: 0.7762\n",
            "Epoch 376/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7573 - val_loss: 0.4703 - val_accuracy: 0.7797\n",
            "Epoch 377/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7585 - val_loss: 0.4699 - val_accuracy: 0.7797\n",
            "Epoch 378/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7538 - val_loss: 0.4699 - val_accuracy: 0.7797\n",
            "Epoch 379/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7573 - val_loss: 0.4703 - val_accuracy: 0.7797\n",
            "Epoch 380/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7573 - val_loss: 0.4701 - val_accuracy: 0.7762\n",
            "Epoch 381/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7573 - val_loss: 0.4703 - val_accuracy: 0.7762\n",
            "Epoch 382/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7550 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
            "Epoch 383/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7596 - val_loss: 0.4700 - val_accuracy: 0.7762\n",
            "Epoch 384/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7550 - val_loss: 0.4697 - val_accuracy: 0.7762\n",
            "Epoch 385/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7538 - val_loss: 0.4697 - val_accuracy: 0.7762\n",
            "Epoch 386/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7561 - val_loss: 0.4696 - val_accuracy: 0.7762\n",
            "Epoch 387/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7526 - val_loss: 0.4702 - val_accuracy: 0.7797\n",
            "Epoch 388/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7538 - val_loss: 0.4701 - val_accuracy: 0.7762\n",
            "Epoch 389/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7526 - val_loss: 0.4704 - val_accuracy: 0.7797\n",
            "Epoch 390/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7526 - val_loss: 0.4699 - val_accuracy: 0.7762\n",
            "Epoch 391/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7526 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
            "Epoch 392/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7538 - val_loss: 0.4698 - val_accuracy: 0.7762\n",
            "Epoch 393/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7561 - val_loss: 0.4693 - val_accuracy: 0.7832\n",
            "Epoch 394/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7526 - val_loss: 0.4698 - val_accuracy: 0.7762\n",
            "Epoch 395/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7573 - val_loss: 0.4696 - val_accuracy: 0.7797\n",
            "Epoch 396/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7538 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
            "Epoch 397/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7573 - val_loss: 0.4695 - val_accuracy: 0.7797\n",
            "Epoch 398/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7561 - val_loss: 0.4695 - val_accuracy: 0.7762\n",
            "Epoch 399/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7573 - val_loss: 0.4694 - val_accuracy: 0.7797\n",
            "Epoch 400/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7573 - val_loss: 0.4690 - val_accuracy: 0.7832\n",
            "Epoch 401/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7526 - val_loss: 0.4685 - val_accuracy: 0.7832\n",
            "Epoch 402/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7550 - val_loss: 0.4689 - val_accuracy: 0.7832\n",
            "Epoch 403/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7515 - val_loss: 0.4692 - val_accuracy: 0.7762\n",
            "Epoch 404/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7596 - val_loss: 0.4684 - val_accuracy: 0.7832\n",
            "Epoch 405/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7561 - val_loss: 0.4686 - val_accuracy: 0.7832\n",
            "Epoch 406/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7550 - val_loss: 0.4689 - val_accuracy: 0.7832\n",
            "Epoch 407/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7526 - val_loss: 0.4690 - val_accuracy: 0.7867\n",
            "Epoch 408/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7561 - val_loss: 0.4687 - val_accuracy: 0.7867\n",
            "Epoch 409/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7561 - val_loss: 0.4689 - val_accuracy: 0.7867\n",
            "Epoch 410/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7561 - val_loss: 0.4693 - val_accuracy: 0.7832\n",
            "Epoch 411/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7573 - val_loss: 0.4682 - val_accuracy: 0.7867\n",
            "Epoch 412/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7550 - val_loss: 0.4691 - val_accuracy: 0.7797\n",
            "Epoch 413/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7550 - val_loss: 0.4695 - val_accuracy: 0.7867\n",
            "Epoch 414/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7526 - val_loss: 0.4698 - val_accuracy: 0.7832\n",
            "Epoch 415/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7573 - val_loss: 0.4692 - val_accuracy: 0.7867\n",
            "Epoch 416/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7585 - val_loss: 0.4689 - val_accuracy: 0.7832\n",
            "Epoch 417/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7561 - val_loss: 0.4693 - val_accuracy: 0.7867\n",
            "Epoch 418/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7561 - val_loss: 0.4694 - val_accuracy: 0.7832\n",
            "Epoch 419/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7561 - val_loss: 0.4696 - val_accuracy: 0.7832\n",
            "Epoch 420/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7585 - val_loss: 0.4693 - val_accuracy: 0.7797\n",
            "Epoch 421/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7596 - val_loss: 0.4695 - val_accuracy: 0.7797\n",
            "Epoch 422/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7596 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
            "Epoch 423/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7573 - val_loss: 0.4699 - val_accuracy: 0.7797\n",
            "Epoch 424/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7585 - val_loss: 0.4691 - val_accuracy: 0.7797\n",
            "Epoch 425/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7596 - val_loss: 0.4693 - val_accuracy: 0.7797\n",
            "Epoch 426/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7573 - val_loss: 0.4694 - val_accuracy: 0.7832\n",
            "Epoch 427/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7608 - val_loss: 0.4694 - val_accuracy: 0.7797\n",
            "Epoch 428/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7608 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
            "Epoch 429/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7596 - val_loss: 0.4698 - val_accuracy: 0.7832\n",
            "Epoch 430/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7596 - val_loss: 0.4696 - val_accuracy: 0.7797\n",
            "Epoch 431/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7596 - val_loss: 0.4690 - val_accuracy: 0.7867\n",
            "Epoch 432/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7573 - val_loss: 0.4697 - val_accuracy: 0.7797\n",
            "Epoch 433/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7596 - val_loss: 0.4694 - val_accuracy: 0.7797\n",
            "Epoch 434/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7585 - val_loss: 0.4695 - val_accuracy: 0.7797\n",
            "Epoch 435/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7561 - val_loss: 0.4701 - val_accuracy: 0.7797\n",
            "Epoch 436/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7561 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
            "Epoch 437/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7596 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
            "Epoch 438/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7585 - val_loss: 0.4693 - val_accuracy: 0.7797\n",
            "Epoch 439/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7561 - val_loss: 0.4693 - val_accuracy: 0.7797\n",
            "Epoch 440/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7596 - val_loss: 0.4692 - val_accuracy: 0.7832\n",
            "Epoch 441/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7573 - val_loss: 0.4694 - val_accuracy: 0.7762\n",
            "Epoch 442/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7608 - val_loss: 0.4692 - val_accuracy: 0.7797\n",
            "Epoch 443/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7620 - val_loss: 0.4691 - val_accuracy: 0.7762\n",
            "Epoch 444/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7573 - val_loss: 0.4691 - val_accuracy: 0.7727\n",
            "Epoch 445/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7561 - val_loss: 0.4696 - val_accuracy: 0.7762\n",
            "Epoch 446/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7585 - val_loss: 0.4695 - val_accuracy: 0.7762\n",
            "Epoch 447/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7596 - val_loss: 0.4693 - val_accuracy: 0.7762\n",
            "Epoch 448/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7585 - val_loss: 0.4699 - val_accuracy: 0.7762\n",
            "Epoch 449/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7585 - val_loss: 0.4692 - val_accuracy: 0.7762\n",
            "Epoch 450/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7585 - val_loss: 0.4694 - val_accuracy: 0.7762\n",
            "Epoch 451/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7608 - val_loss: 0.4693 - val_accuracy: 0.7762\n",
            "Epoch 452/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7573 - val_loss: 0.4696 - val_accuracy: 0.7762\n",
            "Epoch 453/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7585 - val_loss: 0.4691 - val_accuracy: 0.7727\n",
            "Epoch 454/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7573 - val_loss: 0.4697 - val_accuracy: 0.7727\n",
            "Epoch 455/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7573 - val_loss: 0.4691 - val_accuracy: 0.7762\n",
            "Epoch 456/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7596 - val_loss: 0.4697 - val_accuracy: 0.7727\n",
            "Epoch 457/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7596 - val_loss: 0.4692 - val_accuracy: 0.7762\n",
            "Epoch 458/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7573 - val_loss: 0.4688 - val_accuracy: 0.7727\n",
            "Epoch 459/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7620 - val_loss: 0.4696 - val_accuracy: 0.7762\n",
            "Epoch 460/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7596 - val_loss: 0.4696 - val_accuracy: 0.7692\n",
            "Epoch 461/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7585 - val_loss: 0.4692 - val_accuracy: 0.7692\n",
            "Epoch 462/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7620 - val_loss: 0.4688 - val_accuracy: 0.7762\n",
            "Epoch 463/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7608 - val_loss: 0.4689 - val_accuracy: 0.7762\n",
            "Epoch 464/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7585 - val_loss: 0.4691 - val_accuracy: 0.7762\n",
            "Epoch 465/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7596 - val_loss: 0.4694 - val_accuracy: 0.7762\n",
            "Epoch 466/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7608 - val_loss: 0.4697 - val_accuracy: 0.7762\n",
            "Epoch 467/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7585 - val_loss: 0.4694 - val_accuracy: 0.7762\n",
            "Epoch 468/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7585 - val_loss: 0.4699 - val_accuracy: 0.7762\n",
            "Epoch 469/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7655 - val_loss: 0.4701 - val_accuracy: 0.7692\n",
            "Epoch 470/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7631 - val_loss: 0.4703 - val_accuracy: 0.7692\n",
            "Epoch 471/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7608 - val_loss: 0.4704 - val_accuracy: 0.7692\n",
            "Epoch 472/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7620 - val_loss: 0.4700 - val_accuracy: 0.7692\n",
            "Epoch 473/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7596 - val_loss: 0.4700 - val_accuracy: 0.7762\n",
            "Epoch 474/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7585 - val_loss: 0.4702 - val_accuracy: 0.7692\n",
            "Epoch 475/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7631 - val_loss: 0.4707 - val_accuracy: 0.7692\n",
            "Epoch 476/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7608 - val_loss: 0.4698 - val_accuracy: 0.7692\n",
            "Epoch 477/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7561 - val_loss: 0.4696 - val_accuracy: 0.7762\n",
            "Epoch 478/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7585 - val_loss: 0.4700 - val_accuracy: 0.7762\n",
            "Epoch 479/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7608 - val_loss: 0.4702 - val_accuracy: 0.7797\n",
            "Epoch 480/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7620 - val_loss: 0.4705 - val_accuracy: 0.7797\n",
            "Epoch 481/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7620 - val_loss: 0.4706 - val_accuracy: 0.7692\n",
            "Epoch 482/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7608 - val_loss: 0.4708 - val_accuracy: 0.7692\n",
            "Epoch 483/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7620 - val_loss: 0.4706 - val_accuracy: 0.7727\n",
            "Epoch 484/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7631 - val_loss: 0.4721 - val_accuracy: 0.7692\n",
            "Epoch 485/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.7596 - val_loss: 0.4714 - val_accuracy: 0.7727\n",
            "Epoch 486/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7550 - val_loss: 0.4715 - val_accuracy: 0.7727\n",
            "Epoch 487/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7585 - val_loss: 0.4726 - val_accuracy: 0.7657\n",
            "Epoch 488/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7631 - val_loss: 0.4735 - val_accuracy: 0.7657\n",
            "Epoch 489/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7573 - val_loss: 0.4720 - val_accuracy: 0.7727\n",
            "Epoch 490/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7608 - val_loss: 0.4721 - val_accuracy: 0.7727\n",
            "Epoch 491/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7631 - val_loss: 0.4714 - val_accuracy: 0.7797\n",
            "Epoch 492/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7596 - val_loss: 0.4719 - val_accuracy: 0.7692\n",
            "Epoch 493/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7573 - val_loss: 0.4724 - val_accuracy: 0.7692\n",
            "Epoch 494/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7573 - val_loss: 0.4727 - val_accuracy: 0.7727\n",
            "Epoch 495/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7585 - val_loss: 0.4736 - val_accuracy: 0.7727\n",
            "Epoch 496/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7620 - val_loss: 0.4728 - val_accuracy: 0.7727\n",
            "Epoch 497/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7620 - val_loss: 0.4729 - val_accuracy: 0.7727\n",
            "Epoch 498/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7620 - val_loss: 0.4723 - val_accuracy: 0.7727\n",
            "Epoch 499/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7608 - val_loss: 0.4729 - val_accuracy: 0.7692\n",
            "Epoch 500/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7608 - val_loss: 0.4729 - val_accuracy: 0.7692\n",
            "Epoch 501/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7643 - val_loss: 0.4740 - val_accuracy: 0.7727\n",
            "Epoch 502/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7631 - val_loss: 0.4739 - val_accuracy: 0.7692\n",
            "Epoch 503/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7620 - val_loss: 0.4747 - val_accuracy: 0.7727\n",
            "Epoch 504/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7631 - val_loss: 0.4734 - val_accuracy: 0.7727\n",
            "Epoch 505/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7631 - val_loss: 0.4742 - val_accuracy: 0.7692\n",
            "Epoch 506/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7596 - val_loss: 0.4733 - val_accuracy: 0.7762\n",
            "Epoch 507/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7620 - val_loss: 0.4722 - val_accuracy: 0.7762\n",
            "Epoch 508/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7573 - val_loss: 0.4723 - val_accuracy: 0.7762\n",
            "Epoch 509/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7631 - val_loss: 0.4725 - val_accuracy: 0.7727\n",
            "Epoch 510/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7596 - val_loss: 0.4739 - val_accuracy: 0.7692\n",
            "Epoch 511/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7643 - val_loss: 0.4741 - val_accuracy: 0.7692\n",
            "Epoch 512/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7585 - val_loss: 0.4742 - val_accuracy: 0.7692\n",
            "Epoch 513/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7608 - val_loss: 0.4741 - val_accuracy: 0.7692\n",
            "Epoch 514/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7596 - val_loss: 0.4724 - val_accuracy: 0.7762\n",
            "Epoch 515/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7620 - val_loss: 0.4728 - val_accuracy: 0.7727\n",
            "Epoch 516/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7596 - val_loss: 0.4737 - val_accuracy: 0.7727\n",
            "Epoch 517/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7608 - val_loss: 0.4745 - val_accuracy: 0.7657\n",
            "Epoch 518/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7596 - val_loss: 0.4739 - val_accuracy: 0.7657\n",
            "Epoch 519/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7608 - val_loss: 0.4736 - val_accuracy: 0.7727\n",
            "Epoch 520/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7585 - val_loss: 0.4742 - val_accuracy: 0.7727\n",
            "Epoch 521/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7585 - val_loss: 0.4742 - val_accuracy: 0.7657\n",
            "Epoch 522/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7608 - val_loss: 0.4745 - val_accuracy: 0.7657\n",
            "Epoch 523/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7620 - val_loss: 0.4750 - val_accuracy: 0.7692\n",
            "Epoch 524/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7631 - val_loss: 0.4742 - val_accuracy: 0.7692\n",
            "Epoch 525/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7596 - val_loss: 0.4739 - val_accuracy: 0.7727\n",
            "Epoch 526/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7608 - val_loss: 0.4748 - val_accuracy: 0.7692\n",
            "Epoch 527/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7643 - val_loss: 0.4733 - val_accuracy: 0.7797\n",
            "Epoch 528/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7608 - val_loss: 0.4728 - val_accuracy: 0.7762\n",
            "Epoch 529/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7620 - val_loss: 0.4738 - val_accuracy: 0.7762\n",
            "Epoch 530/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7620 - val_loss: 0.4749 - val_accuracy: 0.7727\n",
            "Epoch 531/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7631 - val_loss: 0.4743 - val_accuracy: 0.7762\n",
            "Epoch 532/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7620 - val_loss: 0.4746 - val_accuracy: 0.7727\n",
            "Epoch 533/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7596 - val_loss: 0.4751 - val_accuracy: 0.7727\n",
            "Epoch 534/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7596 - val_loss: 0.4740 - val_accuracy: 0.7797\n",
            "Epoch 535/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7643 - val_loss: 0.4746 - val_accuracy: 0.7727\n",
            "Epoch 536/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7643 - val_loss: 0.4736 - val_accuracy: 0.7832\n",
            "Epoch 537/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7631 - val_loss: 0.4720 - val_accuracy: 0.7762\n",
            "Epoch 538/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7643 - val_loss: 0.4738 - val_accuracy: 0.7797\n",
            "Epoch 539/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7608 - val_loss: 0.4754 - val_accuracy: 0.7762\n",
            "Epoch 540/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7620 - val_loss: 0.4735 - val_accuracy: 0.7797\n",
            "Epoch 541/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7620 - val_loss: 0.4756 - val_accuracy: 0.7762\n",
            "Epoch 542/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7643 - val_loss: 0.4758 - val_accuracy: 0.7762\n",
            "Epoch 543/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7678 - val_loss: 0.4743 - val_accuracy: 0.7832\n",
            "Epoch 544/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7678 - val_loss: 0.4749 - val_accuracy: 0.7762\n",
            "Epoch 545/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7666 - val_loss: 0.4758 - val_accuracy: 0.7762\n",
            "Epoch 546/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7608 - val_loss: 0.4764 - val_accuracy: 0.7762\n",
            "Epoch 547/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7596 - val_loss: 0.4764 - val_accuracy: 0.7762\n",
            "Epoch 548/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7643 - val_loss: 0.4757 - val_accuracy: 0.7762\n",
            "Epoch 549/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7608 - val_loss: 0.4757 - val_accuracy: 0.7797\n",
            "Epoch 550/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7608 - val_loss: 0.4747 - val_accuracy: 0.7797\n",
            "Epoch 551/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7620 - val_loss: 0.4729 - val_accuracy: 0.7797\n",
            "Epoch 552/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7655 - val_loss: 0.4758 - val_accuracy: 0.7692\n",
            "Epoch 553/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7620 - val_loss: 0.4755 - val_accuracy: 0.7727\n",
            "Epoch 554/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7631 - val_loss: 0.4769 - val_accuracy: 0.7657\n",
            "Epoch 555/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7608 - val_loss: 0.4764 - val_accuracy: 0.7692\n",
            "Epoch 556/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7631 - val_loss: 0.4766 - val_accuracy: 0.7692\n",
            "Epoch 557/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7620 - val_loss: 0.4764 - val_accuracy: 0.7692\n",
            "Epoch 558/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7643 - val_loss: 0.4759 - val_accuracy: 0.7797\n",
            "Epoch 559/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7666 - val_loss: 0.4761 - val_accuracy: 0.7692\n",
            "Epoch 560/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7631 - val_loss: 0.4758 - val_accuracy: 0.7762\n",
            "Epoch 561/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7643 - val_loss: 0.4761 - val_accuracy: 0.7797\n",
            "Epoch 562/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7620 - val_loss: 0.4764 - val_accuracy: 0.7692\n",
            "Epoch 563/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7655 - val_loss: 0.4742 - val_accuracy: 0.7797\n",
            "Epoch 564/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7643 - val_loss: 0.4745 - val_accuracy: 0.7762\n",
            "Epoch 565/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7643 - val_loss: 0.4754 - val_accuracy: 0.7762\n",
            "Epoch 566/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7655 - val_loss: 0.4754 - val_accuracy: 0.7727\n",
            "Epoch 567/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7608 - val_loss: 0.4759 - val_accuracy: 0.7762\n",
            "Epoch 568/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7643 - val_loss: 0.4772 - val_accuracy: 0.7727\n",
            "Epoch 569/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7631 - val_loss: 0.4763 - val_accuracy: 0.7727\n",
            "Epoch 570/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7596 - val_loss: 0.4775 - val_accuracy: 0.7762\n",
            "Epoch 571/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7655 - val_loss: 0.4762 - val_accuracy: 0.7727\n",
            "Epoch 572/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7666 - val_loss: 0.4768 - val_accuracy: 0.7762\n",
            "Epoch 573/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7655 - val_loss: 0.4760 - val_accuracy: 0.7797\n",
            "Epoch 574/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7655 - val_loss: 0.4754 - val_accuracy: 0.7762\n",
            "Epoch 575/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7643 - val_loss: 0.4769 - val_accuracy: 0.7727\n",
            "Epoch 576/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7655 - val_loss: 0.4781 - val_accuracy: 0.7727\n",
            "Epoch 577/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7655 - val_loss: 0.4755 - val_accuracy: 0.7727\n",
            "Epoch 578/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.7666 - val_loss: 0.4750 - val_accuracy: 0.7727\n",
            "Epoch 579/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.7678 - val_loss: 0.4759 - val_accuracy: 0.7727\n",
            "Epoch 580/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7655 - val_loss: 0.4758 - val_accuracy: 0.7727\n",
            "Epoch 581/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.7608 - val_loss: 0.4777 - val_accuracy: 0.7727\n",
            "Epoch 582/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.7631 - val_loss: 0.4777 - val_accuracy: 0.7727\n",
            "Epoch 583/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7596 - val_loss: 0.4769 - val_accuracy: 0.7762\n",
            "Epoch 584/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.7666 - val_loss: 0.4766 - val_accuracy: 0.7797\n",
            "Epoch 585/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7678 - val_loss: 0.4765 - val_accuracy: 0.7762\n",
            "Epoch 586/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7690 - val_loss: 0.4763 - val_accuracy: 0.7727\n",
            "Epoch 587/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7725 - val_loss: 0.4753 - val_accuracy: 0.7692\n",
            "Epoch 588/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7596 - val_loss: 0.4759 - val_accuracy: 0.7762\n",
            "Epoch 589/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7596 - val_loss: 0.4765 - val_accuracy: 0.7727\n",
            "Epoch 590/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7631 - val_loss: 0.4760 - val_accuracy: 0.7762\n",
            "Epoch 591/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7620 - val_loss: 0.4756 - val_accuracy: 0.7762\n",
            "Epoch 592/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7643 - val_loss: 0.4769 - val_accuracy: 0.7692\n",
            "Epoch 593/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7666 - val_loss: 0.4755 - val_accuracy: 0.7762\n",
            "Epoch 594/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.4769 - val_accuracy: 0.7762\n",
            "Epoch 595/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7620 - val_loss: 0.4784 - val_accuracy: 0.7727\n",
            "Epoch 596/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.7678 - val_loss: 0.4776 - val_accuracy: 0.7727\n",
            "Epoch 597/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7643 - val_loss: 0.4769 - val_accuracy: 0.7797\n",
            "Epoch 598/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7725 - val_loss: 0.4801 - val_accuracy: 0.7692\n",
            "Epoch 599/1200\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7725 - val_loss: 0.4788 - val_accuracy: 0.7692\n",
            "Epoch 600/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7643 - val_loss: 0.4777 - val_accuracy: 0.7727\n",
            "Epoch 601/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7666 - val_loss: 0.4784 - val_accuracy: 0.7727\n",
            "Epoch 602/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7643 - val_loss: 0.4789 - val_accuracy: 0.7727\n",
            "Epoch 603/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7701 - val_loss: 0.4781 - val_accuracy: 0.7797\n",
            "Epoch 604/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7690 - val_loss: 0.4784 - val_accuracy: 0.7762\n",
            "Epoch 605/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7748 - val_loss: 0.4781 - val_accuracy: 0.7727\n",
            "Epoch 606/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7666 - val_loss: 0.4780 - val_accuracy: 0.7692\n",
            "Epoch 607/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7620 - val_loss: 0.4790 - val_accuracy: 0.7692\n",
            "Epoch 608/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7701 - val_loss: 0.4802 - val_accuracy: 0.7692\n",
            "Epoch 609/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7666 - val_loss: 0.4799 - val_accuracy: 0.7727\n",
            "Epoch 610/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7690 - val_loss: 0.4798 - val_accuracy: 0.7762\n",
            "Epoch 611/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7643 - val_loss: 0.4807 - val_accuracy: 0.7692\n",
            "Epoch 612/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7736 - val_loss: 0.4766 - val_accuracy: 0.7797\n",
            "Epoch 613/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7701 - val_loss: 0.4791 - val_accuracy: 0.7727\n",
            "Epoch 614/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7701 - val_loss: 0.4764 - val_accuracy: 0.7797\n",
            "Epoch 615/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7643 - val_loss: 0.4774 - val_accuracy: 0.7797\n",
            "Epoch 616/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7725 - val_loss: 0.4780 - val_accuracy: 0.7797\n",
            "Epoch 617/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7655 - val_loss: 0.4774 - val_accuracy: 0.7797\n",
            "Epoch 618/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7608 - val_loss: 0.4788 - val_accuracy: 0.7727\n",
            "Epoch 619/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7678 - val_loss: 0.4794 - val_accuracy: 0.7727\n",
            "Epoch 620/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7701 - val_loss: 0.4767 - val_accuracy: 0.7762\n",
            "Epoch 621/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7713 - val_loss: 0.4779 - val_accuracy: 0.7762\n",
            "Epoch 622/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4771 - val_accuracy: 0.7762\n",
            "Epoch 623/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7690 - val_loss: 0.4777 - val_accuracy: 0.7762\n",
            "Epoch 624/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7678 - val_loss: 0.4795 - val_accuracy: 0.7727\n",
            "Epoch 625/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7701 - val_loss: 0.4800 - val_accuracy: 0.7762\n",
            "Epoch 626/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7690 - val_loss: 0.4777 - val_accuracy: 0.7762\n",
            "Epoch 627/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7725 - val_loss: 0.4798 - val_accuracy: 0.7832\n",
            "Epoch 628/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7655 - val_loss: 0.4784 - val_accuracy: 0.7762\n",
            "Epoch 629/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7736 - val_loss: 0.4789 - val_accuracy: 0.7797\n",
            "Epoch 630/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7655 - val_loss: 0.4773 - val_accuracy: 0.7762\n",
            "Epoch 631/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7666 - val_loss: 0.4782 - val_accuracy: 0.7762\n",
            "Epoch 632/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7666 - val_loss: 0.4788 - val_accuracy: 0.7762\n",
            "Epoch 633/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7701 - val_loss: 0.4773 - val_accuracy: 0.7762\n",
            "Epoch 634/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7666 - val_loss: 0.4767 - val_accuracy: 0.7762\n",
            "Epoch 635/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7690 - val_loss: 0.4783 - val_accuracy: 0.7762\n",
            "Epoch 636/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7701 - val_loss: 0.4778 - val_accuracy: 0.7762\n",
            "Epoch 637/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7678 - val_loss: 0.4792 - val_accuracy: 0.7762\n",
            "Epoch 638/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7690 - val_loss: 0.4803 - val_accuracy: 0.7727\n",
            "Epoch 639/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7725 - val_loss: 0.4795 - val_accuracy: 0.7762\n",
            "Epoch 640/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7690 - val_loss: 0.4782 - val_accuracy: 0.7762\n",
            "Epoch 641/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7713 - val_loss: 0.4781 - val_accuracy: 0.7762\n",
            "Epoch 642/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7666 - val_loss: 0.4791 - val_accuracy: 0.7797\n",
            "Epoch 643/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7725 - val_loss: 0.4784 - val_accuracy: 0.7797\n",
            "Epoch 644/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7725 - val_loss: 0.4790 - val_accuracy: 0.7797\n",
            "Epoch 645/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7748 - val_loss: 0.4773 - val_accuracy: 0.7762\n",
            "Epoch 646/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7713 - val_loss: 0.4781 - val_accuracy: 0.7762\n",
            "Epoch 647/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4795 - val_accuracy: 0.7762\n",
            "Epoch 648/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7701 - val_loss: 0.4802 - val_accuracy: 0.7762\n",
            "Epoch 649/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7701 - val_loss: 0.4796 - val_accuracy: 0.7762\n",
            "Epoch 650/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7690 - val_loss: 0.4762 - val_accuracy: 0.7797\n",
            "Epoch 651/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7690 - val_loss: 0.4793 - val_accuracy: 0.7797\n",
            "Epoch 652/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7643 - val_loss: 0.4804 - val_accuracy: 0.7762\n",
            "Epoch 653/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7725 - val_loss: 0.4797 - val_accuracy: 0.7762\n",
            "Epoch 654/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7701 - val_loss: 0.4767 - val_accuracy: 0.7797\n",
            "Epoch 655/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7701 - val_loss: 0.4772 - val_accuracy: 0.7797\n",
            "Epoch 656/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7701 - val_loss: 0.4799 - val_accuracy: 0.7797\n",
            "Epoch 657/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7725 - val_loss: 0.4786 - val_accuracy: 0.7797\n",
            "Epoch 658/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7748 - val_loss: 0.4788 - val_accuracy: 0.7762\n",
            "Epoch 659/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7678 - val_loss: 0.4770 - val_accuracy: 0.7797\n",
            "Epoch 660/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7701 - val_loss: 0.4818 - val_accuracy: 0.7692\n",
            "Epoch 661/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7713 - val_loss: 0.4808 - val_accuracy: 0.7692\n",
            "Epoch 662/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7748 - val_loss: 0.4805 - val_accuracy: 0.7727\n",
            "Epoch 663/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7725 - val_loss: 0.4812 - val_accuracy: 0.7692\n",
            "Epoch 664/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7736 - val_loss: 0.4822 - val_accuracy: 0.7657\n",
            "Epoch 665/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4778 - val_accuracy: 0.7797\n",
            "Epoch 666/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7771 - val_loss: 0.4809 - val_accuracy: 0.7692\n",
            "Epoch 667/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7713 - val_loss: 0.4798 - val_accuracy: 0.7762\n",
            "Epoch 668/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7725 - val_loss: 0.4813 - val_accuracy: 0.7692\n",
            "Epoch 669/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7725 - val_loss: 0.4812 - val_accuracy: 0.7692\n",
            "Epoch 670/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7748 - val_loss: 0.4786 - val_accuracy: 0.7762\n",
            "Epoch 671/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7701 - val_loss: 0.4771 - val_accuracy: 0.7797\n",
            "Epoch 672/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7701 - val_loss: 0.4788 - val_accuracy: 0.7762\n",
            "Epoch 673/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4809 - val_accuracy: 0.7727\n",
            "Epoch 674/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7725 - val_loss: 0.4798 - val_accuracy: 0.7762\n",
            "Epoch 675/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7701 - val_loss: 0.4800 - val_accuracy: 0.7727\n",
            "Epoch 676/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7678 - val_loss: 0.4813 - val_accuracy: 0.7692\n",
            "Epoch 677/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7678 - val_loss: 0.4805 - val_accuracy: 0.7762\n",
            "Epoch 678/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7736 - val_loss: 0.4807 - val_accuracy: 0.7692\n",
            "Epoch 679/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7771 - val_loss: 0.4786 - val_accuracy: 0.7762\n",
            "Epoch 680/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7783 - val_loss: 0.4792 - val_accuracy: 0.7692\n",
            "Epoch 681/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7690 - val_loss: 0.4819 - val_accuracy: 0.7622\n",
            "Epoch 682/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4787 - val_accuracy: 0.7727\n",
            "Epoch 683/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7748 - val_loss: 0.4788 - val_accuracy: 0.7727\n",
            "Epoch 684/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7736 - val_loss: 0.4796 - val_accuracy: 0.7727\n",
            "Epoch 685/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7748 - val_loss: 0.4802 - val_accuracy: 0.7692\n",
            "Epoch 686/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7701 - val_loss: 0.4799 - val_accuracy: 0.7727\n",
            "Epoch 687/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7736 - val_loss: 0.4763 - val_accuracy: 0.7762\n",
            "Epoch 688/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7725 - val_loss: 0.4794 - val_accuracy: 0.7727\n",
            "Epoch 689/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7725 - val_loss: 0.4799 - val_accuracy: 0.7692\n",
            "Epoch 690/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7713 - val_loss: 0.4801 - val_accuracy: 0.7727\n",
            "Epoch 691/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7748 - val_loss: 0.4805 - val_accuracy: 0.7692\n",
            "Epoch 692/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7736 - val_loss: 0.4798 - val_accuracy: 0.7727\n",
            "Epoch 693/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7701 - val_loss: 0.4783 - val_accuracy: 0.7657\n",
            "Epoch 694/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7736 - val_loss: 0.4804 - val_accuracy: 0.7692\n",
            "Epoch 695/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4802 - val_accuracy: 0.7762\n",
            "Epoch 696/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7725 - val_loss: 0.4794 - val_accuracy: 0.7657\n",
            "Epoch 697/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7771 - val_loss: 0.4788 - val_accuracy: 0.7657\n",
            "Epoch 698/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7725 - val_loss: 0.4795 - val_accuracy: 0.7727\n",
            "Epoch 699/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7713 - val_loss: 0.4791 - val_accuracy: 0.7727\n",
            "Epoch 700/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7783 - val_loss: 0.4775 - val_accuracy: 0.7692\n",
            "Epoch 701/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.4809 - val_accuracy: 0.7692\n",
            "Epoch 702/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7783 - val_loss: 0.4811 - val_accuracy: 0.7692\n",
            "Epoch 703/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7783 - val_loss: 0.4805 - val_accuracy: 0.7692\n",
            "Epoch 704/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7760 - val_loss: 0.4826 - val_accuracy: 0.7622\n",
            "Epoch 705/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7736 - val_loss: 0.4822 - val_accuracy: 0.7622\n",
            "Epoch 706/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7771 - val_loss: 0.4811 - val_accuracy: 0.7657\n",
            "Epoch 707/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7736 - val_loss: 0.4813 - val_accuracy: 0.7657\n",
            "Epoch 708/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7771 - val_loss: 0.4819 - val_accuracy: 0.7657\n",
            "Epoch 709/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7748 - val_loss: 0.4828 - val_accuracy: 0.7622\n",
            "Epoch 710/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7806 - val_loss: 0.4820 - val_accuracy: 0.7622\n",
            "Epoch 711/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7818 - val_loss: 0.4821 - val_accuracy: 0.7657\n",
            "Epoch 712/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7748 - val_loss: 0.4782 - val_accuracy: 0.7762\n",
            "Epoch 713/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7795 - val_loss: 0.4812 - val_accuracy: 0.7727\n",
            "Epoch 714/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4826 - val_accuracy: 0.7657\n",
            "Epoch 715/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4815 - val_accuracy: 0.7727\n",
            "Epoch 716/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7783 - val_loss: 0.4789 - val_accuracy: 0.7727\n",
            "Epoch 717/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7806 - val_loss: 0.4790 - val_accuracy: 0.7797\n",
            "Epoch 718/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4783 - val_accuracy: 0.7727\n",
            "Epoch 719/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7806 - val_loss: 0.4809 - val_accuracy: 0.7727\n",
            "Epoch 720/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7771 - val_loss: 0.4793 - val_accuracy: 0.7797\n",
            "Epoch 721/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4801 - val_accuracy: 0.7727\n",
            "Epoch 722/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4795 - val_accuracy: 0.7727\n",
            "Epoch 723/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4810 - val_accuracy: 0.7727\n",
            "Epoch 724/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7748 - val_loss: 0.4799 - val_accuracy: 0.7797\n",
            "Epoch 725/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7657\n",
            "Epoch 726/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7748 - val_loss: 0.4841 - val_accuracy: 0.7622\n",
            "Epoch 727/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7748 - val_loss: 0.4827 - val_accuracy: 0.7692\n",
            "Epoch 728/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7841 - val_loss: 0.4794 - val_accuracy: 0.7797\n",
            "Epoch 729/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7748 - val_loss: 0.4831 - val_accuracy: 0.7657\n",
            "Epoch 730/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7748 - val_loss: 0.4814 - val_accuracy: 0.7727\n",
            "Epoch 731/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7771 - val_loss: 0.4803 - val_accuracy: 0.7727\n",
            "Epoch 732/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4807 - val_accuracy: 0.7762\n",
            "Epoch 733/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7771 - val_loss: 0.4822 - val_accuracy: 0.7727\n",
            "Epoch 734/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7818 - val_loss: 0.4811 - val_accuracy: 0.7727\n",
            "Epoch 735/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7806 - val_loss: 0.4865 - val_accuracy: 0.7692\n",
            "Epoch 736/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7806 - val_loss: 0.4840 - val_accuracy: 0.7657\n",
            "Epoch 737/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4827 - val_accuracy: 0.7657\n",
            "Epoch 738/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7771 - val_loss: 0.4871 - val_accuracy: 0.7727\n",
            "Epoch 739/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7806 - val_loss: 0.4820 - val_accuracy: 0.7692\n",
            "Epoch 740/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7783 - val_loss: 0.4824 - val_accuracy: 0.7692\n",
            "Epoch 741/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7713 - val_loss: 0.4840 - val_accuracy: 0.7657\n",
            "Epoch 742/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7783 - val_loss: 0.4837 - val_accuracy: 0.7692\n",
            "Epoch 743/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7783 - val_loss: 0.4821 - val_accuracy: 0.7622\n",
            "Epoch 744/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7771 - val_loss: 0.4831 - val_accuracy: 0.7727\n",
            "Epoch 745/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7748 - val_loss: 0.4811 - val_accuracy: 0.7727\n",
            "Epoch 746/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7736 - val_loss: 0.4820 - val_accuracy: 0.7727\n",
            "Epoch 747/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4831 - val_accuracy: 0.7692\n",
            "Epoch 748/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7657\n",
            "Epoch 749/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7853 - val_loss: 0.4838 - val_accuracy: 0.7727\n",
            "Epoch 750/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4847 - val_accuracy: 0.7657\n",
            "Epoch 751/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7783 - val_loss: 0.4813 - val_accuracy: 0.7657\n",
            "Epoch 752/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7771 - val_loss: 0.4838 - val_accuracy: 0.7657\n",
            "Epoch 753/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7748 - val_loss: 0.4846 - val_accuracy: 0.7727\n",
            "Epoch 754/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7727\n",
            "Epoch 755/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7748 - val_loss: 0.4843 - val_accuracy: 0.7762\n",
            "Epoch 756/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7806 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
            "Epoch 757/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7806 - val_loss: 0.4834 - val_accuracy: 0.7692\n",
            "Epoch 758/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7818 - val_loss: 0.4827 - val_accuracy: 0.7762\n",
            "Epoch 759/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7771 - val_loss: 0.4848 - val_accuracy: 0.7727\n",
            "Epoch 760/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7806 - val_loss: 0.4825 - val_accuracy: 0.7727\n",
            "Epoch 761/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7657\n",
            "Epoch 762/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7748 - val_loss: 0.4844 - val_accuracy: 0.7657\n",
            "Epoch 763/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7783 - val_loss: 0.4863 - val_accuracy: 0.7587\n",
            "Epoch 764/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7806 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
            "Epoch 765/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7806 - val_loss: 0.4859 - val_accuracy: 0.7762\n",
            "Epoch 766/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4842 - val_accuracy: 0.7692\n",
            "Epoch 767/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7806 - val_loss: 0.4871 - val_accuracy: 0.7587\n",
            "Epoch 768/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7783 - val_loss: 0.4848 - val_accuracy: 0.7692\n",
            "Epoch 769/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7783 - val_loss: 0.4822 - val_accuracy: 0.7762\n",
            "Epoch 770/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7865 - val_loss: 0.4819 - val_accuracy: 0.7762\n",
            "Epoch 771/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7818 - val_loss: 0.4842 - val_accuracy: 0.7622\n",
            "Epoch 772/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7841 - val_loss: 0.4860 - val_accuracy: 0.7692\n",
            "Epoch 773/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7762\n",
            "Epoch 774/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7806 - val_loss: 0.4859 - val_accuracy: 0.7727\n",
            "Epoch 775/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7818 - val_loss: 0.4874 - val_accuracy: 0.7657\n",
            "Epoch 776/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7806 - val_loss: 0.4846 - val_accuracy: 0.7692\n",
            "Epoch 777/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4859 - val_accuracy: 0.7657\n",
            "Epoch 778/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7622\n",
            "Epoch 779/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7818 - val_loss: 0.4874 - val_accuracy: 0.7657\n",
            "Epoch 780/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7622\n",
            "Epoch 781/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7818 - val_loss: 0.4853 - val_accuracy: 0.7727\n",
            "Epoch 782/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7806 - val_loss: 0.4901 - val_accuracy: 0.7657\n",
            "Epoch 783/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7622\n",
            "Epoch 784/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7587\n",
            "Epoch 785/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4867 - val_accuracy: 0.7622\n",
            "Epoch 786/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7692\n",
            "Epoch 787/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4870 - val_accuracy: 0.7692\n",
            "Epoch 788/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7818 - val_loss: 0.4858 - val_accuracy: 0.7692\n",
            "Epoch 789/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7657\n",
            "Epoch 790/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7692\n",
            "Epoch 791/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7818 - val_loss: 0.4858 - val_accuracy: 0.7762\n",
            "Epoch 792/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7806 - val_loss: 0.4848 - val_accuracy: 0.7762\n",
            "Epoch 793/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7727\n",
            "Epoch 794/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.7853 - val_loss: 0.4830 - val_accuracy: 0.7762\n",
            "Epoch 795/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7841 - val_loss: 0.4859 - val_accuracy: 0.7727\n",
            "Epoch 796/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7692\n",
            "Epoch 797/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4848 - val_accuracy: 0.7727\n",
            "Epoch 798/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4847 - val_accuracy: 0.7727\n",
            "Epoch 799/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7818 - val_loss: 0.4874 - val_accuracy: 0.7762\n",
            "Epoch 800/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7841 - val_loss: 0.4860 - val_accuracy: 0.7727\n",
            "Epoch 801/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7806 - val_loss: 0.4854 - val_accuracy: 0.7692\n",
            "Epoch 802/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4851 - val_accuracy: 0.7727\n",
            "Epoch 803/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7783 - val_loss: 0.4864 - val_accuracy: 0.7797\n",
            "Epoch 804/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7853 - val_loss: 0.4855 - val_accuracy: 0.7797\n",
            "Epoch 805/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7832\n",
            "Epoch 806/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7818 - val_loss: 0.4872 - val_accuracy: 0.7762\n",
            "Epoch 807/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7806 - val_loss: 0.4886 - val_accuracy: 0.7762\n",
            "Epoch 808/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7622\n",
            "Epoch 809/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7727\n",
            "Epoch 810/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7867\n",
            "Epoch 811/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7806 - val_loss: 0.4872 - val_accuracy: 0.7692\n",
            "Epoch 812/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7797\n",
            "Epoch 813/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4891 - val_accuracy: 0.7692\n",
            "Epoch 814/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7692\n",
            "Epoch 815/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7818 - val_loss: 0.4883 - val_accuracy: 0.7797\n",
            "Epoch 816/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7806 - val_loss: 0.4892 - val_accuracy: 0.7692\n",
            "Epoch 817/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7587\n",
            "Epoch 818/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7797\n",
            "Epoch 819/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7818 - val_loss: 0.4868 - val_accuracy: 0.7832\n",
            "Epoch 820/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7876 - val_loss: 0.4871 - val_accuracy: 0.7832\n",
            "Epoch 821/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7832\n",
            "Epoch 822/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7818 - val_loss: 0.4912 - val_accuracy: 0.7587\n",
            "Epoch 823/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7587\n",
            "Epoch 824/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7841 - val_loss: 0.4902 - val_accuracy: 0.7797\n",
            "Epoch 825/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7806 - val_loss: 0.4916 - val_accuracy: 0.7622\n",
            "Epoch 826/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7853 - val_loss: 0.4880 - val_accuracy: 0.7692\n",
            "Epoch 827/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7806 - val_loss: 0.4929 - val_accuracy: 0.7587\n",
            "Epoch 828/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7818 - val_loss: 0.4923 - val_accuracy: 0.7727\n",
            "Epoch 829/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7818 - val_loss: 0.4861 - val_accuracy: 0.7832\n",
            "Epoch 830/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7762\n",
            "Epoch 831/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7841 - val_loss: 0.4899 - val_accuracy: 0.7762\n",
            "Epoch 832/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7797\n",
            "Epoch 833/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7806 - val_loss: 0.4942 - val_accuracy: 0.7622\n",
            "Epoch 834/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7841 - val_loss: 0.4908 - val_accuracy: 0.7762\n",
            "Epoch 835/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7797\n",
            "Epoch 836/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7692\n",
            "Epoch 837/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7841 - val_loss: 0.4903 - val_accuracy: 0.7797\n",
            "Epoch 838/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7797\n",
            "Epoch 839/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7876 - val_loss: 0.4899 - val_accuracy: 0.7762\n",
            "Epoch 840/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7841 - val_loss: 0.4889 - val_accuracy: 0.7797\n",
            "Epoch 841/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7841 - val_loss: 0.4885 - val_accuracy: 0.7727\n",
            "Epoch 842/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7841 - val_loss: 0.4902 - val_accuracy: 0.7692\n",
            "Epoch 843/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7797\n",
            "Epoch 844/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7797\n",
            "Epoch 845/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7727\n",
            "Epoch 846/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7797\n",
            "Epoch 847/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7853 - val_loss: 0.4887 - val_accuracy: 0.7797\n",
            "Epoch 848/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7853 - val_loss: 0.4901 - val_accuracy: 0.7797\n",
            "Epoch 849/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7853 - val_loss: 0.4891 - val_accuracy: 0.7832\n",
            "Epoch 850/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7853 - val_loss: 0.4902 - val_accuracy: 0.7727\n",
            "Epoch 851/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7888 - val_loss: 0.4872 - val_accuracy: 0.7832\n",
            "Epoch 852/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7841 - val_loss: 0.4885 - val_accuracy: 0.7832\n",
            "Epoch 853/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7841 - val_loss: 0.4924 - val_accuracy: 0.7727\n",
            "Epoch 854/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7818 - val_loss: 0.4925 - val_accuracy: 0.7727\n",
            "Epoch 855/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7841 - val_loss: 0.4950 - val_accuracy: 0.7622\n",
            "Epoch 856/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7841 - val_loss: 0.4908 - val_accuracy: 0.7832\n",
            "Epoch 857/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7771 - val_loss: 0.4919 - val_accuracy: 0.7762\n",
            "Epoch 858/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7818 - val_loss: 0.4942 - val_accuracy: 0.7727\n",
            "Epoch 859/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7853 - val_loss: 0.4942 - val_accuracy: 0.7797\n",
            "Epoch 860/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7841 - val_loss: 0.4927 - val_accuracy: 0.7762\n",
            "Epoch 861/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7900 - val_loss: 0.4899 - val_accuracy: 0.7762\n",
            "Epoch 862/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7888 - val_loss: 0.4886 - val_accuracy: 0.7797\n",
            "Epoch 863/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7797\n",
            "Epoch 864/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7888 - val_loss: 0.4949 - val_accuracy: 0.7762\n",
            "Epoch 865/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7818 - val_loss: 0.4921 - val_accuracy: 0.7762\n",
            "Epoch 866/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7853 - val_loss: 0.4916 - val_accuracy: 0.7797\n",
            "Epoch 867/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7841 - val_loss: 0.4922 - val_accuracy: 0.7727\n",
            "Epoch 868/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7841 - val_loss: 0.4913 - val_accuracy: 0.7797\n",
            "Epoch 869/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7853 - val_loss: 0.4922 - val_accuracy: 0.7797\n",
            "Epoch 870/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7762\n",
            "Epoch 871/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7657\n",
            "Epoch 872/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7692\n",
            "Epoch 873/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7841 - val_loss: 0.4938 - val_accuracy: 0.7797\n",
            "Epoch 874/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7818 - val_loss: 0.4939 - val_accuracy: 0.7727\n",
            "Epoch 875/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7876 - val_loss: 0.4927 - val_accuracy: 0.7762\n",
            "Epoch 876/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7818 - val_loss: 0.4923 - val_accuracy: 0.7797\n",
            "Epoch 877/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7888 - val_loss: 0.4924 - val_accuracy: 0.7762\n",
            "Epoch 878/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7806 - val_loss: 0.4920 - val_accuracy: 0.7762\n",
            "Epoch 879/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7900 - val_loss: 0.4984 - val_accuracy: 0.7692\n",
            "Epoch 880/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7911 - val_loss: 0.4924 - val_accuracy: 0.7832\n",
            "Epoch 881/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7806 - val_loss: 0.4952 - val_accuracy: 0.7832\n",
            "Epoch 882/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7762\n",
            "Epoch 883/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7876 - val_loss: 0.4905 - val_accuracy: 0.7867\n",
            "Epoch 884/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7841 - val_loss: 0.4911 - val_accuracy: 0.7832\n",
            "Epoch 885/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7853 - val_loss: 0.4942 - val_accuracy: 0.7797\n",
            "Epoch 886/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7841 - val_loss: 0.4963 - val_accuracy: 0.7762\n",
            "Epoch 887/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7900 - val_loss: 0.4947 - val_accuracy: 0.7797\n",
            "Epoch 888/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7818 - val_loss: 0.4932 - val_accuracy: 0.7762\n",
            "Epoch 889/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7853 - val_loss: 0.4936 - val_accuracy: 0.7797\n",
            "Epoch 890/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7853 - val_loss: 0.4936 - val_accuracy: 0.7832\n",
            "Epoch 891/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7946 - val_loss: 0.4901 - val_accuracy: 0.7867\n",
            "Epoch 892/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7832\n",
            "Epoch 893/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7841 - val_loss: 0.4934 - val_accuracy: 0.7797\n",
            "Epoch 894/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7876 - val_loss: 0.4953 - val_accuracy: 0.7797\n",
            "Epoch 895/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7911 - val_loss: 0.4946 - val_accuracy: 0.7797\n",
            "Epoch 896/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7888 - val_loss: 0.4948 - val_accuracy: 0.7797\n",
            "Epoch 897/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7888 - val_loss: 0.4923 - val_accuracy: 0.7797\n",
            "Epoch 898/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7876 - val_loss: 0.4946 - val_accuracy: 0.7797\n",
            "Epoch 899/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7867\n",
            "Epoch 900/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7876 - val_loss: 0.4950 - val_accuracy: 0.7832\n",
            "Epoch 901/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4930 - val_accuracy: 0.7797\n",
            "Epoch 902/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7876 - val_loss: 0.4982 - val_accuracy: 0.7762\n",
            "Epoch 903/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7876 - val_loss: 0.4938 - val_accuracy: 0.7832\n",
            "Epoch 904/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.7806 - val_loss: 0.4967 - val_accuracy: 0.7762\n",
            "Epoch 905/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7797\n",
            "Epoch 906/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7762\n",
            "Epoch 907/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7876 - val_loss: 0.4972 - val_accuracy: 0.7797\n",
            "Epoch 908/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7832\n",
            "Epoch 909/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7900 - val_loss: 0.5025 - val_accuracy: 0.7692\n",
            "Epoch 910/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7853 - val_loss: 0.4961 - val_accuracy: 0.7832\n",
            "Epoch 911/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.7853 - val_loss: 0.4952 - val_accuracy: 0.7797\n",
            "Epoch 912/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7832\n",
            "Epoch 913/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7876 - val_loss: 0.4941 - val_accuracy: 0.7867\n",
            "Epoch 914/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7797\n",
            "Epoch 915/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.4985 - val_accuracy: 0.7727\n",
            "Epoch 916/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7888 - val_loss: 0.4962 - val_accuracy: 0.7832\n",
            "Epoch 917/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7841 - val_loss: 0.4955 - val_accuracy: 0.7832\n",
            "Epoch 918/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7818 - val_loss: 0.4945 - val_accuracy: 0.7832\n",
            "Epoch 919/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7853 - val_loss: 0.4987 - val_accuracy: 0.7797\n",
            "Epoch 920/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7876 - val_loss: 0.4941 - val_accuracy: 0.7832\n",
            "Epoch 921/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7853 - val_loss: 0.4956 - val_accuracy: 0.7832\n",
            "Epoch 922/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.7888 - val_loss: 0.4955 - val_accuracy: 0.7832\n",
            "Epoch 923/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7876 - val_loss: 0.4929 - val_accuracy: 0.7832\n",
            "Epoch 924/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7853 - val_loss: 0.4939 - val_accuracy: 0.7832\n",
            "Epoch 925/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7797\n",
            "Epoch 926/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7911 - val_loss: 0.4953 - val_accuracy: 0.7867\n",
            "Epoch 927/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7935 - val_loss: 0.4959 - val_accuracy: 0.7832\n",
            "Epoch 928/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7727\n",
            "Epoch 929/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7876 - val_loss: 0.4969 - val_accuracy: 0.7832\n",
            "Epoch 930/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7797\n",
            "Epoch 931/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7900 - val_loss: 0.4979 - val_accuracy: 0.7762\n",
            "Epoch 932/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7900 - val_loss: 0.4969 - val_accuracy: 0.7832\n",
            "Epoch 933/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7923 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
            "Epoch 934/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7853 - val_loss: 0.4974 - val_accuracy: 0.7832\n",
            "Epoch 935/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7853 - val_loss: 0.4930 - val_accuracy: 0.7797\n",
            "Epoch 936/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7888 - val_loss: 0.4924 - val_accuracy: 0.7832\n",
            "Epoch 937/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7853 - val_loss: 0.4970 - val_accuracy: 0.7832\n",
            "Epoch 938/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7876 - val_loss: 0.4958 - val_accuracy: 0.7867\n",
            "Epoch 939/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7935 - val_loss: 0.4975 - val_accuracy: 0.7832\n",
            "Epoch 940/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7911 - val_loss: 0.4952 - val_accuracy: 0.7832\n",
            "Epoch 941/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7853 - val_loss: 0.5006 - val_accuracy: 0.7727\n",
            "Epoch 942/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7888 - val_loss: 0.5070 - val_accuracy: 0.7692\n",
            "Epoch 943/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7946 - val_loss: 0.4962 - val_accuracy: 0.7832\n",
            "Epoch 944/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7958 - val_loss: 0.4955 - val_accuracy: 0.7867\n",
            "Epoch 945/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7900 - val_loss: 0.4972 - val_accuracy: 0.7832\n",
            "Epoch 946/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7876 - val_loss: 0.4957 - val_accuracy: 0.7832\n",
            "Epoch 947/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.4967 - val_accuracy: 0.7832\n",
            "Epoch 948/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4994 - val_accuracy: 0.7692\n",
            "Epoch 949/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7935 - val_loss: 0.5007 - val_accuracy: 0.7762\n",
            "Epoch 950/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7911 - val_loss: 0.4993 - val_accuracy: 0.7727\n",
            "Epoch 951/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7888 - val_loss: 0.4997 - val_accuracy: 0.7692\n",
            "Epoch 952/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7900 - val_loss: 0.4970 - val_accuracy: 0.7867\n",
            "Epoch 953/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4958 - val_accuracy: 0.7867\n",
            "Epoch 954/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7911 - val_loss: 0.4938 - val_accuracy: 0.7832\n",
            "Epoch 955/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7981 - val_loss: 0.4951 - val_accuracy: 0.7832\n",
            "Epoch 956/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7841 - val_loss: 0.4959 - val_accuracy: 0.7832\n",
            "Epoch 957/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7853 - val_loss: 0.4995 - val_accuracy: 0.7727\n",
            "Epoch 958/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7853 - val_loss: 0.4972 - val_accuracy: 0.7867\n",
            "Epoch 959/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7946 - val_loss: 0.4950 - val_accuracy: 0.7832\n",
            "Epoch 960/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7900 - val_loss: 0.4973 - val_accuracy: 0.7867\n",
            "Epoch 961/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7911 - val_loss: 0.4969 - val_accuracy: 0.7867\n",
            "Epoch 962/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7923 - val_loss: 0.5008 - val_accuracy: 0.7727\n",
            "Epoch 963/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7876 - val_loss: 0.4981 - val_accuracy: 0.7867\n",
            "Epoch 964/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4974 - val_accuracy: 0.7832\n",
            "Epoch 965/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7935 - val_loss: 0.4976 - val_accuracy: 0.7832\n",
            "Epoch 966/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7832\n",
            "Epoch 967/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7900 - val_loss: 0.4935 - val_accuracy: 0.7797\n",
            "Epoch 968/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7853 - val_loss: 0.4964 - val_accuracy: 0.7867\n",
            "Epoch 969/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7900 - val_loss: 0.4963 - val_accuracy: 0.7832\n",
            "Epoch 970/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7946 - val_loss: 0.4994 - val_accuracy: 0.7867\n",
            "Epoch 971/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7888 - val_loss: 0.4978 - val_accuracy: 0.7867\n",
            "Epoch 972/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7900 - val_loss: 0.5005 - val_accuracy: 0.7797\n",
            "Epoch 973/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7935 - val_loss: 0.4957 - val_accuracy: 0.7797\n",
            "Epoch 974/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7876 - val_loss: 0.4942 - val_accuracy: 0.7832\n",
            "Epoch 975/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7900 - val_loss: 0.4988 - val_accuracy: 0.7832\n",
            "Epoch 976/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7970 - val_loss: 0.4953 - val_accuracy: 0.7832\n",
            "Epoch 977/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7900 - val_loss: 0.5007 - val_accuracy: 0.7797\n",
            "Epoch 978/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7900 - val_loss: 0.4990 - val_accuracy: 0.7797\n",
            "Epoch 979/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7841 - val_loss: 0.5012 - val_accuracy: 0.7797\n",
            "Epoch 980/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7832\n",
            "Epoch 981/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7876 - val_loss: 0.4990 - val_accuracy: 0.7902\n",
            "Epoch 982/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7888 - val_loss: 0.4982 - val_accuracy: 0.7832\n",
            "Epoch 983/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7935 - val_loss: 0.4977 - val_accuracy: 0.7832\n",
            "Epoch 984/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7935 - val_loss: 0.4964 - val_accuracy: 0.7832\n",
            "Epoch 985/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7888 - val_loss: 0.4994 - val_accuracy: 0.7832\n",
            "Epoch 986/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7832\n",
            "Epoch 987/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7946 - val_loss: 0.4989 - val_accuracy: 0.7832\n",
            "Epoch 988/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7876 - val_loss: 0.5004 - val_accuracy: 0.7832\n",
            "Epoch 989/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7923 - val_loss: 0.4966 - val_accuracy: 0.7832\n",
            "Epoch 990/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7923 - val_loss: 0.4985 - val_accuracy: 0.7832\n",
            "Epoch 991/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7923 - val_loss: 0.4950 - val_accuracy: 0.7832\n",
            "Epoch 992/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7911 - val_loss: 0.4987 - val_accuracy: 0.7797\n",
            "Epoch 993/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7923 - val_loss: 0.5010 - val_accuracy: 0.7797\n",
            "Epoch 994/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7923 - val_loss: 0.4997 - val_accuracy: 0.7832\n",
            "Epoch 995/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7946 - val_loss: 0.4954 - val_accuracy: 0.7832\n",
            "Epoch 996/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7946 - val_loss: 0.5007 - val_accuracy: 0.7832\n",
            "Epoch 997/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7911 - val_loss: 0.4991 - val_accuracy: 0.7797\n",
            "Epoch 998/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7981 - val_loss: 0.4979 - val_accuracy: 0.7832\n",
            "Epoch 999/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7911 - val_loss: 0.4971 - val_accuracy: 0.7832\n",
            "Epoch 1000/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7911 - val_loss: 0.5015 - val_accuracy: 0.7797\n",
            "Epoch 1001/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7888 - val_loss: 0.5013 - val_accuracy: 0.7832\n",
            "Epoch 1002/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7923 - val_loss: 0.4948 - val_accuracy: 0.7832\n",
            "Epoch 1003/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.7876 - val_loss: 0.5000 - val_accuracy: 0.7797\n",
            "Epoch 1004/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.7911 - val_loss: 0.4986 - val_accuracy: 0.7832\n",
            "Epoch 1005/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7900 - val_loss: 0.5002 - val_accuracy: 0.7832\n",
            "Epoch 1006/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7935 - val_loss: 0.4970 - val_accuracy: 0.7832\n",
            "Epoch 1007/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7888 - val_loss: 0.5028 - val_accuracy: 0.7762\n",
            "Epoch 1008/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7876 - val_loss: 0.4991 - val_accuracy: 0.7797\n",
            "Epoch 1009/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7876 - val_loss: 0.4996 - val_accuracy: 0.7797\n",
            "Epoch 1010/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7876 - val_loss: 0.4991 - val_accuracy: 0.7797\n",
            "Epoch 1011/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7911 - val_loss: 0.5003 - val_accuracy: 0.7797\n",
            "Epoch 1012/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7923 - val_loss: 0.5029 - val_accuracy: 0.7762\n",
            "Epoch 1013/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7876 - val_loss: 0.4998 - val_accuracy: 0.7832\n",
            "Epoch 1014/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7935 - val_loss: 0.5017 - val_accuracy: 0.7797\n",
            "Epoch 1015/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7797\n",
            "Epoch 1016/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7981 - val_loss: 0.5030 - val_accuracy: 0.7797\n",
            "Epoch 1017/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7911 - val_loss: 0.5016 - val_accuracy: 0.7797\n",
            "Epoch 1018/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.7911 - val_loss: 0.5001 - val_accuracy: 0.7797\n",
            "Epoch 1019/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7888 - val_loss: 0.5019 - val_accuracy: 0.7797\n",
            "Epoch 1020/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7911 - val_loss: 0.5043 - val_accuracy: 0.7762\n",
            "Epoch 1021/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7958 - val_loss: 0.5021 - val_accuracy: 0.7727\n",
            "Epoch 1022/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7935 - val_loss: 0.4996 - val_accuracy: 0.7797\n",
            "Epoch 1023/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7958 - val_loss: 0.4982 - val_accuracy: 0.7797\n",
            "Epoch 1024/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7958 - val_loss: 0.5006 - val_accuracy: 0.7762\n",
            "Epoch 1025/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7935 - val_loss: 0.4968 - val_accuracy: 0.7832\n",
            "Epoch 1026/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7946 - val_loss: 0.5002 - val_accuracy: 0.7797\n",
            "Epoch 1027/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.7888 - val_loss: 0.5019 - val_accuracy: 0.7797\n",
            "Epoch 1028/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7946 - val_loss: 0.5019 - val_accuracy: 0.7832\n",
            "Epoch 1029/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7888 - val_loss: 0.4982 - val_accuracy: 0.7797\n",
            "Epoch 1030/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7876 - val_loss: 0.5020 - val_accuracy: 0.7762\n",
            "Epoch 1031/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7935 - val_loss: 0.5010 - val_accuracy: 0.7727\n",
            "Epoch 1032/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7958 - val_loss: 0.5052 - val_accuracy: 0.7727\n",
            "Epoch 1033/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7911 - val_loss: 0.5050 - val_accuracy: 0.7727\n",
            "Epoch 1034/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7946 - val_loss: 0.5031 - val_accuracy: 0.7762\n",
            "Epoch 1035/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7935 - val_loss: 0.5050 - val_accuracy: 0.7727\n",
            "Epoch 1036/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7935 - val_loss: 0.4995 - val_accuracy: 0.7832\n",
            "Epoch 1037/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7876 - val_loss: 0.5008 - val_accuracy: 0.7762\n",
            "Epoch 1038/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7900 - val_loss: 0.5012 - val_accuracy: 0.7797\n",
            "Epoch 1039/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7888 - val_loss: 0.5026 - val_accuracy: 0.7762\n",
            "Epoch 1040/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7911 - val_loss: 0.5030 - val_accuracy: 0.7762\n",
            "Epoch 1041/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7762\n",
            "Epoch 1042/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7970 - val_loss: 0.5084 - val_accuracy: 0.7762\n",
            "Epoch 1043/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7970 - val_loss: 0.5017 - val_accuracy: 0.7797\n",
            "Epoch 1044/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7911 - val_loss: 0.5003 - val_accuracy: 0.7832\n",
            "Epoch 1045/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7832\n",
            "Epoch 1046/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7888 - val_loss: 0.5019 - val_accuracy: 0.7762\n",
            "Epoch 1047/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7935 - val_loss: 0.5027 - val_accuracy: 0.7762\n",
            "Epoch 1048/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7888 - val_loss: 0.5028 - val_accuracy: 0.7832\n",
            "Epoch 1049/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7900 - val_loss: 0.5080 - val_accuracy: 0.7727\n",
            "Epoch 1050/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7935 - val_loss: 0.5017 - val_accuracy: 0.7797\n",
            "Epoch 1051/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7923 - val_loss: 0.5004 - val_accuracy: 0.7797\n",
            "Epoch 1052/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7935 - val_loss: 0.5044 - val_accuracy: 0.7762\n",
            "Epoch 1053/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7888 - val_loss: 0.5035 - val_accuracy: 0.7797\n",
            "Epoch 1054/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7970 - val_loss: 0.5046 - val_accuracy: 0.7832\n",
            "Epoch 1055/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7958 - val_loss: 0.5081 - val_accuracy: 0.7762\n",
            "Epoch 1056/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7876 - val_loss: 0.5060 - val_accuracy: 0.7762\n",
            "Epoch 1057/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7900 - val_loss: 0.5058 - val_accuracy: 0.7762\n",
            "Epoch 1058/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7911 - val_loss: 0.5009 - val_accuracy: 0.7797\n",
            "Epoch 1059/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7946 - val_loss: 0.5027 - val_accuracy: 0.7727\n",
            "Epoch 1060/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7888 - val_loss: 0.5035 - val_accuracy: 0.7727\n",
            "Epoch 1061/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7911 - val_loss: 0.5047 - val_accuracy: 0.7727\n",
            "Epoch 1062/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7935 - val_loss: 0.5017 - val_accuracy: 0.7797\n",
            "Epoch 1063/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7876 - val_loss: 0.5016 - val_accuracy: 0.7762\n",
            "Epoch 1064/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7958 - val_loss: 0.5027 - val_accuracy: 0.7832\n",
            "Epoch 1065/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7762\n",
            "Epoch 1066/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7900 - val_loss: 0.4988 - val_accuracy: 0.7727\n",
            "Epoch 1067/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7876 - val_loss: 0.5054 - val_accuracy: 0.7692\n",
            "Epoch 1068/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7911 - val_loss: 0.5045 - val_accuracy: 0.7727\n",
            "Epoch 1069/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7958 - val_loss: 0.5045 - val_accuracy: 0.7762\n",
            "Epoch 1070/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7923 - val_loss: 0.5040 - val_accuracy: 0.7692\n",
            "Epoch 1071/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7946 - val_loss: 0.5075 - val_accuracy: 0.7657\n",
            "Epoch 1072/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7946 - val_loss: 0.5010 - val_accuracy: 0.7727\n",
            "Epoch 1073/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7911 - val_loss: 0.5022 - val_accuracy: 0.7727\n",
            "Epoch 1074/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7981 - val_loss: 0.5039 - val_accuracy: 0.7832\n",
            "Epoch 1075/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7923 - val_loss: 0.5021 - val_accuracy: 0.7762\n",
            "Epoch 1076/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7888 - val_loss: 0.5044 - val_accuracy: 0.7727\n",
            "Epoch 1077/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7935 - val_loss: 0.5032 - val_accuracy: 0.7727\n",
            "Epoch 1078/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7935 - val_loss: 0.5011 - val_accuracy: 0.7727\n",
            "Epoch 1079/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7923 - val_loss: 0.5020 - val_accuracy: 0.7797\n",
            "Epoch 1080/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7727\n",
            "Epoch 1081/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7970 - val_loss: 0.5071 - val_accuracy: 0.7762\n",
            "Epoch 1082/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7935 - val_loss: 0.5037 - val_accuracy: 0.7727\n",
            "Epoch 1083/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7946 - val_loss: 0.5005 - val_accuracy: 0.7727\n",
            "Epoch 1084/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7946 - val_loss: 0.5035 - val_accuracy: 0.7762\n",
            "Epoch 1085/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7958 - val_loss: 0.5045 - val_accuracy: 0.7727\n",
            "Epoch 1086/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7935 - val_loss: 0.5024 - val_accuracy: 0.7762\n",
            "Epoch 1087/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7946 - val_loss: 0.5007 - val_accuracy: 0.7762\n",
            "Epoch 1088/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7946 - val_loss: 0.4981 - val_accuracy: 0.7797\n",
            "Epoch 1089/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7970 - val_loss: 0.4998 - val_accuracy: 0.7762\n",
            "Epoch 1090/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7923 - val_loss: 0.4981 - val_accuracy: 0.7832\n",
            "Epoch 1091/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7911 - val_loss: 0.5030 - val_accuracy: 0.7797\n",
            "Epoch 1092/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7946 - val_loss: 0.5035 - val_accuracy: 0.7692\n",
            "Epoch 1093/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7923 - val_loss: 0.5052 - val_accuracy: 0.7692\n",
            "Epoch 1094/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7970 - val_loss: 0.5062 - val_accuracy: 0.7797\n",
            "Epoch 1095/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7911 - val_loss: 0.5015 - val_accuracy: 0.7797\n",
            "Epoch 1096/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7911 - val_loss: 0.5028 - val_accuracy: 0.7727\n",
            "Epoch 1097/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7911 - val_loss: 0.5061 - val_accuracy: 0.7727\n",
            "Epoch 1098/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7946 - val_loss: 0.5024 - val_accuracy: 0.7727\n",
            "Epoch 1099/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7923 - val_loss: 0.5024 - val_accuracy: 0.7727\n",
            "Epoch 1100/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7923 - val_loss: 0.5034 - val_accuracy: 0.7797\n",
            "Epoch 1101/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7970 - val_loss: 0.5037 - val_accuracy: 0.7762\n",
            "Epoch 1102/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7888 - val_loss: 0.5010 - val_accuracy: 0.7797\n",
            "Epoch 1103/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7923 - val_loss: 0.5020 - val_accuracy: 0.7692\n",
            "Epoch 1104/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7923 - val_loss: 0.5073 - val_accuracy: 0.7762\n",
            "Epoch 1105/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7958 - val_loss: 0.5021 - val_accuracy: 0.7762\n",
            "Epoch 1106/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7911 - val_loss: 0.5059 - val_accuracy: 0.7727\n",
            "Epoch 1107/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7911 - val_loss: 0.5060 - val_accuracy: 0.7762\n",
            "Epoch 1108/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7911 - val_loss: 0.5004 - val_accuracy: 0.7797\n",
            "Epoch 1109/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7923 - val_loss: 0.4998 - val_accuracy: 0.7797\n",
            "Epoch 1110/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7935 - val_loss: 0.5017 - val_accuracy: 0.7762\n",
            "Epoch 1111/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7923 - val_loss: 0.5014 - val_accuracy: 0.7727\n",
            "Epoch 1112/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7853 - val_loss: 0.5027 - val_accuracy: 0.7762\n",
            "Epoch 1113/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.7935 - val_loss: 0.5009 - val_accuracy: 0.7797\n",
            "Epoch 1114/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7888 - val_loss: 0.5049 - val_accuracy: 0.7797\n",
            "Epoch 1115/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7970 - val_loss: 0.5040 - val_accuracy: 0.7762\n",
            "Epoch 1116/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7958 - val_loss: 0.5045 - val_accuracy: 0.7797\n",
            "Epoch 1117/1200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7900 - val_loss: 0.5039 - val_accuracy: 0.7762\n",
            "Epoch 1118/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7958 - val_loss: 0.5006 - val_accuracy: 0.7797\n",
            "Epoch 1119/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7876 - val_loss: 0.5019 - val_accuracy: 0.7727\n",
            "Epoch 1120/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7935 - val_loss: 0.5013 - val_accuracy: 0.7762\n",
            "Epoch 1121/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7981 - val_loss: 0.4964 - val_accuracy: 0.7727\n",
            "Epoch 1122/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7911 - val_loss: 0.5047 - val_accuracy: 0.7762\n",
            "Epoch 1123/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7911 - val_loss: 0.5035 - val_accuracy: 0.7727\n",
            "Epoch 1124/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7900 - val_loss: 0.5090 - val_accuracy: 0.7692\n",
            "Epoch 1125/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7970 - val_loss: 0.5010 - val_accuracy: 0.7797\n",
            "Epoch 1126/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7935 - val_loss: 0.5013 - val_accuracy: 0.7727\n",
            "Epoch 1127/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7935 - val_loss: 0.5026 - val_accuracy: 0.7657\n",
            "Epoch 1128/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7958 - val_loss: 0.5037 - val_accuracy: 0.7657\n",
            "Epoch 1129/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4466 - accuracy: 0.7888 - val_loss: 0.5050 - val_accuracy: 0.7727\n",
            "Epoch 1130/1200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8028 - val_loss: 0.5022 - val_accuracy: 0.7762\n",
            "Epoch 1131/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.7900 - val_loss: 0.5023 - val_accuracy: 0.7762\n",
            "Epoch 1132/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7958 - val_loss: 0.5009 - val_accuracy: 0.7762\n",
            "Epoch 1133/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7876 - val_loss: 0.5049 - val_accuracy: 0.7797\n",
            "Epoch 1134/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7935 - val_loss: 0.5048 - val_accuracy: 0.7727\n",
            "Epoch 1135/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7876 - val_loss: 0.5068 - val_accuracy: 0.7657\n",
            "Epoch 1136/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7958 - val_loss: 0.5074 - val_accuracy: 0.7692\n",
            "Epoch 1137/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7970 - val_loss: 0.5011 - val_accuracy: 0.7727\n",
            "Epoch 1138/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7946 - val_loss: 0.5002 - val_accuracy: 0.7797\n",
            "Epoch 1139/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7876 - val_loss: 0.5030 - val_accuracy: 0.7762\n",
            "Epoch 1140/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7923 - val_loss: 0.5042 - val_accuracy: 0.7762\n",
            "Epoch 1141/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7888 - val_loss: 0.5070 - val_accuracy: 0.7692\n",
            "Epoch 1142/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7935 - val_loss: 0.5019 - val_accuracy: 0.7727\n",
            "Epoch 1143/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7900 - val_loss: 0.5038 - val_accuracy: 0.7727\n",
            "Epoch 1144/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7946 - val_loss: 0.5027 - val_accuracy: 0.7727\n",
            "Epoch 1145/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7993 - val_loss: 0.5010 - val_accuracy: 0.7762\n",
            "Epoch 1146/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7911 - val_loss: 0.5012 - val_accuracy: 0.7762\n",
            "Epoch 1147/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7911 - val_loss: 0.5006 - val_accuracy: 0.7762\n",
            "Epoch 1148/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7923 - val_loss: 0.5054 - val_accuracy: 0.7762\n",
            "Epoch 1149/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7762\n",
            "Epoch 1150/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7935 - val_loss: 0.4998 - val_accuracy: 0.7797\n",
            "Epoch 1151/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7923 - val_loss: 0.5041 - val_accuracy: 0.7727\n",
            "Epoch 1152/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7911 - val_loss: 0.5039 - val_accuracy: 0.7692\n",
            "Epoch 1153/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7946 - val_loss: 0.5035 - val_accuracy: 0.7692\n",
            "Epoch 1154/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7946 - val_loss: 0.5009 - val_accuracy: 0.7727\n",
            "Epoch 1155/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7970 - val_loss: 0.5037 - val_accuracy: 0.7797\n",
            "Epoch 1156/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7900 - val_loss: 0.5072 - val_accuracy: 0.7727\n",
            "Epoch 1157/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7970 - val_loss: 0.5024 - val_accuracy: 0.7692\n",
            "Epoch 1158/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7888 - val_loss: 0.5007 - val_accuracy: 0.7727\n",
            "Epoch 1159/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7911 - val_loss: 0.5034 - val_accuracy: 0.7692\n",
            "Epoch 1160/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7900 - val_loss: 0.4991 - val_accuracy: 0.7727\n",
            "Epoch 1161/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7970 - val_loss: 0.5025 - val_accuracy: 0.7657\n",
            "Epoch 1162/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7900 - val_loss: 0.5033 - val_accuracy: 0.7657\n",
            "Epoch 1163/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7923 - val_loss: 0.5027 - val_accuracy: 0.7762\n",
            "Epoch 1164/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7935 - val_loss: 0.5036 - val_accuracy: 0.7727\n",
            "Epoch 1165/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7911 - val_loss: 0.5025 - val_accuracy: 0.7762\n",
            "Epoch 1166/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7888 - val_loss: 0.5029 - val_accuracy: 0.7692\n",
            "Epoch 1167/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7993 - val_loss: 0.5046 - val_accuracy: 0.7762\n",
            "Epoch 1168/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7981 - val_loss: 0.5025 - val_accuracy: 0.7692\n",
            "Epoch 1169/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7923 - val_loss: 0.4999 - val_accuracy: 0.7692\n",
            "Epoch 1170/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7692\n",
            "Epoch 1171/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7946 - val_loss: 0.5022 - val_accuracy: 0.7762\n",
            "Epoch 1172/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7958 - val_loss: 0.5067 - val_accuracy: 0.7727\n",
            "Epoch 1173/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7900 - val_loss: 0.5058 - val_accuracy: 0.7692\n",
            "Epoch 1174/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7946 - val_loss: 0.5021 - val_accuracy: 0.7762\n",
            "Epoch 1175/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8005 - val_loss: 0.5003 - val_accuracy: 0.7727\n",
            "Epoch 1176/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7900 - val_loss: 0.5068 - val_accuracy: 0.7762\n",
            "Epoch 1177/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7935 - val_loss: 0.5044 - val_accuracy: 0.7692\n",
            "Epoch 1178/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7911 - val_loss: 0.5040 - val_accuracy: 0.7692\n",
            "Epoch 1179/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7981 - val_loss: 0.5049 - val_accuracy: 0.7692\n",
            "Epoch 1180/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7900 - val_loss: 0.5045 - val_accuracy: 0.7727\n",
            "Epoch 1181/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7900 - val_loss: 0.5040 - val_accuracy: 0.7727\n",
            "Epoch 1182/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7993 - val_loss: 0.5072 - val_accuracy: 0.7727\n",
            "Epoch 1183/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7970 - val_loss: 0.5034 - val_accuracy: 0.7762\n",
            "Epoch 1184/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7923 - val_loss: 0.4978 - val_accuracy: 0.7797\n",
            "Epoch 1185/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7900 - val_loss: 0.5050 - val_accuracy: 0.7762\n",
            "Epoch 1186/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7935 - val_loss: 0.5029 - val_accuracy: 0.7762\n",
            "Epoch 1187/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7923 - val_loss: 0.5025 - val_accuracy: 0.7797\n",
            "Epoch 1188/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7935 - val_loss: 0.5008 - val_accuracy: 0.7797\n",
            "Epoch 1189/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7911 - val_loss: 0.5013 - val_accuracy: 0.7762\n",
            "Epoch 1190/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7970 - val_loss: 0.5040 - val_accuracy: 0.7727\n",
            "Epoch 1191/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7993 - val_loss: 0.5000 - val_accuracy: 0.7762\n",
            "Epoch 1192/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7946 - val_loss: 0.5018 - val_accuracy: 0.7657\n",
            "Epoch 1193/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7900 - val_loss: 0.5031 - val_accuracy: 0.7692\n",
            "Epoch 1194/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7946 - val_loss: 0.5016 - val_accuracy: 0.7797\n",
            "Epoch 1195/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7958 - val_loss: 0.5078 - val_accuracy: 0.7692\n",
            "Epoch 1196/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7970 - val_loss: 0.5011 - val_accuracy: 0.7762\n",
            "Epoch 1197/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7923 - val_loss: 0.4989 - val_accuracy: 0.7762\n",
            "Epoch 1198/1200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7958 - val_loss: 0.5061 - val_accuracy: 0.7727\n",
            "Epoch 1199/1200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7981 - val_loss: 0.5032 - val_accuracy: 0.7692\n",
            "Epoch 1200/1200\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7958 - val_loss: 0.4993 - val_accuracy: 0.7762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_B = (modelB.predict(X_test_normB) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_B = modelB.predict(X_test_normB)"
      ],
      "metadata": {
        "id": "YE5pBAh2LSgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6ec767-c74b-4bc2-8a22-3f232c2ed886"
      },
      "id": "YE5pBAh2LSgq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_testB,y_pred_class_nn_B)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_testB,y_pred_prob_nn_B)))\n",
        "\n",
        "plot_roc(y_testB, y_pred_prob_nn_B, 'NN')"
      ],
      "metadata": {
        "id": "gX66vF6gLfZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "10628078-74fc-4e55-870c-4951a9243ea5"
      },
      "id": "gX66vF6gLfZe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.837\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_B.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_B.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "tvkH2tPiLSXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f04e932d-c8f6-4fc7-d233-7aa3ef15d6c4"
      },
      "id": "tvkH2tPiLSXz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c5a1cc3f850>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbfElEQVR4nO3deVhU1f8H8PfMKKAoYCqbg+ACpuUWIKEtfpVCM1MrNX/uuWRpWZZbpi0umFpZtpjm1uZWamWmKZq5oCDupggqwpTgDkIpOnN+f1xnmIEZZgZmY3i/nuc+Mucuc+YK3A/nfM45MiGEABEREZELkzu7AkRERETmMGAhIiIil8eAhYiIiFweAxYiIiJyeQxYiIiIyOUxYCEiIiKXx4CFiIiIXB4DFiIiInJ51ZxdAVvQaDT4559/ULt2bchkMmdXh4iIiCwghMCNGzcQHBwMubzsNhS3CFj++ecfhISEOLsaREREVA7Z2dlQKpVlHuMWAUvt2rUBSB/Yx8fHybUhIiIiS+Tn5yMkJET3HC+LWwQs2m4gHx8fBixERESVjCXpHEy6JSIiIpfHgIWIiIhcHgMWIiIicnnlymH57LPPMHfuXOTk5KB169ZYsGAB2rVrZ/TYjh07YufOnaXKn3jiCfz6668AgCFDhmDFihUG++Pj47F58+byVI+IiKwkhMCdO3egVqudXRVyMwqFAtWqVavwtCNWByyrV6/GuHHjsHDhQsTExGD+/PmIj49HWloa/P39Sx2/bt06FBUV6V5fuXIFrVu3Ru/evQ2O69KlC5YtW6Z77enpaW3ViIioHIqKinDhwgX8+++/zq4KuamaNWsiKCgIHh4e5b6G1QHLhx9+iBEjRmDo0KEAgIULF+LXX3/F0qVLMWnSpFLH33PPPQavV61ahZo1a5YKWDw9PREYGGhtdYiIqAI0Gg3OnTsHhUKB4OBgeHh4cAJOshkhBIqKinDp0iWcO3cO4eHhZieIM8WqgKWoqAipqamYPHmyrkwulyMuLg5JSUkWXWPJkiV47rnn4O3tbVD+xx9/wN/fH3Xq1EGnTp0wY8YM1K1b1+g1bt26hVu3bule5+fnW/MxiIjorqKiImg0GoSEhKBmzZrOrg65oRo1aqB69eo4f/48ioqK4OXlVa7rWBXmXL58GWq1GgEBAQblAQEByMnJMXt+cnIyjh8/juHDhxuUd+nSBV9//TUSExPx/vvvY+fOnejatavJvtSEhAT4+vrqNs5yS0RUMeX9q5fIErb4/nLoxHFLlixBy5YtSyXoPvfcc7qvW7ZsiVatWqFJkyb4448/0Llz51LXmTx5MsaNG6d7rZ0pj4iIiNyTVSFPvXr1oFAokJuba1Cem5trNv+ksLAQq1atwrBhw8y+T+PGjVGvXj1kZGQY3e/p6amb1Zaz2xIREbk/qwIWDw8PREZGIjExUVem0WiQmJiI2NjYMs9du3Ytbt26hQEDBph9H5VKhStXriAoKMia6tmFSgXs2CH9S0RE7issLAzz5893djXIBKs7lcaNG4fFixdjxYoVOHnyJF588UUUFhbqRg0NGjTIIClXa8mSJejZs2epRNqCggKMHz8e+/btQ2ZmJhITE9GjRw80bdoU8fHx5fxYtrFkCRAaCnTqJP27ZIlTq0NERJDWnSlre+edd8p13ZSUFIwcObJCdevYsSNeffXVCl2DjLM6h6Vv3764dOkSpk2bhpycHLRp0wabN2/WJeJmZWWVSq5JS0vD7t278fvvv5e6nkKhwNGjR7FixQpcv34dwcHBePzxxzF9+nSnzsWiUgEjRwIajfRaowFeeAGIjwfMrIBNRFQ1qVRAejoQHm7XX5QXLlzQfb169WpMmzYNaWlpurJatWrpvhZCQK1Wo1o184+7+vXr27aiZFPlStsdM2YMzp8/j1u3bmH//v2IiYnR7fvjjz+wfPlyg+ObNWsGIQQee+yxUteqUaMGtmzZgosXL6KoqAiZmZlYtGhRqZFIjpaeXhysaKnVgIm0GiIi9yEEUFho3fb554ZN0p9/bv01hLCoeoGBgbrN19cXMplM9/rUqVOoXbs2fvvtN0RGRsLT0xO7d+/GmTNn0KNHDwQEBKBWrVqIjo7Gtm3bDK5bsktIJpPhq6++Qq9evVCzZk2Eh4fj559/rtCt/fHHH3HffffB09MTYWFh+OCDDwz2f/755wgPD4eXlxcCAgLw7LPP6vb98MMPaNmyJWrUqIG6desiLi4OhYWFFapPZeLQUUKVSXg4IJcbBi0KBdC0qfPqRETkEP/+C+i1UlhNowFGj5Y2axQUACXm6CqvSZMmYd68eWjcuDHq1KmD7OxsPPHEE5g5cyY8PT3x9ddfo3v37khLS0PDhg1NXufdd9/FnDlzMHfuXCxYsAD9+/fH+fPnS02KaonU1FT06dMH77zzDvr27Yu9e/fipZdeQt26dTFkyBAcOHAAr7zyCr755hu0b98eV69exa5duwBIrUr9+vXDnDlz0KtXL9y4cQO7du2CsDDIcwcMWExQKoFFiwDtlDEKBfDll+wOIiKqDN577z2DVv177rkHrVu31r2ePn061q9fj59//hljxowxeZ0hQ4agX79+AIBZs2bhk08+QXJyMrp06WJ1nT788EN07twZU6dOBQBERETgr7/+wty5czFkyBBkZWXB29sbTz75JGrXro3Q0FC0bdsWgBSw3LlzB08//TRCQ0MBSNOAVCWcKagMw4YB2mUPdu+WXhMRub2aNaXWDku3tDSpSVqfQiGVW3MdG860GxUVZfC6oKAAb7zxBpo3bw4/Pz/UqlULJ0+eRFZWVpnXadWqle5rb29v+Pj44OLFi+Wq08mTJ9GhQweDsg4dOiA9PR1qtRqPPfYYQkND0bhxYwwcOBDfffedbn2n1q1bo3PnzmjZsiV69+6NxYsX49q1a+WqR2XFgMUMbcBSr55z60FE5DAymdQ1Y+kWESE1SSsU0vnaJumICOuuY8M1jEou//LGG29g/fr1mDVrFnbt2oXDhw+jZcuWBovzGlO9evUSt0YGTckERxupXbs2Dh48iJUrVyIoKAjTpk1D69atcf36dSgUCmzduhW//fYbWrRogQULFqBZs2Y4d+6cXeriihiwmKH9Xr1927n1ICJyacOGAZmZ0sRVmZku1yS9Z88eDBkyBL169ULLli0RGBiIzMxMh9ahefPm2LNnT6l6RUREQHE32KtWrRri4uIwZ84cHD16FJmZmdi+fTsAKVjq0KED3n33XRw6dAgeHh5Yv369Qz+DMzGHxQwGLEREFlIqXTbRLzw8HOvWrUP37t0hk8kwdepUu7WUXLp0CYcPHzYoCwoKwuuvv47o6GhMnz4dffv2RVJSEj799FN8/vnnAICNGzfi7NmzeOSRR1CnTh1s2rQJGo0GzZo1w/79+5GYmIjHH38c/v7+2L9/Py5duoTmzZvb5TO4IgYsZjBgISKq/D788EM8//zzaN++PerVq4eJEyciPz/fLu/1/fff4/vvvzcomz59Ot566y2sWbMG06ZNw/Tp0xEUFIT33nsPQ4YMAQD4+flh3bp1eOedd3Dz5k2Eh4dj5cqVuO+++3Dy5En8+eefmD9/PvLz8xEaGooPPvgAXbt2tctncEUy4QZjovLz8+Hr64u8vDybryvUqJHUupmUBDz4oE0vTUTkdDdv3sS5c+fQqFEjeHl5Obs65KZMfZ9Z8/xmDosZbGEhIiJyPgYsZlSXSZHK7X8uObkmREREVRcDlrJ89RWqnz4BALjdbxBXPyQiInISBiymqFTACy/AA9IY/dtCIa1+qFI5uWJERERVDwMWU+6uflgdd7uEUJ2rHxIRETkJAxZT7q5+aBCwcPVDIiIip2DAYsrd1Q91AYvMk6sfEhEROQkDlrIMG4bqcmkmxNuTp7ncVNNERERVBQMWM+7IpIlYLt7ydXJNiIjIljp27IhXX31V9zosLAzz588v8xyZTIYNGzZU+L1tdZ2qhAFLGZYsAbaq/wcAmPRhfY5qJiJyAd27d0eXLl2M7tu1axdkMhmOHj1q9XVTUlIwcuTIilbPwDvvvIM2bdqUKr9w4YLdp9Vfvnw5/Pz87PoejsSAxQSVCpC+b6XlzoWQcVQzEZELGDZsGLZu3QqVkV/Iy5YtQ1RUFFq1amX1devXr4+aNWvaoopmBQYGwtPT0yHv5S4YsJhwd1SzAY5qJiIyTaUCduyw/x92Tz75JOrXr4/ly5cblBcUFGDt2rUYNmwYrly5gn79+qFBgwaoWbMmWrZsiZUrV5Z53ZJdQunp6XjkkUfg5eWFFi1aYOvWraXOmThxIiIiIlCzZk00btwYU6dOxe27a7ksX74c7777Lo4cOQKZTAaZTKarc8kuoWPHjqFTp06oUaMG6tati5EjR6KgoEC3f8iQIejZsyfmzZuHoKAg1K1bF6NHj9a9V3lkZWWhR48eqFWrFnx8fNCnTx/k5ubq9h85cgT/+9//ULt2bfj4+CAyMhIHDhwAAJw/fx7du3dHnTp14O3tjfvuuw+bNm0qd10swdWaTbg7qtkgaOGoZiKqCoQA/v3XunNWrABefln6nSmXAwsWAIMHW3eNmjUBmcz8cdWqVcOgQYOwfPlyTJkyBbK7J61duxZqtRr9+vVDQUEBIiMjMXHiRPj4+ODXX3/FwIED0aRJE7Rr187se2g0Gjz99NMICAjA/v37kZeXZ5DvolW7dm0sX74cwcHBOHbsGEaMGIHatWtjwoQJ6Nu3L44fP47Nmzdj27ZtAABf39L5kIWFhYiPj0dsbCxSUlJw8eJFDB8+HGPGjDEIynbs2IGgoCDs2LEDGRkZ6Nu3L9q0aYMRI0aYv2lGPp82WNm5cyfu3LmD0aNHo2/fvvjjjz8AAP3790fbtm3xxRdfQKFQ4PDhw6h+d4G90aNHo6ioCH/++Se8vb3x119/oVatWlbXwyrCDeTl5QkAIi8vz6bX/eorIWRQC0AImUwjvvrKppcnInK6//77T/z111/iv//+05UVFAghhS2O3QoKLK/3yZMnBQCxY8cOXdnDDz8sBgwYYPKcbt26iddff133+tFHHxVjx47VvQ4NDRUfffSREEKILVu2iGrVqom///5bt/+3334TAMT69etNvsfcuXNFZGSk7vXbb78tWrduXeo4/essWrRI1KlTRxTo3YBff/1VyOVykZOTI4QQYvDgwSI0NFTcuXNHd0zv3r1F3759TdZl2bJlwtfX1+i+33//XSgUCpGVlaUrO3HihAAgkpOThRBC1K5dWyxfvtzo+S1bthTvvPOOyfcuydj3mRDWPb/ZJVSGYcOAMXVXAQCGPPY3RzUTEbmIe++9F+3bt8fSpUsBABkZGdi1axeG3f1FrVarMX36dLRs2RL33HMPatWqhS1btiArK8ui6588eRIhISEIDg7WlcXGxpY6bvXq1ejQoQMCAwNRq1YtvPXWWxa/h/57tW7dGt7e3rqyDh06QKPRIC0tTVd23333QaFQ6F4HBQXh4sWLVr2X/nuGhIQgJCREV9aiRQv4+fnh5MmTAIBx48Zh+PDhiIuLw+zZs3HmzBndsa+88gpmzJiBDh064O233y5XkrO1GLCYEeB5HQCggKbsA4mI3ETNmkBBgeVbWprUDaRPoZDKrbmOtfmuw4YNw48//ogbN25g2bJlaNKkCR599FEAwNy5c/Hxxx9j4sSJ2LFjBw4fPoz4+HgUFRXZ6C4BSUlJ6N+/P5544gls3LgRhw4dwpQpU2z6Hvq03TFaMpkMmpLJljb0zjvv4MSJE+jWrRu2b9+OFi1aYP369QCA4cOH4+zZsxg4cCCOHTuGqKgoLFiwwG51ARiwmFWj+h0AwH83LehYJSJyAzIZ4O1t+RYRASxaJAUpgPTvl19K5dZcx5L8FX19+vSBXC7H999/j6+//hrPP/+8Lp9lz5496NGjBwYMGIDWrVujcePGOH36tMXXbt68ObKzs3HhwgVd2b59+wyO2bt3L0JDQzFlyhRERUUhPDwc58+fNzjGw8MDarXa7HsdOXIEhYWFurI9e/ZALpejWbNmFtfZGtrPl52drSv766+/cP36dbRo0UJXFhERgddeew2///47nn76aSxbtky3LyQkBKNGjcK6devw+uuvY/HixXapqxYDFjO8qkvfaAxYiIhMGzYMyMyURgllZjpmYvBatWqhb9++mDx5Mi5cuIAhQ4bo9oWHh2Pr1q3Yu3cvTp48iRdeeMFgBIw5cXFxiIiIwODBg3HkyBHs2rULU6ZMMTgmPDwcWVlZWLVqFc6cOYNPPvlE1wKhFRYWhnPnzuHw4cO4fPkybt26Veq9+vfvDy8vLwwePBjHjx/Hjh078PLLL2PgwIEICAiw7qaUoFarcfjwYYPt5MmTiIuLQ8uWLdG/f38cPHgQycnJGDRoEB599FFERUXhv//+w5gxY/DHH3/g/Pnz2LNnD1JSUtC8eXMAwKuvvootW7bg3LlzOHjwIHbs2KHbZy8MWMzQtbDc4q0iIiqLUgl07OjYJdeGDRuGa9euIT4+3iDf5K233sIDDzyA+Ph4dOzYEYGBgejZs6fF15XL5Vi/fj3+++8/tGvXDsOHD8fMmTMNjnnqqafw2muvYcyYMWjTpg327t2LqVOnGhzzzDPPoEuXLvjf//6H+vXrGx1aXbNmTWzZsgVXr15FdHQ0nn32WXTu3BmffvqpdTfDiIKCArRt29Zg6969O2QyGX766SfUqVMHjzzyCOLi4tC4cWOsXr0aAKBQKHDlyhUMGjQIERER6NOnD7p27Yp3330XgBQIjR49Gs2bN0eXLl0QERGBzz//vML1LYtMCCHs+g4OkJ+fD19fX+Tl5cHHx8em117VZjb6HZmE/zW/gO1/Bdn02kREznbz5k2cO3cOjRo1gpeXl7OrQ27K1PeZNc9vNhuYUUNIkxHkXKnGWW6JiIichAFLWZYswc6jfgCAkxfrI7ShhusJEREROQEDFlNUKqhGvIuPMVZXpBFyvPCCYEsLERGRgzFgMSU9HemiCTRQGBSr1TKuJ0RERORgDFhMCQ9HuOwM5DAcP69QCK4nRERE5GAMWExRKqFc/DZm4C1dkUKuwZdfyhw6ZI+IyBHcYMAouTBbfH8xYCnLsGEYPES6RXKokXlezvWEiMitaKd7/9fa5ZmJrKD9/iq5vIA1qtmqMu6qRpAfAEADBSo44SARkctRKBTw8/PTLaJXs2ZN3fT2RBUlhMC///6Lixcvws/Pz2DxRmsxYDGjRq3im/vff0AFgkMiIpcUGBgIAOVe+ZfIHD8/P933WXkxYDHDs7aH7uszZ4C2bZ1YGSIiO5DJZAgKCoK/vz9u377t7OqQm6levXqFWla0GLCYsfRAKwACgAxRUdKKpMxjISJ3pFAobPJgIbIHJt2WQaUCRn7zMACpP1ejAV54AZw4joiIyMEYsJQhPR3QCMPkM7UanDiOiIjIwRiwlCG81oXSE8fhDpp6X3BSjYiIiKomBixlUBacwiKMhJTDIs3F8iVegLIwzbkVIyIiqmIYsJQlPBzD5MvxCHYCAD7AOAxTrADn5iciInIsBixlUSqBGTMQAGluAoUMwJdfgnPzExEROVa5ApbPPvsMYWFh8PLyQkxMDJKTk00e27FjR8hkslJbt27ddMcIITBt2jQEBQWhRo0aiIuLQ3p6enmqZnvDh8MH+QCAw71nQBXPMc1ERESOZnXAsnr1aowbNw5vv/02Dh48iNatWyM+Pt7kDInr1q3DhQsXdNvx48ehUCjQu3dv3TFz5szBJ598goULF2L//v3w9vZGfHw8bt68Wf5PZis+PshCCABg6ZraCA0Flixxcp2IiIiqGJmwcgnFmJgYREdH49NPPwUAaDQahISE4OWXX8akSZPMnj9//nxMmzYNFy5cgLe3N4QQCA4Oxuuvv4433ngDAJCXl4eAgAAsX74czz33nNlr5ufnw9fXF3l5efDx8bHm45ilUgENQzQQerGdQgFkZrJniIiIqCKseX5b1cJSVFSE1NRUxMXFFV9ALkdcXBySkpIsusaSJUvw3HPPwdvbGwBw7tw55OTkGFzT19cXMTExJq9569Yt5OfnG2z2kv7xJoNgBeBcLERERI5mVcBy+fJlqNVqBJRYtjggIAA5OTlmz09OTsbx48cxfPhwXZn2PGuumZCQAF9fX90WEhJizcewnEqF8A9GQQaNQbFCIThQiIiIyIEcOkpoyZIlaNmyJdq1a1eh60yePBl5eXm6LTs720Y1LCE9HUqRjVFYqCtS4A6+fC2N3UFEREQOZFXAUq9ePSgUCuTm5hqU5+bmml02urCwEKtWrcKwEisHas+z5pqenp7w8fEx2OwiPByQy9EL66W64m8kyTpg2Nha9nk/IiIiMsqqgMXDwwORkZFITEzUlWk0GiQmJiI2NrbMc9euXYtbt25hwIABBuWNGjVCYGCgwTXz8/Oxf/9+s9e0O6USWLQIO/EoACAHDfAgkrBkC5tXiIiIHKmatSeMGzcOgwcPRlRUFNq1a4f58+ejsLAQQ4cOBQAMGjQIDRo0QEJCgsF5S5YsQc+ePVG3bl2DcplMhldffRUzZsxAeHg4GjVqhKlTpyI4OBg9e/Ys/yezEVX8MCTo5bBohBwvvADEx3OUEBERkaNYHbD07dsXly5dwrRp05CTk4M2bdpg8+bNuqTZrKwsyOWGDTdpaWnYvXs3fv/9d6PXnDBhAgoLCzFy5Ehcv34dDz30EDZv3gwvL69yfCTbSk8HNCZGCTFgISIicgyr52FxRXadhyXlAkLb+UMDha5MgTvITL4EZXSQTd+LiIioKrHbPCxVkbLgFAbia2hXbAYEBuAbrthMRETkQAxYzFDVuhffYBAA2d0SGb7FQKi8mzmzWkRERFUKAxYz0guCDLqDAECNasgoZHcQERGRozBgMSM8HJDLSsx0K9dwplsiIiIHYsBihhIqLMILetPza5CgmQQlVE6tFxERUVXCgMWc9HQME18hDtvuFsgxCQlY8nGBU6tFRERUlTBgMSc8HCpZCLaheDVpDRR44aNmULGRhYiIyCEYsJijVCL9sZcgSk0eJ0NGhpPqREREVMUwYDFHpUL41s8hh9qgWKEQTLwlIiJyEAYs5qSnQymy8SR+0SsUGBCXw6n5iYiIHIQBizl3c1g2orteoQzfbgtkDgsREZGDMGAxR6lE+usLS08exxwWIiIih2HAYoHwPm1L57DgDpp6X3BSjYiIiKoWBiwW4AKIREREzsWAxQJcAJGIiMi5GLBYgAsgEhERORcDFguE17pQKodFzhwWIiIih2HAYgFlwSkswkgAxas2C8ixZU2e8ypFRERUhTBgsUR4OOLxuy6DBZACFq4nRERE5BgMWCyUjnCuJ0REROQkDFgskZ6OcJwuPReLnOsJEREROQIDFkuEh0Mpv4DnsFKvUGDAA8e5nhAREZEDMGCxhFIJ1aRPsQr99Apl+PZAc6hSOFKIiIjI3hiwWCi97oPG52LZk+ukGhEREVUdDFgsFP5woPG5WDoEOKlGREREVQcDFgspo4OwKGYpSs3FcpSz3RIREdkbAxZLqVSIT55eei6WFwTnYiEiIrIzBiyWSk9HumjCuViIiIicgAGLpcLDES47A5lelxAAKGQazsVCRERkZwxYLKVUQvn+y+iERL1CgQHiGyjBPiEiIiJ7YsBiBVVoB+xAJ70SGb5Ff6iSsp1WJyIioqqAAYsV0hFufC4WsE+IiIjInhiwWCG8ff1SOSwyaNA0tr6TakRERFQ1MGCxxoXS0/DLIIyWExERke0wYLFC+q6cUsOaNVBwen4iIiI7Y8BiBU7PT0RE5BwMWKygDFJjEV5Aqen5d3o6r1JERERVAAMWa6SnIx6bS0/PP7EOp+cnIiKyIwYs1ggPR7qsWenp+TWcnp+IiMieGLBYQ6lE+PvDS0/PL+f0/ERERPbEgMVKyn4PIx5b9EoEBmg4PT8REZE9MWCxkmpvFn7H43olnJ6fiIjI3hiwWInT8xMRETkeAxYrhbevD3nJHBaZmtPzExER2REDFispocJAfANA3C0RGCC+ZQ4LERGRHZUrYPnss88QFhYGLy8vxMTEIDk5uczjr1+/jtGjRyMoKAienp6IiIjApk2bdPvfeecdyGQyg+3ee+8tT9XsTrU3C99gAKCbjYU5LERERPZWzdoTVq9ejXHjxmHhwoWIiYnB/PnzER8fj7S0NPj7+5c6vqioCI899hj8/f3xww8/oEGDBjh//jz8/PwMjrvvvvuwbdu24opVs7pqDlFWDovSSXUiIiJyd1ZHBR9++CFGjBiBoUOHAgAWLlyIX3/9FUuXLsWkSZNKHb906VJcvXoVe/fuRfXq1QEAYWFhpStSrRoCAwOtrY7DhTe6AznUBkGLHHfQNOyOE2tFRETk3qzqEioqKkJqairi4uKKLyCXIy4uDklJSUbP+fnnnxEbG4vRo0cjICAA999/P2bNmgW12nARwfT0dAQHB6Nx48bo378/srKyTNbj1q1byM/PN9gcRVlwCoswEqXWE1qT57A6EBERVTVWBSyXL1+GWq1GQIDh6sQBAQHIyckxes7Zs2fxww8/QK1WY9OmTZg6dSo++OADzJgxQ3dMTEwMli9fjs2bN+OLL77AuXPn8PDDD+PGjRtGr5mQkABfX1/dFhISYs3HqJjwcMTLtpZeT+ijZlxPiIiIyE7sPkpIo9HA398fixYtQmRkJPr27YspU6Zg4cKFumO6du2K3r17o1WrVoiPj8emTZtw/fp1rFmzxug1J0+ejLy8PN2Wne3AhFelEumvLyy9npCa6wkRERHZi1U5LPXq1YNCoUBubq5BeW5ursn8k6CgIFSvXh0KRXHOR/PmzZGTk4OioiJ4eHiUOsfPzw8RERHIMBEBeHp6wtPT05qq21R4n7aQzzPMY1HgDpp6XwIQ5LR6ERERuSurWlg8PDwQGRmJxMREXZlGo0FiYiJiY2ONntOhQwdkZGRAoynO+Th9+jSCgoKMBisAUFBQgDNnziAoyDUf/sqCU3gGP+iVCAzAN1AWpjmtTkRERO7M6i6hcePGYfHixVixYgVOnjyJF198EYWFhbpRQ4MGDcLkyZN1x7/44ou4evUqxo4di9OnT+PXX3/FrFmzMHr0aN0xb7zxBnbu3InMzEzs3bsXvXr1gkKhQL9+/WzwEW1PVete/Ihn9Upk+BYDofJu5rQ6ERERuTOrhzX37dsXly5dwrRp05CTk4M2bdpg8+bNukTcrKwsyOXFcVBISAi2bNmC1157Da1atUKDBg0wduxYTJw4UXeMSqVCv379cOXKFdSvXx8PPfQQ9u3bh/r1XXO6+/SCoBKT89+di6UwiHOxEBER2YFMCCHMH+ba8vPz4evri7y8PPj4+Nj9/VQpFxDazr9UDktm8iUoo12zG4uIiMjVWPP85lpC5VA8F4sU68mgRgImMYeFiIjIThiwlEd4OIbJlyMSBwAAAgpMwvtYcqCVkytGRETknhiwlIdSCdXsb3EQkboiDRR4YaIfJ48jIiKyAwYs5ZQeGld68jiNHBlJl5xUIyIiIvfFgKWcwpEOWYmxQgrcQVNwulsiIiJbY8BSTsr2DfEYftcrERiA76CMdeC6RkRERFUEA5ZyUkGJbXhcr0SGb2UDoOJMLERERDbHgKWc0vdegqZkDotQMIeFiIjIDhiwlFM40iGH2qCMOSxERET2wYClnJTtG2IgvoV28jjmsBAREdkPA5ZyUkGJb2QDAcjuljCHhYiIyF4YsJRT+t5L0AjmsBARETkCA5ZyYg4LERGR4zBgKSdl+4ZYJBulN3mcRloA8fwep9aLiIjIHTFgKS+lEsPej8CT+OVugVxaAHFCGrigEBERkW0xYKkAVWgHbER33WsNFHhBfAFVUrYTa0VEROR+GLBUQDrCSy+AiGrIQFMn1YiIiMg9MWCpgPD29SEvuQCiTI2msfWdVCMiIiL3xIClApRQoTfW6JUIDBDfQgnmsBAREdkSA5YKUO3Nwlr01iuR4Vv0Zw4LERGRjTFgqYB0hEMDhUEZc1iIiIhsjwFLBYS3rw+5jDksRERE9saApQKUUGGg+AYGCyAyh4WIiMjmGLBUgGpvFr7BABgsgMgcFiIiIptjwFIBzGEhIiJyDAYsFWAsh0WOO2iauc1JNSIiInJPDFgqQKkEFs25rrcAIiAgx5aJ27meEBERkQ0xYKmg+IanDF4LyLmeEBERkY0xYKkgridERERkfwxYKii80R3IoTYoU+AOmobdcVKNiIiI3A8DlgpSFpzCAJSYiwXfQFmY5sxqERERuRUGLBWkqnUvvsVAGM7FMhCqbafKOo2IiIiswIClgtILgozPxZKwliOFiIiIbIQBSwWFhwNyuTAok+MOmmrSgIwMJ9WKiIjIvTBgqSClElj0/jWg5Fwssq5AU44UIiIisgUGLDYQ/9w9kOlyWO7OxYKFUEHpxFoRERG5DwYsNpC+9xKEXsACAGqhQEbSJSfViIiIyL0wYLGBcKQbTM8P3J2LBcxhISIisgUGLDagbN8QcdBf8FBgAL6FMjbEaXUiIiJyJwxYbEB1QYFEdNYrkeFbDIDqgsLkOURERGQ5Biw2kL4rx/hcLPM2OKdCREREboYBiw2EPxxofD2hH2Zz8jgiIiIbYMBiA8roIAy87yBKrSekyeLkcURERDbAgMUGVCrgm5NRKLWeEJScPI6IiMgGyhWwfPbZZwgLC4OXlxdiYmKQnJxc5vHXr1/H6NGjERQUBE9PT0RERGDTpk0VuqYrSU8HNJoS87CgGjJk4U6qERERkXuxOmBZvXo1xo0bh7fffhsHDx5E69atER8fj4sXLxo9vqioCI899hgyMzPxww8/IC0tDYsXL0aDBg3KfU1XY2w9IUDggHiAXUJEREQ2IBNClHzSlikmJgbR0dH49NNPAQAajQYhISF4+eWXMWnSpFLHL1y4EHPnzsWpU6dQvXp1m1yzpPz8fPj6+iIvLw8+Pj7WfBybmfvWNUyY6QfozXirwB1kJl+CMjrIKXUiIiJyZdY8v61qYSkqKkJqairi4uKKLyCXIy4uDklJSUbP+fnnnxEbG4vRo0cjICAA999/P2bNmgW1Wl3ua966dQv5+fkGm7NFtboDlJyeH9WQkVnNORUiIiJyI1YFLJcvX4ZarUZAQIBBeUBAAHJycoyec/bsWfzwww9Qq9XYtGkTpk6dig8++AAzZswo9zUTEhLg6+ur20JCnD+jbDjSjQ9tTvzSSTUiIiJyH3YfJaTRaODv749FixYhMjISffv2xZQpU7Bw4cJyX3Py5MnIy8vTbdnZ2Tascfko2zfEM/hRr+Tu0Oav3uFcLERERBVkVcBSr149KBQK5ObmGpTn5uYiMDDQ6DlBQUGIiIiAQlE8E2zz5s2Rk5ODoqKicl3T09MTPj4+BpuzqaDEj7Jn9UruDm1WBzLxloiIqIKsClg8PDwQGRmJxMREXZlGo0FiYiJiY2ONntOhQwdkZGRAoylezfj06dMICgqCh4dHua7pitLTAY0wvJ1qVEMGmgLe3k6qFRERkXuwukto3LhxWLx4MVasWIGTJ0/ixRdfRGFhIYYOHQoAGDRoECZPnqw7/sUXX8TVq1cxduxYnD59Gr/++itmzZqF0aNHW3zNyiA8HJDJDAdcyaBGU2QAa9Y4qVZERETuweohLH379sWlS5cwbdo05OTkoE2bNti8ebMuaTYrKwtyeXEcFBISgi1btuC1115Dq1at0KBBA4wdOxYTJ060+JqVlW7M0EcfAWPHAkqlM6tDRERUaVk9D4srcoV5WHbsADp1MlKOjuiIndIBHTs6vF5ERESuym7zsJBp0my3JUsFDiBK+pJ5LEREROXGgMVGlEpg9mygeMVmAJBhEmZDhQZAYaGTakZERFT5MWCxoagowOhst2jKVZuJiIgqgAGLDRlbBFGBO9JIoVWrnFQrIiKiyo8Biw0plcCAzjko7ha6O9st/gYmTuSMt0REROXEgMWGVCrg28RAFHcL3Z3tFg0AjYYz3hIREZUTAxYbSk8HNBoTOSwARwoRERGVEwMWGzI7tJkjhYiIiMqFAYsNmR3avG2bk2pGRERUuTFgsbEyhzYnJDDxloiIqBwYsNhYrVqAYQuL9NobhUy8JSIiKicGLDZWUACUbGEBZCjE3YRbdgsRERFZjQGLjYWHA7IS8YoMamnyOACYNYvdQkRERFZiwOIABvGLEEBSkrOqQkREVCkxYLGx9HQpJtGngaJ4LhYiIiKyGgMWGzM7FwsAHDniyCoRERFVegxYbKx4LhZ9enOxAMxjISIishIDFjuIiipdZjBFP/NYiIiIrMKAxQ6kuVhKujsXi9bPPzuqOkRERJUeAxY7kOZiKUlvLhYA+PZbdgsRERFZiAGLHZidi0Vr5kzHVYqIiKgSY8DiTAsXspWFiIjIAgxY7MDYXCwCCnyMV0ofPHmyYypFRERUiTFgsQNjXUIA8BHGFQ9t1mIuCxERkVkMWOxAqQRef710ucHQZn0c4kxERFQmBix20qePsdISQ5u1EhLsXR0iIqJKjQGLnZga2rwGvUsXHzoEvPWWvatERERUaTFgsROr8lgAaYgzc1mIiIiMYsBiJ1bnsQAcMURERGQCAxY7Mp7HAniH1je+gyOGiIiIjGLAYkfG81iAwknTTZ/0ipG5WoiIiKo4Bix2ZHwRRMA78l6gVSvjO9evB+bNs1+liIiIKiEGLHZkqoVlzRoAX31l+sTx49k1REREpIcBix2ZGin0wQeAKigaeOQR0yc/9ZT9KkZERFTJMGCxI6USGDmydLkQdye3/e470ycfOsR8FiIiorsYsNhZp05l7FQqgTffNL1/wQLmsxAREYEBi901amS8/MiRu1/MnAm0bWv6AsxnISIiYsBib6YSbxMS9OKQn38u+yJduti0TkRERJUNAxY7M5V4q9EAGRl3XyiVwJw5pi9y4gTQoYNd6kdERFQZMGCxM6XS9Iz727bpvRg/Hnj5ZdMX2ruXQQsREVVZDFgcIC7OeLlBtxAAfPJJ2fkse/cCnTvbtG5ERESVAQMWB7CoW0jLXD7L9u3A88/brG5ERESVAQMWByirW8jb28jBZc2CCwDLlrGlhYiIqhQGLA7SurXx8qVLjRQOGwYkJ5d9we3bmdNCRERVBgMWJ/vySxPTrERHlz1yCGAiLhERVRnlClg+++wzhIWFwcvLCzExMUguozVg+fLlkMlkBpuXl5fBMUOGDCl1TBc3m3ukfXvj5bpp+o0ZPx6YMqXsCzNoISKiKsDqgGX16tUYN24c3n77bRw8eBCtW7dGfHw8Ll68aPIcHx8fXLhwQbedP3++1DFdunQxOGblypXWVs2lmVpXyKwZMywLWqKiylUvIiKiysDqgOXDDz/EiBEjMHToULRo0QILFy5EzZo1sdRoMoZEJpMhMDBQtwUEBJQ6xtPT0+CYOnXqWFs1lzd8uPFy3TT9plgStKSmAoGBnMafiIjcklUBS1FREVJTUxGnN7GIXC5HXFwckkz2awAFBQUIDQ1FSEgIevTogRMnTpQ65o8//oC/vz+aNWuGF198EVeuXDF5vVu3biE/P99gqwxMTdM/c6YFccaMGcDcuWUfk5sLhISYP46IiKiSsSpguXz5MtRqdakWkoCAAOTk5Bg9p1mzZli6dCl++uknfPvtt9BoNGjfvj1Uek/oLl264Ouvv0ZiYiLef/997Ny5E127doVarTZ6zYSEBPj6+uq2kJAQaz6G04SHm943c6YFF3jjDfOjhwBgwgTgrbcsrhcREZGrkwkhhKUH//PPP2jQoAH27t2L2NhYXfmECROwc+dO7N+/3+w1bt++jebNm6Nfv36YPn260WPOnj2LJk2aYNu2behsZL6RW7du4datW7rX+fn5CAkJQV5eHnx8fCz9OE7xwgvAokWly2UyICtLynUxa8kS0/1L+l5+WZo9l4iIyAXl5+fD19fXoue3VS0s9erVg0KhQG5urkF5bm4uAgMDLbpG9erV0bZtW2SUmuK1WOPGjVGvXj2Tx3h6esLHx8dgqyymTjVeXuZooZKGDQOyswEjuUAGFizgBHNEROQWrApYPDw8EBkZicTERF2ZRqNBYmKiQYtLWdRqNY4dO4agoCCTx6hUKly5cqXMYyorpRL4v/8zvs/crPylLpSTAzRpUvZx27dzBBEREVV6Vo8SGjduHBYvXowVK1bg5MmTePHFF1FYWIihQ4cCAAYNGoTJevPQv/fee/j9999x9uxZHDx4EAMGDMD58+cx/G6XRkFBAcaPH499+/YhMzMTiYmJ6NGjB5o2bYr4+HgbfUzX0qOH8fLvvivHIJ+MDKBPn7KPSU0FGjTgCCIiIqq0qll7Qt++fXHp0iVMmzYNOTk5aNOmDTZv3qxLxM3KyoJcXhwHXbt2DSNGjEBOTg7q1KmDyMhI7N27Fy1atAAAKBQKHD16FCtWrMD169cRHByMxx9/HNOnT4enp6eNPqZrMTeJXO/eVl5w9Wrg8mWpNcWUf/6RRhDNmSNNSEdERFSJWJV066qsSdpxFf37A99/X7q8bVvg4MFyXvTJJ4FffzV/HJNxiYjIBdgt6ZZsx1S30KFDFRiRvHEj8Msv5o9bsAC4/352ERERUaXBgMVJTHULARZOJGfKk08CX31l/rgTJzjJHBERVRoMWJxEqQTefNP0fouHOBujHfbcrJn5YydMAJ5/vgJvRkREZH8MWJxo5kygTRvj+z78sIIXVyqBU6fKbsrRWrYMaNq0gm9IRERkPwxYnExvBLiBffuAlBQbvMGePUC3buaPO3OGiycSEZHLYsDiZGU1gJTVZWSVjRulNYjq1i37OO3iieZWhiYiInIwBixOVtbMt9u2AfPm2eiNoqOluVos6SKaNUtaqdEmTTxEREQVx4DFBbz/vul948fbuJdmzx7LWlAyMoB27SzrTiIiIrIzBiwuQKkERo40vX/mTBu/4YwZli2eCACbNgGNGrG1hYiInIoBi4swtYozACxcaIdcWO3iiZGR5o/NzJRaW9q2ZVIuERE5BQMWF+HwVhatAweATp0sO/bwYSkpt1cvBi5ERORQDFhciMNbWbQSE60bGbRhgxS49O/PwIWIiByCAYsLMdfKYvUqztbQ5rX06mX5Od9/LwUuL79sv3oRERGBAYvLKauVZd++CiyMaAmlEli3zvr1hT79FPDxkYZDs8WFiIjsgAGLi1EqgTlzTO+v0MKIlnrjDam1ZcAAy8+5cUPqVmJXERER2QEDFhc0fnzZPTOvvOKASiiVwDffSIHL009bdy67ioiIyMYYsLioTz4xvW/9ehvOgGuOUgn8+KMUuDzwgHXnfvop4O/POVyIiKjCGLC4KKWy7LWEbD4DrjlKJZCaKq1J1KKF5eddusQ5XIiIqMIYsLiwmTOBmBjT+596ynF10YmOBk6ckAKX8HDLz9PO4RIdDXzxBYMXIiKyCgMWF/fDD6b3HTrkoHwWY6KjgdOnrQ9cDhwAXnqJOS5ERGQVBiwuzlzX0IIFDsxnMUY/cLGmqwjgcGgiIrKYTAghnF2JisrPz4evry/y8vLg4+Pj7OrYxQMPSC0qpmRnS8GN06WkAH36SOsPWev//k9autolPggREdmbNc9vtrBUEj//XPb+Ll0cUw+zoqOBc+esm+pfSzscmmsVERFRCQxYKglzE8qdOAF07uy4+pilnerf2jlcgOK1ihi4EBHRXQxYKpHx48vOU92+3YlJuMboz+EyaxbQoIF152sDl7g4zuVCRFTFMWCpZD75BOjUyfT+BQvsvN5QeSiVwOTJUmuJtaOKAGk1ac7lQkRUpTFgqYQSE4H77jO9f+ZMFwxatMo7HBoonsuFXUVERFUOA5ZKavPmsvfPnOnk4c7mVGQ4NLuKiIiqHAYslZS5+VkAJ0zfXx76M+c+/LB157KriIioymDAUonNnAl061b2MS4z3Nmc6Gjgzz/Lt8iitqvooYfY4kJE5KYYsFRyGzcCQ4ea3n/iBNChg+PqU2H6iyw+9ph15+7ZI7W4NG/OwIWIyM0wYHEDS5eWPXJo795KFrQAUovL77+Xby6XU6ekwKVpUwYuRERuggGLm0hMBNq3N71/714gKspx9bEZ/blcrO0qOnNGClwaNJCaooiIqNJiwOJG9uwpe7hzaioQFuaw6thWRbqK/vkH6N4dCApiiwsRUSXFgMXNmBvufP48EBhYiQfVVKSrKCeHXUVERJUUAxY3Y27NIQDIzZUG1cyd65g62YV+V5G1gQu7ioiIKh0GLG5o/HjLgpEJE1x4RlxL6QcuAwZYd662q+ieexi4EFGloVIBO3ZU4pbycpIJIYSzK1FR+fn58PX1RV5eHnx8fJxdHZehUkmJtrm5ZR/38svSGkVuQaUCvvlGama6ft26c318pNlzhw4FnnzSLtUjIvehUgHp6UCtWkBBQfG/4eHS31L2sGQJMHIkoNEAcjmwaBEwbJh93gso/oz2+kzWPL8ZsFQBYWFS7kpZ2reXknbdysaNwIgRUu6KtUJCpKFV9vqtQ0QWs/dDszwWLADGjgWMPUFLBhIl62/J5zF2jEoFhIZKwYqWQgEkJQHnzkmvGzUqHTSZe7+SgZf2OEcER1Y9v4UbyMvLEwBEXl6es6visiIjhZB+tExvdesKkZzs7JrawZQp5j+8qa1nTyGys539CYiqrK++EkIul34c5XLptbNlZ5v/1SGTSceVrP/gwcY/T3a2EKtXS9vcucXHAEK8+aZ0zPbtpt+rZJn22mXdv+xsIV54ofT5crkQc+YY1kFbbutfh9Y8v9nCUoV06CA1Gpjz7LPA2rX2r49DVaSrCAAiIoDBg4FBg1znTzwiN2eqRSEz0zk/hikpwC+/APn5wMcfmz/+0UeBXbsM61+SQgHMni3lFJb1NO7WTfr1069f2dfTJ5NJm7H7t2ULMHx42ecaq88bb9h2wAa7hMikzp2B7dvNH+dWeS0lbdwIjBoF/P13+c7v2VNqD2bgQmRXO3YYn8V7xw6gY0f7vnfJbpQhQ4AVK+z7no6yZg3Qt2/ZAZIptg4YrXl+c5RQFZOYKAUj5ixY4AYjiEx58knpt1FyMuDvb/35GzZIOS733w/MmlX1UvWJHCQ8XPpLX59CIU2lZE9LlkgtO506Sf9OmeI+wQoAJCSUL1gBALUayMiwbX0sxYClCvrkE8ua9GbOdOOgBZAmocvNldp4n30WqF3buvNPnJB+k4WEAP37M3AhsoA1Q3KVSsNuC4UC+PJL2zduauuUkiK1PmgTTQHp34QE276fsx06VLHzDxywTT2sxS6hKkylArp2BY4fL/u4KVOAGTMcUyene+UVqXmpvKKigOefl+Z3YZcRkYHyjDpZvrx4Rfq0NCmdzFZUKikX5cMPLc8LIdt2C9m9S+izzz5DWFgYvLy8EBMTg+TkZJPHLl++HDKZzGDz8vIyOEYIgWnTpiEoKAg1atRAXFwc0tPTy1M1soJSCRw7VvzLwJSZM6VncJXwySflmz1X68AB4KWXpFaXhx7iEgBEd6lUpVsuXnjBfEvLrVuGX5dsoTH1WttasmaNVFayfNQo6cd03jwGK9ZyWreQtUOQVq1aJTw8PMTSpUvFiRMnxIgRI4Sfn5/Izc01evyyZcuEj4+PuHDhgm7LyckxOGb27NnC19dXbNiwQRw5ckQ89dRTolGjRuK///6zqE4c1lxx3bqZH6YXHFzFRvhmZwsxa5YQzZqVf1g0IESbNlXsxhGVZmpI7o4dxo/PzpbO0f/dpD/8ViYT4tlnTQ8ZtmToL7fybQqF7X6lWfP8tjpgadeunRg9erTutVqtFsHBwSIhIcHo8cuWLRO+vr4mr6fRaERgYKCYO3euruz69evC09NTrFy50qI6MWCxjaFDLftm1c4JUKVkZwvxwAMV+ylv21aIX35x9ichcors7NLBhEIhzf20fXvxAzA7W4g33jAdeHBz7iaT2XYuHGue31Z1CRUVFSE1NRVxcXG6Mrlcjri4OCQlJZk8r6CgAKGhoQgJCUGPHj1w4sQJ3b5z584hJyfH4Jq+vr6IiYkxec1bt24hPz/fYKOKW7rU+BDCkmbNkuZ0qVKUSiA1VRpZ9NprUluytQ4dknJb6tYFvviCSbrkNixNpB03zvB1r17Agw8Wj8Z5+ml207g6IZz33lYFLJcvX4ZarUZAQIBBeUBAAHJMTH/erFkzLF26FD/99BO+/fZbaDQatG/fHqq739na86y5ZkJCAnx9fXVbSHkeHmRUYqJlQcvevUC9elUwRSM6WsrQy8qSgpcWLay/xtWrzHMht1FyCPCSJaaPmTfPsPyHHwxzWtavt399qeIsyT2yB7sPa46NjcWgQYPQpk0bPProo1i3bh3q16+PL7/8stzXnDx5MvLy8nRbdna2DWtMiYnSyCBzrlwB2rUDeve2f51cUnS0NLQ5OVkae1ki6LbInj3STaxfX7oGgxeqRIwl0o4cWZzoauwYMq/k3DOuxllJt1YFLPXq1YNCoUBuieV/c3NzERgYaNE1qlevjrZt2yLj7qfVnmfNNT09PeHj42OwkW3NmCENlgkONn/sDz9Iz9wq+6yNjgYWL5YWWdQGLzVrWneNy5elP0O1wUu/fuw2IpdQVnfP3r2lAxGNRppFNTRUmu9pzZqqFazI5dIKIGvWSF+X3PfLL9L9/Pxz09dYvVqaAl8/cJHJgCeeMDzujTekXzk7dkh/ZGrfTy4HYmKKz9dO0W+MTFa6nuY4YvI+o6xNkGnXrp0YM2aM7rVarRYNGjQwmXRb0p07d0SzZs3Ea6+9JoQoTrqdN2+e7pi8vDwm3boQS5NxASGeeMLZtXUhnTrZJsstPl5aEY0jjcgOtKNxjH176S+cBwgxcmRxkuzcuVV75I1cbnzRQP0FZL/6SkosBqR/Sy48aOz+6Y/Ayc4WYs0aaUtONp60rP//lp0tjbrSP1/7umRd5swp3qd9H2OLHY4aZVhPWy9AaddRQqtWrRKenp5i+fLl4q+//hIjR44Ufn5+uqHKAwcOFJMmTdId/+6774otW7aIM2fOiNTUVPHcc88JLy8vceLECd0xs2fPFn5+fuKnn34SR48eFT169OCwZhczd67lP8j16gkxcyafr0II6bfMa68JUaeObX5LtmolxNixbrqsNjmauZV8q+pInTVrpFWMje2TyaRRTMaCAGMP8pJBRMn7b2kwYO2wcGPKqou2PsY+j37g5MzVmq0OWIQQYsGCBaJhw4bCw8NDtGvXTuzbt0+379FHHxWDBw/WvX711Vd1xwYEBIgnnnhCHDx40OB6Go1GTJ06VQQEBAhPT0/RuXNnkZaWZnF9GLA4Rna2EPffb90PfpUcAm3KL78IERpqu9+qnN+FrKBtSdG2kPzyS9l/sZt6QLrzVvIhbazFoeTfCuaCAEv+XywJBkwNC7f1r4CKfh5rWfP85tT8ZLXnnweWLbP8+LAwqT83OtpuVapcUlKkOcnXrJHWqa+oRo2Ali2lf/v3542mUvSnxDdnzRppBGBiojTLdVWyZo3hIIIlS6QRMWp18TpG5pYSsCdXq48tWPP8ZsBC5dKnD7B2rXXnhIRIiWZPPmmfOlVKGzdKybV//gkUFNjmmv7+0hjTRx7hmkYElUpKgLUkWNEmZ7pbkuzLLwMXL0q/s0x9NlPr46hU0oiYpk1d40fJ1epTUQxYyCFSUoDXXwd27bLuPF9fYMIEYNAg9/iBsxlt8JKcLI0aspWePaUFHXmzKz2VCkhPB2rVkuLb8PCy/1tVKqnV4PXXHVdHexo8GPjmG8sDKrkcmD0bGD9eeq192Ht7S/flo4/cq7WiMrLq+W3XzikHYQ6Lc1mTkFtymzPH2bV3UcnJQjz8sG076CMihBg2jAm7lVTJETvanApTSZpffFE5RvH06mV5fknJRFe5XEqAnTvX9AiYsjg6X4NKYw4LOZxKJTUQzJkDnDtn3bmtW0v9suy9MEJ7Y//8Ezh4EEhLs8112T9XqZTVrSOTAfv3G6YuqVRAw4bSo96VabthVq2SWl2FkFpFBg4Evv66uP5yuZT2pW0BMdYt4m5dJVUFu4TIqVJSpOfgxYvWn8veCzNUKmDsWGDdOttcLyREmv2LN9xhtN065rpz9I+9dEmajM0UmUyauzA+Xjp+9Wqpi8OVtG8PJCVZHoSoVNLxABAby29Rd8WAhVzCK69IwUd5/N//Ae+/z19SJqlUUmf+1q3A+fPA2bMVu96bb1a9ISFOMG8eMHGi1FJS8oFd0ltvSQuNWvMbWiZzbKuKTCb9nNauDbz4ounjtC0pAIMQMsSAhVxGRbqKAGlV6I8+4khds7Q3etkyKWm3PAIDpbm/o6LYP2cHc+dK3R76So5M0baofPAB8OuvDq+i1b74Ahg1Svpaf+i0/mgjJrRSWRiwkEtKSZGGQ2v/0rJGcLD0S48pFxbQtqW/9x5w/Hj5r9OhgzSvC4OXCisrp2THDqkbZNIk4PvvXT/vREsmkxYt1//W0O/WAZhTQuYxYCGX9tZb5e99CAwEfv6ZLS4WS0kBVq6UnoqHD5f/OvfdJ/XTcSy61cwNLR461LqJGJ1JLresO4vIUgxYyOVVNHe0TRtp1VM+O62g7TZ6803g2rXyXyciAnj4YWloVxWPHEvOi1JyfpSvvpK6SVz9t6xCITXKjR8P7NxZer82QImPZ6sJ2RYDFqo0Ktp7EREhTSbFP/ytZO36Cqb4+wMPPlhplwVQqaRBUoA0isXYLKemRvSUNd29dsKykjkrzrJmjZSbrU34LSvHJCVFyp8JDAQiI4HCQgYoZD8MWKhSSkkBhgwB/vqrfOdzSLSV5s0rngLUVgICgKeflhaj6d7dLgGMNcOCy7JkCTB8uGHZk09KDUf//it1PWpzSowNwbV0untnmzsXeOMN6WvmmJCrYcBClVpF1wbkkGgraIdHr1wJHDtm++s3aAA8+2yFWl/0A5SSE4zpBxEpKdIyEQ8/XPxW+ucCxd03Bw4AL71kfV20c6GcPg0cOlSuj2MTlg5fnjPH9jEpkS0xYCG3sXEjMGIEkJNj/bkcEm0lbY7L999bv0CUJUJDpSe+p6fFrS+WrDK8erU0K6r+MOBnnwViYoqDG3fSvbs0SbF2TZwHHyx9f774QmotYtBOro4BC7mdiows4pDoctAGL6mpwJYtQHa27d+jSROonp+G9KZdEd6+fqmHa0qKFHRU/t9QtpWcbBjrLVkidWNxET+qjBiwkFuq6Mgib2/pF/1jjzFJ12q2Gh4NQIUG2ItYbEcnLMZIaKCADGqMbJ2MTh0F2vdvhC1HgzBiRNUMVmQyYNo0oFs34LPPgBUrivcNHgwsX176HK6jQ5UVAxZya9q0ixUrKrYWIJN0y8nMrLopiMIuPISHsRsA8B36AQDikIid6IgP8DoE5GW8gQaA7O7mvpo3B06dMgzKjLWQpKQAe/ZIXZzs3iR3w4CFqgyVCujRQ1rIuLw6dwYSEvgwKJe7f9qrDl7EL/PSsPBCdxxFa0jBhvZXizbwEHD3IMQS2vV3xo8vbhnx9ubwYaqaGLBQlVPRIdGANO9EmzbSKJOq3GVkbNiwtqywUGpUCQqSlhw6cAD48UcgMdG5da4M5HJg3DipW7Oqfm8RlcSAhaqsig6J1tehg7QWYNOmxicVcyfagGT9euDTT4u7KXr2BG7cYEBijkwmBSRqdenyyZOlvCm2nhCVxoCFCFKaxahRwN9/2+Z6jz4KPPKI3eZDczhtkJKYCMyaVRkSXEt2MZV1nKzEa0vOMySXS902c+YY3hu5HBg9WkqI1Z8pVn/aeoBJsESWYMBCpEfb6rJ9O3D2rG2u2aYN0Ls3cPNm5Qxg5s2rbHOUCEzBDIzCl/gYr9xN3FXo9knBiBr98R3CcB4JeBMaKCCHGrMxEf2wCh97jMdHRWOghgL6QY12Gv2LF6V5e0oODzY1bJgjc4gqjgELkQm2SNI15pFHpCDg3DnptSt3IVVkThvn0GAOJmA8PtCVqNAASYgFAIQhE4XwRlNkQIm/dfsz0NSgTL/cG4XIRBhQ3x+x916D0vsa0KoVVGEPIaPeg2gaazgvDIMTIvtgwEJkRkoKMGUKsHWr/d6jVSspMbVJEyAvD7hwAejTx/IJ7Eomv5aVDGtqXR3t6OMbN6TWgevXgX37bPYRK6RXL2l0zHffFbf06E85H/fQf3jm3r/wZPUtUJ7aJq3eZ6smMnOioqQKVoUEJiInYsBCZCHtnC67d0trw1y4YP/39PGRnoGtWkmr4TZqJLXMpKYCR48CHh7Ss/nIkeJzAgKA3Nzi140aATVqGI6KiogA7r1XKvf2lqaq1z/HmfSTUrVdMNo1bqxakM/eyweY0qGDtHl6Au3aSTe4oqsvEhEDFqLyckTLS2XXrJn5Cfu6dQM2bzbM+9BPSrXJc16lApKSpK8LC4G1a4E//wQKCmxwcQuNGSONgwfYEkNUDgxYiCpI+yzMyAA2bDA6oWuVo786sv7sq0ePFiel6reeOC3vY+NGafW/a9ekJqi8PMe9d3w88PzzDF6ILMSAhcjGVCopUXXhQmfXxH7GjAGeeaa4a2bjRmmV7KgooFatsgMPl05K3bhRWsfhr78qNrOgtSIipMV/WrUCTp+WWmIq23AyIjtjwEJkJ/otLzt2VP6uo//9T1pozyUDDXvQ/gempkrNZjdvApmZjkleAoDQUGk2vrg45sEQgQGLs6tDVYg2B/TPP6Weh9BQaSTOwYMVW5jR1qpVA+7cKX7dvLnU6MA/+O9KSZGylHfuBP74w7Hvfe+9gJ8f4OVVeilxc8PAiCo5BixELkAbzJw+LfUOeHlJz8Q9eyz7g75ZM+lZdv48cPiwYfk99wC1awO3b0ujjgBp5V9jQdKYMdKq1Fz110LaVphVq4B165xThw4dpP/gLVukcd4yGfD661yIiNwOAxYiF6f9g/7iRSkg8fWVJp+LjDS+aq+lOSLaZ+2VK0DdukBsLJ9vFaK98QUF0r8ajXSDExOlpF5nePBBIDhY+mZ57DGpbuHh0j62xlAlw4CFiMjetMm81au7Vh+gTAa8/76ULc3ghVwcAxYiIkfTbzbbvt11AhjtsuN16kjNbo0aFbfKMJghJ2PAQkTkbCqVlHOyfr3rrjIZFVW8hkT37gxgyOEYsBARuQptHoy3tzSEOiNDWhPp0iUgP1/qUjp1CsjKcnZNpSzvsLDidSM4AR7ZGQMWIqLKZt48YMIE12uNadQIaNmyeJGqJk2Ku5fat5eOYbIvlRMDFiKiykh/mJfWtWtSi8yBA4bj211R27bAs88aziVDVAYGLERE7kh/mPX27dLaCbt3A9nZzq5ZaW3bSsOuw8Kk19oWmZLj9dk6U6UxYCEiqkr0Ryjt3g0cP+56XUta990nTTp07JhUV6033uDEeFUQAxYioqpMP9E3NVWabnnrVimQcXUREVLyb716Ur5M06bMlXFjDFiIiKg07foMTZsC//0nldWoAfz0E3DmjDRayVELQVZEz57A449LX3NumUqNAQsREZWPfvfSqVPS2hFnzzq7VpbT5s5wWHalwICFiIhsR3/00rVrwG+/Abt2ObtWlnn0UalrqbDQcFg2wERgF8CAhYiI7KvkEOy6daUgZsEC59arPDp3Bp55RgpqJk6UFrnUrsk0fryza+fW7B6wfPbZZ5g7dy5ycnLQunVrLFiwAO3atTN73qpVq9CvXz/06NEDGzZs0JUPGTIEK1asMDg2Pj4emzdvtqg+DFiIiFyE/tDrAweAmzeloKaw0HWHYJclIgJ44AFp8jz9CfO0rS8qFbB3r/R1yXK21Jhl14Bl9erVGDRoEBYuXIiYmBjMnz8fa9euRVpaGvz9/U2el5mZiYceegiNGzfGPffcUypgyc3NxbJly3Rlnp6eqKNttjODAQsRUSVRMvFXu1RBYSFw8qTrT46nFRUltcKkpBiWjxwJ1K8PJCRILTVyObBoETBsmHPq6eLsGrDExMQgOjoan376KQBAo9EgJCQEL7/8MiZNmmT0HLVajUceeQTPP/88du3ahevXr5cKWEqWWYMBCxGRm9C20KxbB3z6afF8Ms2aAf/+W/laaLSee05qpQGkhGZ/fw7ZhnXP72rWXLioqAipqamYPHmyrkwulyMuLg5JSUkmz3vvvffg7++PYcOGYZeJRK0//vgD/v7+qFOnDjp16oQZM2agbt26Ro+9desWbt26pXudn59vzccgIiJXpVRKW8eO0tpKGRnSg137IE9JAVaulLqbKkviLwCsWiVt5kRFAb16FXc/aYds16plOHS7CnY5WRWwXL58GWq1GgEBAQblAQEBOHXqlNFzdu/ejSVLluBwGc18Xbp0wdNPP41GjRrhzJkzePPNN9G1a1ckJSVBoVCUOj4hIQHvvvuuNVUnIqLKRhu86IuOljagOPEXkOaT0QY3KhWwbBmQnOzY+trCgQPSVpbBg4FvvilODh45EujUCahZU5ok8OGHi++RG7GqS+iff/5BgwYNsHfvXsTGxurKJ0yYgJ07d2L//v0Gx9+4cQOtWrXC559/jq5duwKwrPvn7NmzaNKkCbZt24bOnTuX2m+shSUkJIRdQkREVEx/JFPdulJQs3175WudKY82baRA5to1KfG5e3epfNculwpo7NYlVK9ePSgUCuTm5hqU5+bmIjAwsNTxZ86cQWZmJrprbxSknBcAqFatGtLS0tCkSZNS5zVu3Bj16tVDRkaG0YDF09MTnp6e1lSdiIiqGqUS6N3bsOzJJ6V/VSpg40ZpAcmwMCkR+MwZ6QFfWRJ/y3L4MPDSS8Wvp0833N+gARAfL3VBRUVJQVxaGuDpCVy+DNSuDfTv7zKBDVDOpNt27dphwd2x9hqNBg0bNsSYMWNKJd3evHkTGRkZBmVvvfUWbty4gY8//hgRERHw8PAo9R4qlQoNGzbEhg0b8NRTT5mtE5NuiYjIZvS7msLCgMzM4tFMR49KeTSVfwozy/j7S91NLVsWJwnbMGfG7sOaBw8ejC+//BLt2rXD/PnzsWbNGpw6dQoBAQEYNGgQGjRogISEBKPnl+wSKigowLvvvotnnnkGgYGBOHPmDCZMmIAbN27g2LFjFrWkMGAhIiKHKbm45Lp1wLZtxUFMdLSUW1IZc2jMkcmAxYttNkzbbl1CANC3b19cunQJ06ZNQ05ODtq0aYPNmzfrEnGzsrIgl8stvp5CocDRo0exYsUKXL9+HcHBwXj88ccxffp0dvsQEZHr0U8Gjo4GRo0qDmL0RzSVnA342jVgxw7D4AYAWrWSRgPt2weUSLlwOUIAI0ZI3UkOHp3EqfmJiIgcSb/LKTbW8MGvHbZ94wZQvbo0O/Dx467XBbVmTen8oHKwawsLERERVYCxZGAt/WHbWtrWm6+/BpYvLw5e6tSRWm20/P2lSenclOV9N0REROR42on0li4FsrKkbqXsbODqVSlP5qOPpH9zc6XyUaOkJQEAKeckKsrwesHBFauPTCa1DDkYu4SIiIjcTcmcGmOvN24Evv/ecE6a/v2Bhx6SWm42bCidOOzEpFsGLERERFWZsYRh/X36k++VzLmpIOawEBERkWWMLYGgv88GybW2wBwWIiIicnkMWIiIiMjlMWAhIiIil8eAhYiIiFweAxYiIiJyeQxYiIiIyOUxYCEiIiKXx4CFiIiIXB4DFiIiInJ5DFiIiIjI5TFgISIiIpfnFmsJaddvzM/Pd3JNiIiIyFLa57Yl6zC7RcBy48YNAEBISIiTa0JERETWunHjBnx9fcs8RiYsCWtcnEajwT///IPatWtDJpPZ9Nr5+fkICQlBdna22aWvqzreK8vxXlmH98tyvFeW472ynL3ulRACN27cQHBwMOTysrNU3KKFRS6XQ2lqaWwb8fHx4Te0hXivLMd7ZR3eL8vxXlmO98py9rhX5lpWtJh0S0RERC6PAQsRERG5PAYsZnh6euLtt9+Gp6ens6vi8nivLMd7ZR3eL8vxXlmO98pyrnCv3CLploiIiNwbW1iIiIjI5TFgISIiIpfHgIWIiIhcHgMWIiIicnkMWMz47LPPEBYWBi8vL8TExCA5OdnZVXKohIQEREdHo3bt2vD390fPnj2RlpZmcMzNmzcxevRo1K1bF7Vq1cIzzzyD3Nxcg2OysrLQrVs31KxZE/7+/hg/fjzu3LnjyI/icLNnz4ZMJsOrr76qK+O9Kvb3339jwIABqFu3LmrUqIGWLVviwIEDuv1CCEybNg1BQUGoUaMG4uLikJ6ebnCNq1evon///vDx8YGfnx+GDRuGgoICR38Uu1Or1Zg6dSoaNWqEGjVqoEmTJpg+fbrB+itV9X79+eef6N69O4KDgyGTybBhwwaD/ba6L0ePHsXDDz8MLy8vhISEYM6cOfb+aDZX1r26ffs2Jk6ciJYtW8Lb2xvBwcEYNGgQ/vnnH4NrOPVeCTJp1apVwsPDQyxdulScOHFCjBgxQvj5+Ync3FxnV81h4uPjxbJly8Tx48fF4cOHxRNPPCEaNmwoCgoKdMeMGjVKhISEiMTERHHgwAHx4IMPivbt2+v237lzR9x///0iLi5OHDp0SGzatEnUq1dPTJ482RkfySGSk5NFWFiYaNWqlRg7dqyunPdKcvXqVREaGiqGDBki9u/fL86ePSu2bNkiMjIydMfMnj1b+Pr6ig0bNogjR46Ip556SjRq1Ej8999/umO6dOkiWrduLfbt2yd27dolmjZtKvr16+eMj2RXM2fOFHXr1hUbN24U586dE2vXrhW1atUSH3/8se6Yqnq/Nm3aJKZMmSLWrVsnAIj169cb7LfFfcnLyxMBAQGif//+4vjx42LlypWiRo0a4ssvv3TUx7SJsu7V9evXRVxcnFi9erU4deqUSEpKEu3atRORkZEG13DmvWLAUoZ27dqJ0aNH616r1WoRHBwsEhISnFgr57p48aIAIHbu3CmEkL7Jq1evLtauXas75uTJkwKASEpKEkJIPyRyuVzk5OTojvniiy+Ej4+PuHXrlmM/gAPcuHFDhIeHi61bt4pHH31UF7DwXhWbOHGieOihh0zu12g0IjAwUMydO1dXdv36deHp6SlWrlwphBDir7/+EgBESkqK7pjffvtNyGQy8ffff9uv8k7QrVs38fzzzxuUPf3006J///5CCN4vrZIPYVvdl88//1zUqVPH4Gdw4sSJolmzZnb+RPZjLLgrKTk5WQAQ58+fF0I4/16xS8iEoqIipKamIi4uTlcml8sRFxeHpKQkJ9bMufLy8gAA99xzDwAgNTUVt2/fNrhP9957Lxo2bKi7T0lJSWjZsiUCAgJ0x8THxyM/Px8nTpxwYO0dY/To0ejWrZvBPQF4r/T9/PPPiIqKQu/eveHv74+2bdti8eLFuv3nzp1DTk6Owb3y9fVFTEyMwb3y8/NDVFSU7pi4uDjI5XLs37/fcR/GAdq3b4/ExEScPn0aAHDkyBHs3r0bXbt2BcD7ZYqt7ktSUhIeeeQReHh46I6Jj49HWloarl275qBP43h5eXmQyWTw8/MD4Px75RaLH9rD5cuXoVarDR4cABAQEIBTp045qVbOpdFo8Oqrr6JDhw64//77AQA5OTnw8PDQfUNrBQQEICcnR3eMsfuo3edOVq1ahYMHDyIlJaXUPt6rYmfPnsUXX3yBcePG4c0330RKSgpeeeUVeHh4YPDgwbrPauxe6N8rf39/g/3VqlXDPffc41b3CgAmTZqE/Px83HvvvVAoFFCr1Zg5cyb69+8PALxfJtjqvuTk5KBRo0alrqHdV6dOHbvU35lu3ryJiRMnol+/frrFDp19rxiwkMVGjx6N48ePY/fu3c6uikvKzs7G2LFjsXXrVnh5eTm7Oi5No9EgKioKs2bNAgC0bdsWx48fx8KFCzF48GAn1871rFmzBt999x2+//573HfffTh8+DBeffVVBAcH836Rzd2+fRt9+vSBEAJffPGFs6ujwy4hE+rVqweFQlFqBEdubi4CAwOdVCvnGTNmDDZu3IgdO3ZAqVTqygMDA1FUVITr168bHK9/nwIDA43eR+0+d5GamoqLFy/igQceQLVq1VCtWjXs3LkTn3zyCapVq4aAgADeq7uCgoLQokULg7LmzZsjKysLQPFnLevnLzAwEBcvXjTYf+fOHVy9etWt7hUAjB8/HpMmTcJzzz2Hli1bYuDAgXjttdeQkJAAgPfLFFvdl6rycwkUByvnz5/H1q1bda0rgPPvFQMWEzw8PBAZGYnExERdmUajQWJiImJjY51YM8cSQmDMmDFYv349tm/fXqqpLzIyEtWrVze4T2lpacjKytLdp9jYWBw7dszgG137g1DyoVWZde7cGceOHcPhw4d1W1RUFPr376/7mvdK0qFDh1LD40+fPo3Q0FAAQKNGjRAYGGhwr/Lz87F//36De3X9+nWkpqbqjtm+fTs0Gg1iYmIc8Ckc599//4VcbvjrWqFQQKPRAOD9MsVW9yU2NhZ//vknbt++rTtm69ataNasmVt1B2mDlfT0dGzbtg1169Y12O/0e1XhtF03tmrVKuHp6SmWL18u/vrrLzFy5Ejh5+dnMILD3b344ovC19dX/PHHH+LChQu67d9//9UdM2rUKNGwYUOxfft2ceDAAREbGytiY2N1+7VDdR9//HFx+PBhsXnzZlG/fn23G6prjP4oISF4r7SSk5NFtWrVxMyZM0V6err47rvvRM2aNcW3336rO2b27NnCz89P/PTTT+Lo0aOiR48eRoejtm3bVuzfv1/s3r1bhIeHV/phusYMHjxYNGjQQDesed26daJevXpiwoQJumOq6v26ceOGOHTokDh06JAAID788ENx6NAh3cgWW9yX69evi4CAADFw4EBx/PhxsWrVKlGzZs1KN6y5rHtVVFQknnrqKaFUKsXhw4cNft/rj/hx5r1iwGLGggULRMOGDYWHh4do166d2Ldvn7Or5FAAjG7Lli3THfPff/+Jl156SdSpU0fUrFlT9OrVS1y4cMHgOpmZmaJr166iRo0aol69euL1118Xt2/fdvCncbySAQvvVbFffvlF3H///cLT01Pce++9YtGiRQb7NRqNmDp1qggICBCenp6ic+fOIi0tzeCYK1euiH79+olatWoJHx8fMXToUHHjxg1HfgyHyM/PF2PHjhUNGzYUXl5eonHjxmLKlCkGD5Kqer927Nhh9HfU4MGDhRC2uy9HjhwRDz30kPD09BQNGjQQs2fPdtRHtJmy7tW5c+dM/r7fsWOH7hrOvFcyIfSmSiQiIiJyQcxhISIiIpfHgIWIiIhcHgMWIiIicnkMWIiIiMjlMWAhIiIil8eAhYiIiFweAxYiIiJyeQxYiIiIyOUxYCEiIiKXx4CFiIiIXB4DFiIiInJ5DFiIiIjI5f0/Um/vYiygIzwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwuqC0OxLmVX"
      },
      "id": "wwuqC0OxLmVX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "I learned about how different choices in neural network strcutures, learning rates, and epochs can affet the model's performance. Like changing the number of layers and nodes can influence the model's capacity to learn complex patterns from the data. Adjusting too the learning rate can impact the speed and quality of convergence during training. And modifying the number of epochs can affect the amount of training time and the model's ability to generalize."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}